{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1649feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from callback.lr_scheduler import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from callback.progressbar import ProgressBar\n",
    "from callback.adversarial import FGM\n",
    "\n",
    "from tools.common import seed_everything\n",
    "from tools.common import init_logger, logger\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from transformers import WEIGHTS_NAME, BertConfig, get_linear_schedule_with_warmup, AdamW, BertTokenizer\n",
    "\n",
    "from pytorch_tabnet.multitask import TabNetMultiTaskClassifier\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "from models.nezha.modeling_nezha import NeZhaForSequenceClassification, NeZhaModel\n",
    "from models.nezha.configuration_nezha import NeZhaConfig\n",
    "\n",
    "from pylab import mpl\n",
    "\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9dcdea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    ## bert ernie bert_wwm bert_wwwm_ext\n",
    "    'bert-base-chinese': (BertConfig, AutoModel, BertTokenizer),\n",
    "    'roberta-base':(BertConfig, AutoModel, BertTokenizer),\n",
    "    'nezha-cn-base': (NeZhaConfig, NeZhaModel, BertTokenizer),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ecbe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFGs:\n",
    "    def __init__(self):\n",
    "        super(CFGs, self).__init__()\n",
    "        \n",
    "        self.data_dir = './data/'\n",
    "        self.out_dir = './output'\n",
    "\n",
    "        self.epochs=100\n",
    "        self.folds = 5\n",
    "\n",
    "        self.task = 'whole' # whole detail\n",
    "        #self.train_file = f'{self.task}.pkl'\n",
    "        self.train_file = f'{self.task}.pkl'\n",
    "        self.model_name = 'roberta-base'\n",
    "        self.tokenizer_path = './prev_trained_model/chinese-roberta-wwm-ext'\n",
    "        self.model_path = './prev_trained_model/chinese-roberta-wwm-ext-pretrained/maskedLM-pretraining/checkpoint-21000'\n",
    "\n",
    "        self.scheduler='cosine'\n",
    "        self.seed = 42\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.batch_size = 512 #16,32\n",
    "        self.dropout = 0.2\n",
    "        #self.max_len = 40\n",
    "\n",
    "        self.text_dim = 768\n",
    "        self.img_dim = 2048\n",
    "\n",
    "        self.transformer_lr = 2e-5\n",
    "        self.clf_lr = 1e-4\n",
    "\n",
    "        self.weight_decay = 0.01\n",
    "        self.eps=1e-6\n",
    "        self.betas=(0.9, 0.999)\n",
    "        self.num_warmup_steps=0\n",
    "\n",
    "        self.max_norm = 1000\n",
    "        self.num_cycles=0.5\n",
    "        self.patience = 5\n",
    "        \n",
    "        self.do_fgm = False\n",
    "        self.do_pgd = False\n",
    "        self.do_freelb = False\n",
    "        self.do_ema = True\n",
    "\n",
    "        self.log_name = './output'\n",
    "\n",
    "        self.overwrite_output_dir = True\n",
    "        \n",
    "CFG = CFGs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe81a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./prev_trained_model/chinese-roberta-wwm-ext-pretrained/maskedLM-pretraining/checkpoint-21000 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ./prev_trained_model/chinese-roberta-wwm-ext-pretrained/maskedLM-pretraining/checkpoint-21000 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "425"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[CFG.model_name]\n",
    "    \n",
    "config = config_class.from_pretrained(CFG.model_path)\n",
    "tokenizer = tokenizer_class.from_pretrained(CFG.tokenizer_path)\n",
    "bert_model = model_class.from_pretrained(CFG.model_path, config=config)\n",
    "CFG.tokenizer = tokenizer\n",
    "\n",
    "del tokenizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074630cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.text = df['text'].values\n",
    "        self.feature = df['feature'].values\n",
    "        self.label = None\n",
    "        if 'label' in df.columns:\n",
    "            self.label = df['label'].values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.label is not None:\n",
    "            return self.text[index],  torch.tensor(self.feature[index]), torch.tensor(self.label[index]).long()\n",
    "        else:\n",
    "            return self.text[index],  torch.tensor(self.feature[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b9030fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuseLayer(nn.Module):\n",
    "    def __init__(self, text_dim, img_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm1d(768*2)\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(img_dim, text_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(2 * text_dim, text_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "        )\n",
    "    \n",
    "    def forward(self, text, img):\n",
    "        img = self.fc1(img)\n",
    "        \n",
    "        concat = torch.cat((img, text),dim=1)\n",
    "        concat = self.bn(concat)\n",
    "        fuse = self.fc2(concat)\n",
    "        return fuse\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, CFG):\n",
    "        super().__init__()\n",
    "        dropout = CFG.dropout\n",
    "        self.transformer = model_class.from_pretrained(CFG.model_path, config=config)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fuse = FuseLayer(CFG.text_dim, CFG.img_dim, dropout)\n",
    "        self.clf = nn.Linear(CFG.text_dim, 2)\n",
    "        self.clf1 = nn.Sequential(\n",
    "                    nn.Linear(CFG.text_dim, 256),\n",
    "                    nn.Linear(256, 64),\n",
    "                    nn.Linear(64, 13))\n",
    "        \n",
    "    def forward(self, text, img):\n",
    "        text = self.transformer(**text)[1]\n",
    "        text = self.dropout(text)\n",
    "        fuse = self.fuse(text, img)\n",
    "        out = self.clf1(fuse)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f033bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = CFG.device\n",
    "task_name = '_pretrained_6000_2_1.5_1.5_5_shuffle_0.3_fold5_修正数据集'\n",
    "CFG.out_dir = os.path.join(CFG.out_dir, f'roberta-base' + task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6349b942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:07, 1264.19it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/preliminary_testB.txt'\n",
    "import json\n",
    "import itertools\n",
    "import re\n",
    "def load_attr_dict(file):\n",
    "    # 读取属性字典\n",
    "    with open(file, 'r') as f:\n",
    "        attr_dict = {}\n",
    "        for attr, attrval_list in json.load(f).items():\n",
    "            attrval_list = list(map(lambda x: x.split('='), attrval_list))\n",
    "            attr_dict[attr] = list(itertools.chain.from_iterable(attrval_list))\n",
    "    return attr_dict\n",
    "\n",
    "attr_dict_file = \"./data/attr_to_attrvals.json\"\n",
    "attr_dict = load_attr_dict(attr_dict_file)\n",
    "\n",
    "def extract_key_attr(title, attr, attr_dict):\n",
    "    # 在title中匹配属性值\n",
    "    if attr == '图文':\n",
    "        return '图文', '符合'\n",
    "    attr_dict1 = attr_dict\n",
    "    attrvals = \"|\".join(attr_dict1[attr])\n",
    "    ret = re.findall(attrvals, title)\n",
    "    if ret:\n",
    "        return attr, ret[0]\n",
    "    else:\n",
    "        return 'N',''\n",
    "\n",
    "\n",
    "def extract_all_key_attr(text):\n",
    "    key_attr = {}\n",
    "    for attr in class_name:\n",
    "        #print(text, attr)\n",
    "        ret_attr, class_label = extract_key_attr(text, attr, attr_dict)\n",
    "        if ret_attr != 'N':\n",
    "            key_attr[ret_attr] = class_label\n",
    "    if not key_attr:\n",
    "        return '无'\n",
    "    return key_attr #['衣长':'中长款']\n",
    "\n",
    "img_name = []\n",
    "img_features = []\n",
    "texts =[]\n",
    "querys = []\n",
    "class_name = ['图文', '版型', '裤型', '袖长', '裙长', '领型', '裤门襟', '鞋帮高度', '穿着方式', '衣长', '闭合方式', '裤长', '类别']\n",
    "\n",
    "with open(data_dir, 'r') as f:\n",
    "    for data in tqdm(f):\n",
    "        data = json.loads(data)\n",
    "        img_features.append(np.array(data['feature']).astype(np.float32))\n",
    "        img_name.append(data['img_name'])\n",
    "        texts.append(data['title'])\n",
    "        querys.append(data['query'])\n",
    "\n",
    "df = pd.DataFrame(img_name)\n",
    "df['feature'] = img_features\n",
    "df['text'] = texts\n",
    "df['querys'] = querys\n",
    "df.columns = ['img_name', 'feature', 'text', 'querys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc1e42d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>feature</th>\n",
       "      <th>text</th>\n",
       "      <th>querys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test004000</td>\n",
       "      <td>[-0.044185117, 0.0056368606, 0.113686286, -1.9...</td>\n",
       "      <td>蓝色衬衫2021年秋季长袖童装</td>\n",
       "      <td>[图文, 袖长]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test004001</td>\n",
       "      <td>[0.09333559, -0.008259959, 0.09762427, -0.2455...</td>\n",
       "      <td>短裤2021年冬季女士休闲裤阔腿裤黑色加厚女装</td>\n",
       "      <td>[图文, 裤型]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test004002</td>\n",
       "      <td>[0.29037216, -0.0029620992, 0.020722916, -0.88...</td>\n",
       "      <td>紧身裤短裤男装厚度常规2022年春季运动裤</td>\n",
       "      <td>[图文, 裤型, 裤长]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test004003</td>\n",
       "      <td>[-0.24379866, -0.008214505, 0.06657183, -0.950...</td>\n",
       "      <td>灰色厚度常规女装2021年春季七分裤女士休闲裤</td>\n",
       "      <td>[图文, 裤长]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test004004</td>\n",
       "      <td>[0.2508675, -0.0061487244, -0.037342805, -0.83...</td>\n",
       "      <td>低帮2021年夏季男士休闲鞋一脚蹬灰色</td>\n",
       "      <td>[图文, 鞋帮高度]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     img_name                                            feature  \\\n",
       "0  test004000  [-0.044185117, 0.0056368606, 0.113686286, -1.9...   \n",
       "1  test004001  [0.09333559, -0.008259959, 0.09762427, -0.2455...   \n",
       "2  test004002  [0.29037216, -0.0029620992, 0.020722916, -0.88...   \n",
       "3  test004003  [-0.24379866, -0.008214505, 0.06657183, -0.950...   \n",
       "4  test004004  [0.2508675, -0.0061487244, -0.037342805, -0.83...   \n",
       "\n",
       "                      text        querys  \n",
       "0          蓝色衬衫2021年秋季长袖童装      [图文, 袖长]  \n",
       "1  短裤2021年冬季女士休闲裤阔腿裤黑色加厚女装      [图文, 裤型]  \n",
       "2    紧身裤短裤男装厚度常规2022年春季运动裤  [图文, 裤型, 裤长]  \n",
       "3  灰色厚度常规女装2021年春季七分裤女士休闲裤      [图文, 裤长]  \n",
       "4      低帮2021年夏季男士休闲鞋一脚蹬灰色    [图文, 鞋帮高度]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ca46205",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(df, CFG, fold):\n",
    "    pred = np.empty((0,13))\n",
    "    dataset = MyDataset(df)\n",
    "    loader = DataLoader(dataset, batch_size=CFG.batch_size, pin_memory=True)\n",
    "    model = Model(CFG).to(device)\n",
    "    model.eval()\n",
    "    model.load_state_dict(torch.load(f'{CFG.out_dir}/model_{CFG.task}_fold{fold}.pth'))\n",
    "    for text, feature in tqdm(loader):\n",
    "        text = CFG.tokenizer(text, return_tensors='pt', add_special_tokens=True, padding=True)\n",
    "        for k, v in text.items():\n",
    "            text[k] = v.cuda()\n",
    "        img = feature.cuda()\n",
    "        outputs = model(text, img)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        #print(outputs.shape, outputs)\n",
    "        pred= np.concatenate((pred, outputs.cpu().numpy()))\n",
    "        #print(pred.shape)\n",
    "        #pred = np.stack([pred, outputs.cpu().numpy()])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a9ca625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./prev_trained_model/chinese-roberta-wwm-ext-pretrained/maskedLM-pretraining/checkpoint-21000 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ./prev_trained_model/chinese-roberta-wwm-ext-pretrained/maskedLM-pretraining/checkpoint-21000 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 20/20 [00:30<00:00,  1.54s/it]\n",
      "Some weights of the model checkpoint at ./prev_trained_model/chinese-roberta-wwm-ext-pretrained/maskedLM-pretraining/checkpoint-21000 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ./prev_trained_model/chinese-roberta-wwm-ext-pretrained/maskedLM-pretraining/checkpoint-21000 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 20/20 [00:08<00:00,  2.27it/s]\n",
      "Some weights of the model checkpoint at ./prev_trained_model/chinese-roberta-wwm-ext-pretrained/maskedLM-pretraining/checkpoint-21000 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ./prev_trained_model/chinese-roberta-wwm-ext-pretrained/maskedLM-pretraining/checkpoint-21000 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 20/20 [00:07<00:00,  2.84it/s]\n",
      "Some weights of the model checkpoint at ./prev_trained_model/chinese-roberta-wwm-ext-pretrained/maskedLM-pretraining/checkpoint-21000 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ./prev_trained_model/chinese-roberta-wwm-ext-pretrained/maskedLM-pretraining/checkpoint-21000 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 20/20 [00:07<00:00,  2.85it/s]\n",
      "Some weights of the model checkpoint at ./prev_trained_model/chinese-roberta-wwm-ext-pretrained/maskedLM-pretraining/checkpoint-21000 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ./prev_trained_model/chinese-roberta-wwm-ext-pretrained/maskedLM-pretraining/checkpoint-21000 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 20/20 [00:07<00:00,  2.76it/s]\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "CFG.folds = 5\n",
    "\n",
    "for fold in range(CFG.folds):\n",
    "    pred.append(evaluate(df, CFG, fold))\n",
    "\n",
    "\n",
    "\n",
    "# pred = []\n",
    "# CFG.folds = 1\n",
    "\n",
    "# for fold in [2]:\n",
    "#     pred.append(evaluate(df, CFG, fold))\n",
    "\n",
    "# pred = np.mean(pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc1e1a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.mean(pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73124dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.95482361e-01, 7.59311122e-10, 2.56077689e-09, ...,\n",
       "        1.92529722e-10, 2.28087361e-07, 1.48916808e-08],\n",
       "       [6.55258693e-05, 3.28966524e-08, 9.80447233e-01, ...,\n",
       "        7.32720515e-07, 2.43781182e-05, 1.03547826e-09],\n",
       "       [2.01985047e-09, 1.86724972e-07, 5.37951998e-03, ...,\n",
       "        4.71472686e-08, 1.75374046e-07, 6.55442434e-13],\n",
       "       ...,\n",
       "       [9.89723551e-01, 5.19829739e-09, 3.40055176e-09, ...,\n",
       "        8.32683550e-10, 2.74463315e-06, 1.46830635e-08],\n",
       "       [9.50243222e-13, 1.83735760e-12, 1.49755734e-09, ...,\n",
       "        1.64256064e-08, 2.82474913e-09, 8.31762159e-18],\n",
       "       [9.99960852e-01, 7.60867554e-08, 3.52279700e-07, ...,\n",
       "        1.52549977e-05, 2.07406439e-06, 9.99997687e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "960a1e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.model_name = 'nezha-cn-base'\n",
    "CFG.tokenizer_path = './prev_trained_model/nezha-cn-base'\n",
    "CFG.model_path = './prev_trained_model/nezha-cn-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaa72010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of NeZhaModel were not initialized from the model checkpoint at ./prev_trained_model/nezha-cn-base and are newly initialized: []\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "431"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[CFG.model_name]\n",
    "    \n",
    "config = config_class.from_pretrained(CFG.model_path)\n",
    "tokenizer = tokenizer_class.from_pretrained(CFG.tokenizer_path)\n",
    "bert_model = model_class.from_pretrained(CFG.model_path, config=config)\n",
    "CFG.tokenizer = tokenizer\n",
    "\n",
    "del tokenizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1344800",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = CFG.device\n",
    "task_name = '_pretrained_6000_2_1.5_1.5_5_shuffle_0.3_fold5_修正数据集'\n",
    "CFG.out_dir = os.path.join('./output', f'nezha-cn-base' + task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b62d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(df, CFG, fold):\n",
    "    pred = np.empty((0,13))\n",
    "    dataset = MyDataset(df)\n",
    "    loader = DataLoader(dataset, batch_size=CFG.batch_size, pin_memory=True)\n",
    "    model = Model(CFG).to(device)\n",
    "    model.eval()\n",
    "    model.load_state_dict(torch.load(f'{CFG.out_dir}/model_{CFG.task}_fold{fold}.pth', map_location='cpu'), strict=False)\n",
    "    for text, feature in tqdm(loader):\n",
    "        text = CFG.tokenizer(text, return_tensors='pt', add_special_tokens=True, padding=True)\n",
    "        for k, v in text.items():\n",
    "            text[k] = v.cuda()\n",
    "        img = feature.cuda()\n",
    "        outputs = model(text, img)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        #print(outputs.shape, outputs)\n",
    "        pred= np.concatenate((pred, outputs.cpu().numpy()))\n",
    "        #print(pred.shape)\n",
    "        #pred = np.stack([pred, outputs.cpu().numpy()])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e2a2be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of NeZhaModel were not initialized from the model checkpoint at ./prev_trained_model/nezha-cn-base and are newly initialized: []\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 20/20 [00:16<00:00,  1.18it/s]\n",
      "Some weights of NeZhaModel were not initialized from the model checkpoint at ./prev_trained_model/nezha-cn-base and are newly initialized: []\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 20/20 [00:08<00:00,  2.30it/s]\n",
      "Some weights of NeZhaModel were not initialized from the model checkpoint at ./prev_trained_model/nezha-cn-base and are newly initialized: []\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.69it/s]\n",
      "Some weights of NeZhaModel were not initialized from the model checkpoint at ./prev_trained_model/nezha-cn-base and are newly initialized: []\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 20/20 [00:08<00:00,  2.32it/s]\n",
      "Some weights of NeZhaModel were not initialized from the model checkpoint at ./prev_trained_model/nezha-cn-base and are newly initialized: []\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 20/20 [00:08<00:00,  2.44it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_nezha = []\n",
    "CFG.folds = 5\n",
    "\n",
    "for fold in range(CFG.folds):\n",
    "    pred_nezha.append(evaluate(df, CFG, fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "292b57c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_nezha = np.mean(pred_nezha, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78a4055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cc = pd.read_csv('./data/pred.csv')\n",
    "pred_cc = pred_cc[['图文', '版型', '裤型', '袖长', '裙长', '领型', '裤门襟', '鞋帮高度', '穿着方式', '衣长', '闭合方式', '裤长', '类别']]\n",
    "pred_cc = pred_cc.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c51290a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_last = np.mean([pred, pred_nezha, pred_cc],  axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f151148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d84d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ddcdf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e5fcd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2128ff3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e31cdaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['pred'] = list(torch.sigmoid(torch.from_numpy(pred)).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf1ef1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred'] = list(pred_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9053c136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>feature</th>\n",
       "      <th>text</th>\n",
       "      <th>querys</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test004000</td>\n",
       "      <td>[-0.044185117, 0.0056368606, 0.113686286, -1.9...</td>\n",
       "      <td>蓝色衬衫2021年秋季长袖童装</td>\n",
       "      <td>[图文, 袖长]</td>\n",
       "      <td>[0.9935616453488668, 0.0002019983049626054, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test004001</td>\n",
       "      <td>[0.09333559, -0.008259959, 0.09762427, -0.2455...</td>\n",
       "      <td>短裤2021年冬季女士休闲裤阔腿裤黑色加厚女装</td>\n",
       "      <td>[图文, 裤型]</td>\n",
       "      <td>[0.0012159751139506618, 0.00017367854506139088...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test004002</td>\n",
       "      <td>[0.29037216, -0.0029620992, 0.020722916, -0.88...</td>\n",
       "      <td>紧身裤短裤男装厚度常规2022年春季运动裤</td>\n",
       "      <td>[图文, 裤型, 裤长]</td>\n",
       "      <td>[3.8624471712694975e-05, 8.689490778788192e-05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test004003</td>\n",
       "      <td>[-0.24379866, -0.008214505, 0.06657183, -0.950...</td>\n",
       "      <td>灰色厚度常规女装2021年春季七分裤女士休闲裤</td>\n",
       "      <td>[图文, 裤长]</td>\n",
       "      <td>[2.5088159061977444e-05, 1.8810140521654298e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test004004</td>\n",
       "      <td>[0.2508675, -0.0061487244, -0.037342805, -0.83...</td>\n",
       "      <td>低帮2021年夏季男士休闲鞋一脚蹬灰色</td>\n",
       "      <td>[图文, 鞋帮高度]</td>\n",
       "      <td>[0.003223230822989491, 8.103681704613931e-05, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     img_name                                            feature  \\\n",
       "0  test004000  [-0.044185117, 0.0056368606, 0.113686286, -1.9...   \n",
       "1  test004001  [0.09333559, -0.008259959, 0.09762427, -0.2455...   \n",
       "2  test004002  [0.29037216, -0.0029620992, 0.020722916, -0.88...   \n",
       "3  test004003  [-0.24379866, -0.008214505, 0.06657183, -0.950...   \n",
       "4  test004004  [0.2508675, -0.0061487244, -0.037342805, -0.83...   \n",
       "\n",
       "                      text        querys  \\\n",
       "0          蓝色衬衫2021年秋季长袖童装      [图文, 袖长]   \n",
       "1  短裤2021年冬季女士休闲裤阔腿裤黑色加厚女装      [图文, 裤型]   \n",
       "2    紧身裤短裤男装厚度常规2022年春季运动裤  [图文, 裤型, 裤长]   \n",
       "3  灰色厚度常规女装2021年春季七分裤女士休闲裤      [图文, 裤长]   \n",
       "4      低帮2021年夏季男士休闲鞋一脚蹬灰色    [图文, 鞋帮高度]   \n",
       "\n",
       "                                                pred  \n",
       "0  [0.9935616453488668, 0.0002019983049626054, 1....  \n",
       "1  [0.0012159751139506618, 0.00017367854506139088...  \n",
       "2  [3.8624471712694975e-05, 8.689490778788192e-05...  \n",
       "3  [2.5088159061977444e-05, 1.8810140521654298e-0...  \n",
       "4  [0.003223230822989491, 8.103681704613931e-05, ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7acae376",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name=['图文','版型', '裤型', '袖长', '裙长', '领型', '裤门襟', '鞋帮高度', '穿着方式', '衣长', '闭合方式', '裤长', '类别']\n",
    "class_dict={'图文': ['符合','不符合'], \n",
    "            '版型': ['修身型', '宽松型', '标准型'], \n",
    "            '裤型': ['微喇裤', '小脚裤', '哈伦裤', '直筒裤', '阔腿裤', '铅笔裤', 'O型裤', '灯笼裤', '锥形裤', '喇叭裤', '工装裤', '背带裤', '紧身裤'],\n",
    "            '袖长': ['长袖', '短袖', '七分袖', '五分袖', '无袖', '九分袖'], \n",
    "            '裙长': ['中长裙', '短裙', '超短裙', '中裙', '长裙'], \n",
    "            '领型': ['半高领', '高领', '翻领', 'POLO领', '立领', '连帽', '娃娃领', 'V领', '圆领', '西装领', '荷叶领', '围巾领', '棒球领', '方领', '可脱卸帽', '衬衫领', 'U型领', '堆堆领', '一字领', '亨利领', '斜领', '双层领'], \n",
    "            '裤门襟': ['系带', '松紧', '拉链'], \n",
    "            '鞋帮高度': ['低帮', '高帮', '中帮'], \n",
    "            '穿着方式': ['套头', '开衫'], \n",
    "            '衣长': ['常规款', '中长款', '长款', '短款', '超短款', '超长款'], \n",
    "            '闭合方式': ['系带', '套脚', '一脚蹬', '松紧带', '魔术贴', '搭扣', '套筒', '拉链'], \n",
    "            '裤长': ['九分裤', '长裤', '五分裤', '七分裤', '短裤'], \n",
    "            '类别': ['单肩包', '斜挎包', '双肩包', '手提包']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f753d440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>feature</th>\n",
       "      <th>text</th>\n",
       "      <th>querys</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test004000</td>\n",
       "      <td>[-0.044185117, 0.0056368606, 0.113686286, -1.9...</td>\n",
       "      <td>蓝色衬衫2021年秋季长袖童装</td>\n",
       "      <td>[图文, 袖长]</td>\n",
       "      <td>[0.9935616453488668, 0.0002019983049626054, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test004001</td>\n",
       "      <td>[0.09333559, -0.008259959, 0.09762427, -0.2455...</td>\n",
       "      <td>短裤2021年冬季女士休闲裤阔腿裤黑色加厚女装</td>\n",
       "      <td>[图文, 裤型]</td>\n",
       "      <td>[0.0012159751139506618, 0.00017367854506139088...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test004002</td>\n",
       "      <td>[0.29037216, -0.0029620992, 0.020722916, -0.88...</td>\n",
       "      <td>紧身裤短裤男装厚度常规2022年春季运动裤</td>\n",
       "      <td>[图文, 裤型, 裤长]</td>\n",
       "      <td>[3.8624471712694975e-05, 8.689490778788192e-05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test004003</td>\n",
       "      <td>[-0.24379866, -0.008214505, 0.06657183, -0.950...</td>\n",
       "      <td>灰色厚度常规女装2021年春季七分裤女士休闲裤</td>\n",
       "      <td>[图文, 裤长]</td>\n",
       "      <td>[2.5088159061977444e-05, 1.8810140521654298e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test004004</td>\n",
       "      <td>[0.2508675, -0.0061487244, -0.037342805, -0.83...</td>\n",
       "      <td>低帮2021年夏季男士休闲鞋一脚蹬灰色</td>\n",
       "      <td>[图文, 鞋帮高度]</td>\n",
       "      <td>[0.003223230822989491, 8.103681704613931e-05, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     img_name                                            feature  \\\n",
       "0  test004000  [-0.044185117, 0.0056368606, 0.113686286, -1.9...   \n",
       "1  test004001  [0.09333559, -0.008259959, 0.09762427, -0.2455...   \n",
       "2  test004002  [0.29037216, -0.0029620992, 0.020722916, -0.88...   \n",
       "3  test004003  [-0.24379866, -0.008214505, 0.06657183, -0.950...   \n",
       "4  test004004  [0.2508675, -0.0061487244, -0.037342805, -0.83...   \n",
       "\n",
       "                      text        querys  \\\n",
       "0          蓝色衬衫2021年秋季长袖童装      [图文, 袖长]   \n",
       "1  短裤2021年冬季女士休闲裤阔腿裤黑色加厚女装      [图文, 裤型]   \n",
       "2    紧身裤短裤男装厚度常规2022年春季运动裤  [图文, 裤型, 裤长]   \n",
       "3  灰色厚度常规女装2021年春季七分裤女士休闲裤      [图文, 裤长]   \n",
       "4      低帮2021年夏季男士休闲鞋一脚蹬灰色    [图文, 鞋帮高度]   \n",
       "\n",
       "                                                pred  \n",
       "0  [0.9935616453488668, 0.0002019983049626054, 1....  \n",
       "1  [0.0012159751139506618, 0.00017367854506139088...  \n",
       "2  [3.8624471712694975e-05, 8.689490778788192e-05...  \n",
       "3  [2.5088159061977444e-05, 1.8810140521654298e-0...  \n",
       "4  [0.003223230822989491, 8.103681704613931e-05, ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3a99c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred_0'] = df['pred'].apply(lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b51f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(x):\n",
    "    query = x['querys']\n",
    "    pre = x['pred']\n",
    "    tmp={}\n",
    "    for que in query:\n",
    "#         if que != '图文':\n",
    "#             tmp[que]=2\n",
    "#             continue\n",
    "        inx=class_name.index(que)\n",
    "        if pre[inx] > Threshold:\n",
    "            #print(pre[inx])\n",
    "            tmp[que]=1\n",
    "        else:\n",
    "            tmp[que]=0\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6677517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold = sorted(list(df['pred_0'].values))[2326]\n",
    "# print(Threshold)\n",
    "Threshold = 0.5\n",
    "df['match'] = df.apply(function, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5851286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def itm_same_as_tuwen(x):\n",
    "    ret = {}\n",
    "    for key, value in x['match'].items():\n",
    "        if key == '图文':\n",
    "            ret[key] = value\n",
    "        elif ret['图文'] and ret['图文'] == 1:\n",
    "            ret[key] = 1\n",
    "        else:\n",
    "            ret[key] = value\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e820c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def itm_same_as_key_attr(x):\n",
    "    ret = {}\n",
    "    for key, value in x['match'].items():\n",
    "        if value == 0:\n",
    "            ret['图文'] = 0\n",
    "        ret[key] = value\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f2e82b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df['itm'] = df['match'].apply(lambda x:x['图文'])\n",
    "# df['match'] = df.apply(itm_same_as_key_attr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80269c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>feature</th>\n",
       "      <th>text</th>\n",
       "      <th>querys</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test004000</td>\n",
       "      <td>[-0.044185117, 0.0056368606, 0.113686286, -1.9...</td>\n",
       "      <td>蓝色衬衫2021年秋季长袖童装</td>\n",
       "      <td>[图文, 袖长]</td>\n",
       "      <td>[0.9935616453488668, 0.0002019983049626054, 1....</td>\n",
       "      <td>0.993562</td>\n",
       "      <td>{'图文': 1, '袖长': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test004001</td>\n",
       "      <td>[0.09333559, -0.008259959, 0.09762427, -0.2455...</td>\n",
       "      <td>短裤2021年冬季女士休闲裤阔腿裤黑色加厚女装</td>\n",
       "      <td>[图文, 裤型]</td>\n",
       "      <td>[0.0012159751139506618, 0.00017367854506139088...</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>{'图文': 0, '裤型': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test004002</td>\n",
       "      <td>[0.29037216, -0.0029620992, 0.020722916, -0.88...</td>\n",
       "      <td>紧身裤短裤男装厚度常规2022年春季运动裤</td>\n",
       "      <td>[图文, 裤型, 裤长]</td>\n",
       "      <td>[3.8624471712694975e-05, 8.689490778788192e-05...</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>{'图文': 0, '裤型': 0, '裤长': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test004003</td>\n",
       "      <td>[-0.24379866, -0.008214505, 0.06657183, -0.950...</td>\n",
       "      <td>灰色厚度常规女装2021年春季七分裤女士休闲裤</td>\n",
       "      <td>[图文, 裤长]</td>\n",
       "      <td>[2.5088159061977444e-05, 1.8810140521654298e-0...</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>{'图文': 0, '裤长': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test004004</td>\n",
       "      <td>[0.2508675, -0.0061487244, -0.037342805, -0.83...</td>\n",
       "      <td>低帮2021年夏季男士休闲鞋一脚蹬灰色</td>\n",
       "      <td>[图文, 鞋帮高度]</td>\n",
       "      <td>[0.003223230822989491, 8.103681704613931e-05, ...</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>{'图文': 0, '鞋帮高度': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     img_name                                            feature  \\\n",
       "0  test004000  [-0.044185117, 0.0056368606, 0.113686286, -1.9...   \n",
       "1  test004001  [0.09333559, -0.008259959, 0.09762427, -0.2455...   \n",
       "2  test004002  [0.29037216, -0.0029620992, 0.020722916, -0.88...   \n",
       "3  test004003  [-0.24379866, -0.008214505, 0.06657183, -0.950...   \n",
       "4  test004004  [0.2508675, -0.0061487244, -0.037342805, -0.83...   \n",
       "\n",
       "                      text        querys  \\\n",
       "0          蓝色衬衫2021年秋季长袖童装      [图文, 袖长]   \n",
       "1  短裤2021年冬季女士休闲裤阔腿裤黑色加厚女装      [图文, 裤型]   \n",
       "2    紧身裤短裤男装厚度常规2022年春季运动裤  [图文, 裤型, 裤长]   \n",
       "3  灰色厚度常规女装2021年春季七分裤女士休闲裤      [图文, 裤长]   \n",
       "4      低帮2021年夏季男士休闲鞋一脚蹬灰色    [图文, 鞋帮高度]   \n",
       "\n",
       "                                                pred    pred_0  \\\n",
       "0  [0.9935616453488668, 0.0002019983049626054, 1....  0.993562   \n",
       "1  [0.0012159751139506618, 0.00017367854506139088...  0.001216   \n",
       "2  [3.8624471712694975e-05, 8.689490778788192e-05...  0.000039   \n",
       "3  [2.5088159061977444e-05, 1.8810140521654298e-0...  0.000025   \n",
       "4  [0.003223230822989491, 8.103681704613931e-05, ...  0.003223   \n",
       "\n",
       "                         match  \n",
       "0           {'图文': 1, '袖长': 1}  \n",
       "1           {'图文': 0, '裤型': 1}  \n",
       "2  {'图文': 0, '裤型': 0, '裤长': 0}  \n",
       "3           {'图文': 0, '裤长': 0}  \n",
       "4         {'图文': 0, '鞋帮高度': 1}  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0bf173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_key0_itm1(x):\n",
    "    for i in x.keys():\n",
    "        if i == '图文' and x[i]==1:\n",
    "            flag = 1\n",
    "        elif i == '图文' and x[i]==0:\n",
    "            flag = 0\n",
    "        else:\n",
    "            if x[i] == 0 and flag == 1:\n",
    "                return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a2a6e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['key0_itm1'] = df['match'].apply(lambda x:count_key0_itm1(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5888a879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9967\n",
       "1      33\n",
       "Name: key0_itm1, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['key0_itm1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d5eb47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_item(x):\n",
    "    ret = {}\n",
    "    for i in x.keys():\n",
    "        if i == '图文' and x[i]==1:\n",
    "            ret['图文'] = 1\n",
    "        elif i == '图文' and x[i]==0:\n",
    "            ret['图文'] = 0\n",
    "        else:\n",
    "            if x[i] == 0 and ret['图文'] == 1:\n",
    "                ret[i] = 1\n",
    "            else:\n",
    "                ret[i] = x[i]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c521b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['match1'] = df['match'].apply(lambda x:image_item(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7af90c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.key0_itm1 == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d772914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit=[]\n",
    "submit_sample={\"img_name\":\"test000255\",\"match\":{\"图文\":0,\"领型\":1,\"袖长\":1,\"穿着方式\":0}}\n",
    "for i, row in df.iterrows():\n",
    "    submit_sample['img_name']=row['img_name']\n",
    "    submit_sample['match']=row['match1']\n",
    "    #print(submit_sample)\n",
    "    submit.append(json.dumps(submit_sample, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24d8b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(CFG.out_dir, 'finally_sub_testb_tuwen_dai_guanjian.txt'), 'w') as f:\n",
    "    f.writelines(submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1dd488d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2325.5999999999995"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4000*(1-0.4186)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a17d1e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./output/nezha-cn-base_pretrained_6000_2_1.5_1.5_5_shuffle_0.3_fold5_修正数据集'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550cb63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "com_envs",
   "language": "python",
   "name": "com_envs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
