{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a53fc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import jieba\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from callback.lr_scheduler import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from callback.progressbar import ProgressBar\n",
    "from callback.adversarial import FGM, PGD\n",
    "from callback.ema import EMA\n",
    "from tools.common import seed_everything\n",
    "from tools.common import init_logger, logger\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from transformers import WEIGHTS_NAME, BertConfig, get_linear_schedule_with_warmup, AdamW, BertTokenizer\n",
    "\n",
    "from models.nezha.modeling_nezha import NeZhaForSequenceClassification, NeZhaModel\n",
    "from models.nezha.configuration_nezha import NeZhaConfig\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6d4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    ## bert ernie bert_wwm bert_wwwm_ext\n",
    "    'bert-base-chinese': (BertConfig, AutoModel, BertTokenizer),\n",
    "    'nezha-cn-base': (NeZhaConfig, NeZhaModel, BertTokenizer),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a803e2",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5300b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFGs:\n",
    "    def __init__(self):\n",
    "        super(CFGs, self).__init__()\n",
    "        \n",
    "        self.data_dir = './data/'\n",
    "        self.out_dir = './output'\n",
    "\n",
    "        self.epochs=100\n",
    "        self.folds = 5\n",
    "\n",
    "        self.task = 'whole' # whole detail\n",
    "        #self.train_file = f'{self.task}.pkl'\n",
    "        self.train_file = f'{self.task}.pkl'\n",
    "        self.model_name = 'nezha-cn-base'\n",
    "        self.tokenizer_path = './prev_trained_model/nezha-cn-base'\n",
    "        self.model_path = './prev_trained_model/bert-base-replace/checkpoint-6000'\n",
    "\n",
    "        self.scheduler='cosine'\n",
    "        self.seed = 42\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.batch_size = 512 #16,32\n",
    "        self.dropout = 0.2\n",
    "        #self.max_len = 40\n",
    "\n",
    "        self.text_dim = 768\n",
    "        self.img_dim = 2048\n",
    "\n",
    "        self.transformer_lr = 2e-5\n",
    "        self.clf_lr = 1e-4\n",
    "\n",
    "        self.weight_decay = 0.01\n",
    "        self.eps=1e-6\n",
    "        self.betas=(0.9, 0.999)\n",
    "        self.num_warmup_steps=0\n",
    "\n",
    "        self.max_norm = 1000\n",
    "        self.num_cycles=0.5\n",
    "        self.patience = 3\n",
    "        \n",
    "        self.do_fgm = False\n",
    "        self.do_pgd = False\n",
    "        self.do_freelb = False\n",
    "        self.do_ema = True\n",
    "\n",
    "        self.log_name = './output'\n",
    "\n",
    "        self.overwrite_output_dir = True\n",
    "        \n",
    "CFG = CFGs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bf7ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16564e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = '_pretrained_6000_2_1.5_1.5_5_shuffle_0.3_fold5_ica'\n",
    "CFG.out_dir = os.path.join(CFG.out_dir, f'{CFG.model_name}' + task_name)\n",
    "if not os.path.exists(CFG.out_dir):\n",
    "    os.makedirs(CFG.out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52da911a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RootLogger root (INFO)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_ = time.strftime(\"%Y-%m-%d-%H:%M:%S\", time.localtime())\n",
    "CFG.log_name = os.path.join(CFG.out_dir, \\\n",
    "                            f'{task_name}_{time_}.log' )\n",
    "\n",
    "init_logger(log_file=CFG.log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f538c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(CFG.out_dir) and os.listdir(CFG.out_dir) and not CFG.overwrite_output_dir:\n",
    "    raise ValueError(\n",
    "        \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
    "            CFG.out_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "146b6262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/30/2022 13:31:49 - INFO - root -   data_dir:./data/\n",
      "out_dir:./output/nezha-cn-base_pretrained_6000_2_1.5_1.5_5_shuffle_0.3_fold5_ica\n",
      "epochs:100\n",
      "folds:5\n",
      "task:whole\n",
      "train_file:whole.pkl\n",
      "model_name:nezha-cn-base\n",
      "tokenizer_path:./prev_trained_model/nezha-cn-base\n",
      "model_path:./prev_trained_model/bert-base-replace/checkpoint-6000\n",
      "scheduler:cosine\n",
      "seed:42\n",
      "device:cuda\n",
      "batch_size:512\n",
      "dropout:0.2\n",
      "text_dim:768\n",
      "img_dim:2048\n",
      "transformer_lr:2e-05\n",
      "clf_lr:0.0001\n",
      "weight_decay:0.01\n",
      "eps:1e-06\n",
      "betas:(0.9, 0.999)\n",
      "num_warmup_steps:0\n",
      "max_norm:1000\n",
      "num_cycles:0.5\n",
      "patience:3\n",
      "do_fgm:False\n",
      "do_pgd:False\n",
      "do_freelb:False\n",
      "do_ema:True\n",
      "log_name:./output/nezha-cn-base_pretrained_6000_2_1.5_1.5_5_shuffle_0.3_fold5_ica/_pretrained_6000_2_1.5_1.5_5_shuffle_0.3_fold5_ica_2022-04-30-13:31:49.log\n",
      "overwrite_output_dir:True\n"
     ]
    }
   ],
   "source": [
    "# 记录训练参数\n",
    "def prn_obj(obj):\n",
    "    logger.info('\\n'.join(['%s:%s' % item for item in obj.__dict__.items()]))\n",
    "    \n",
    "prn_obj(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcc3a948",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa2122e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[CFG.model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5866daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_class.from_pretrained(CFG.tokenizer_path)\n",
    "tokenizer = tokenizer_class.from_pretrained(CFG.tokenizer_path)\n",
    "#bert_model = model_class.from_pretrained(CFG.model_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fe59f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.tokenizer = tokenizer\n",
    "\n",
    "del tokenizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba33c8",
   "metadata": {},
   "source": [
    "# Read In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01811c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [00:22, 2245.95it/s]\n",
      "100000it [00:40, 2494.33it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/train_fine.txt'\n",
    "import json\n",
    "import itertools\n",
    "import re\n",
    "def load_attr_dict(file):\n",
    "    # 读取属性字典\n",
    "    with open(file, 'r') as f:\n",
    "        attr_dict = {}\n",
    "        for attr, attrval_list in json.load(f).items():\n",
    "            attrval_list = list(map(lambda x: x.split('='), attrval_list))\n",
    "            attr_dict[attr] = list(itertools.chain.from_iterable(attrval_list))\n",
    "    return attr_dict\n",
    "\n",
    "attr_dict_file = \"./data/attr_to_attrvals.json\"\n",
    "attr_dict = load_attr_dict(attr_dict_file)\n",
    "\n",
    "def extract_key_attr(title, attr, attr_dict):\n",
    "    # 在title中匹配属性值\n",
    "    if attr == '图文':\n",
    "        return '图文', '符合'\n",
    "    attr_dict1 = attr_dict\n",
    "    attrvals = \"|\".join(attr_dict1[attr])\n",
    "    ret = re.findall(attrvals, title)\n",
    "    if ret:\n",
    "        # 纯色灰色款拉链款加绒裤2021年冬季直筒裤男装\n",
    "        if ret[0] in ['松紧', '拉链', '系带']:\n",
    "            if '裤' in title and attr == '裤门襟':\n",
    "                return attr, ret[0]\n",
    "            elif ('鞋' in title or '靴' in title) and attr == '闭合方式':\n",
    "                return attr, ret[0]\n",
    "            return 'N',''\n",
    "        return attr, ret[0]\n",
    "    else:\n",
    "        return 'N',''\n",
    "\n",
    "\n",
    "def extract_all_key_attr(text):\n",
    "    key_attr = {}\n",
    "    for attr in class_name:\n",
    "        #print(text, attr)\n",
    "        ret_attr, class_label = extract_key_attr(text, attr, attr_dict)\n",
    "        if ret_attr != 'N':\n",
    "            key_attr[ret_attr] = class_label\n",
    "    # 系带进行处理\n",
    "    if not key_attr:\n",
    "        return '无'     \n",
    "    return key_attr #['衣长':'中长款']\n",
    "\n",
    "img_name = []\n",
    "img_features = []\n",
    "texts =[]\n",
    "key_attr = []\n",
    "labels = []\n",
    "class_name = ['图文', '版型', '裤型', '袖长', '裙长', '领型', '裤门襟', '鞋帮高度', '穿着方式', '衣长', '闭合方式', '裤长', '类别']\n",
    "\n",
    "with open(data_dir, 'r') as f:\n",
    "    for data in tqdm(f):\n",
    "        data = json.loads(data)\n",
    "        img_features.append(np.array(data['feature']).astype(np.float32))\n",
    "        img_name.append(data['img_name'])\n",
    "        texts.append(data['title'])\n",
    "        ## 构造标签\n",
    "        match = extract_all_key_attr(data['title'])\n",
    "        key_attr.append(match)\n",
    "        keys = match.keys()\n",
    "        # 图文标签为1\n",
    "        sample_encode = [1]\n",
    "        # 遍历class_name中的其他关键属性\n",
    "        for name in class_name[1:]:\n",
    "            encode = [-1]\n",
    "            if name in keys: #该属性匹配\n",
    "                encode = [1]\n",
    "            sample_encode += encode\n",
    "        # sample_encode为最后的标签\n",
    "        labels.append(sample_encode)\n",
    "\n",
    "coarse_path = './data/train_coarse.txt'\n",
    "with open(coarse_path, 'r') as f:\n",
    "    for data in tqdm(f):\n",
    "        data = json.loads(data)\n",
    "        if data['match']['图文'] == 1:\n",
    "            img_features.append(np.array(data['feature']).astype(np.float32))\n",
    "            img_name.append(data['img_name'])\n",
    "            texts.append(data['title'])\n",
    "            ## 构造标签\n",
    "            match = extract_all_key_attr(data['title'])\n",
    "            key_attr.append(match)\n",
    "            keys = match.keys()\n",
    "            # 图文标签为1\n",
    "            sample_encode = [1]\n",
    "            # 遍历class_name中的其他关键属性\n",
    "            for name in class_name[1:]:\n",
    "                encode = [-1]\n",
    "                if name in keys: #该属性匹配\n",
    "                    encode = [1]\n",
    "                sample_encode += encode\n",
    "            # sample_encode为最后的标签\n",
    "            labels.append(sample_encode)\n",
    "        \n",
    "df = pd.DataFrame(img_name)\n",
    "df['feature'] = img_features\n",
    "df['text'] = texts\n",
    "df['key_attr'] = key_attr\n",
    "df['labels'] = labels\n",
    "df.columns = ['img_name', 'feature', 'text', 'key_attr', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35b50b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139588, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6975f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.img_name != 'train139054']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f8f0eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>feature</th>\n",
       "      <th>text</th>\n",
       "      <th>key_attr</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139583</th>\n",
       "      <td>train089583</td>\n",
       "      <td>[0.3453068, 0.006607449, -0.008650677, 0.12480...</td>\n",
       "      <td>2021年秋季低帮女士休闲鞋纯色系带白色</td>\n",
       "      <td>{'图文': '符合', '鞋帮高度': '低帮', '闭合方式': '系带'}</td>\n",
       "      <td>[1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139584</th>\n",
       "      <td>train089584</td>\n",
       "      <td>[0.5622448, -0.009292278, 0.024309224, 1.10481...</td>\n",
       "      <td>堆堆领2020年秋季女士T恤女装长袖纯色</td>\n",
       "      <td>{'图文': '符合', '袖长': '长袖', '领型': '堆堆领'}</td>\n",
       "      <td>[1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139585</th>\n",
       "      <td>train089585</td>\n",
       "      <td>[0.46319145, -0.022567572, 0.06200119, -0.6101...</td>\n",
       "      <td>常规厚度酒红色格子裤子长裤男装</td>\n",
       "      <td>{'图文': '符合', '裤长': '长裤'}</td>\n",
       "      <td>[1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139586</th>\n",
       "      <td>train089586</td>\n",
       "      <td>[0.2999022, -0.021870004, 0.09405348, -1.24268...</td>\n",
       "      <td>蓝色2021年冬季宽松型吊带常规款纯色女装</td>\n",
       "      <td>{'图文': '符合', '版型': '宽松型', '衣长': '常规款'}</td>\n",
       "      <td>[1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139587</th>\n",
       "      <td>train089587</td>\n",
       "      <td>[-1.3712472, 0.042915933, 0.06434516, -0.51706...</td>\n",
       "      <td>常规厚度男装2021年秋季白色套头高领时尚潮流修身型针织衫</td>\n",
       "      <td>{'图文': '符合', '版型': '修身型', '领型': '高领', '穿着方式': ...</td>\n",
       "      <td>[1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           img_name                                            feature  \\\n",
       "139583  train089583  [0.3453068, 0.006607449, -0.008650677, 0.12480...   \n",
       "139584  train089584  [0.5622448, -0.009292278, 0.024309224, 1.10481...   \n",
       "139585  train089585  [0.46319145, -0.022567572, 0.06200119, -0.6101...   \n",
       "139586  train089586  [0.2999022, -0.021870004, 0.09405348, -1.24268...   \n",
       "139587  train089587  [-1.3712472, 0.042915933, 0.06434516, -0.51706...   \n",
       "\n",
       "                                 text  \\\n",
       "139583           2021年秋季低帮女士休闲鞋纯色系带白色   \n",
       "139584           堆堆领2020年秋季女士T恤女装长袖纯色   \n",
       "139585                常规厚度酒红色格子裤子长裤男装   \n",
       "139586          蓝色2021年冬季宽松型吊带常规款纯色女装   \n",
       "139587  常规厚度男装2021年秋季白色套头高领时尚潮流修身型针织衫   \n",
       "\n",
       "                                                 key_attr  \\\n",
       "139583           {'图文': '符合', '鞋帮高度': '低帮', '闭合方式': '系带'}   \n",
       "139584              {'图文': '符合', '袖长': '长袖', '领型': '堆堆领'}   \n",
       "139585                           {'图文': '符合', '裤长': '长裤'}   \n",
       "139586             {'图文': '符合', '版型': '宽松型', '衣长': '常规款'}   \n",
       "139587  {'图文': '符合', '版型': '修身型', '领型': '高领', '穿着方式': ...   \n",
       "\n",
       "                                                   labels  \n",
       "139583  [1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1]  \n",
       "139584  [1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "139585  [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1,...  \n",
       "139586  [1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1]  \n",
       "139587   [1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(139587, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df.tail())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa6a6e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_feather(CFG.data_dir + 'multi_label/fine.feather')\n",
    "# display(df.head())\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0883bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./data/df_sample_0.1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d142241",
   "metadata": {},
   "source": [
    "# CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbec1b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# kfold = GroupKFold(CFG.folds)\n",
    "# for fold, (trn_id, val_id) in enumerate(kfold.split(df, groups=df['img_name'])):\n",
    "#     df.loc[val_id, 'fold'] = fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b299bdb",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "478529a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class textDataset(Dataset):\n",
    "    def __init__(self, data, index=None):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        #self.set_type = set_type\n",
    "        self.class_name = ['图文', '版型', '裤型', '袖长', '裙长', '领型', '裤门襟', '鞋帮高度', '穿着方式', '衣长', '闭合方式', '裤长', '类别']\n",
    "        self.synonym_dict = {\n",
    "            # 领型\n",
    "            '高领':['半高领', '立领'], '半高领':['高领', '立领'], '立领':['半高领', '高领'],\n",
    "            '连帽':['可脱卸帽'], '可脱卸帽':['连帽'],\n",
    "            '翻领':['衬衫领', 'POLO领', '方领', '娃娃领', '荷叶领'],'衬衫领':['翻领', 'POLO领', '方领', '娃娃领', '荷叶领'],\n",
    "                    'POLO领':['翻领', '衬衫领', '方领', '娃娃领', '荷叶领'],'方领':['翻领', '衬衫领', 'POLO领', '娃娃领', '荷叶领'],\n",
    "                    '娃娃领':['翻领', '衬衫领', 'POLO领', '方领', '荷叶领'], '荷叶领':['翻领', '衬衫领', 'POLO领', '方领', '娃娃领'],\n",
    "            # 袖长\n",
    "            '短袖':['五分袖'], '五分袖':['短袖'],\n",
    "            '九分袖':['长袖'], '长袖':['九分袖'], \n",
    "            # 衣长\n",
    "            '超短款':['短款', '常规款'], '短款':['超短款', '常规款'], '常规款':['超短款', '短款'],\n",
    "            '长款':['超长款'],'超长款':['长款'],\n",
    "            # 版型\n",
    "            '修身型':['标准型'], '标准型':['修身型'],\n",
    "            # 裙长\n",
    "            '短裙': ['超短裙'], '超短裙': ['短裙'],\n",
    "            '中裙':['长裙'],'长裙':['中裙'],\n",
    "            # 裤型\n",
    "            'O型裤':['锥形裤', '哈伦裤', '灯笼裤'], '锥形裤':['O型裤', '哈伦裤', '灯笼裤'],\n",
    "            '哈伦裤':['锥形裤', 'O型裤', '灯笼裤'], '灯笼裤':['锥形裤', '哈伦裤', 'O型裤'],\n",
    "            '铅笔裤':['直筒裤', '小脚裤'], '直筒裤':['铅笔裤', '小脚裤'],  '小脚裤':['直筒裤', '铅笔裤'],\n",
    "            '喇叭裤':['微喇裤'], '微喇裤':['喇叭裤'],\n",
    "            # 裤长\n",
    "            '九分裤':['长裤'], '长裤':['九分裤'],\n",
    "            # 闭合方式\n",
    "            '套筒':['套脚', '一脚蹬'], '套脚':['套筒', '一脚蹬'], '一脚蹬':['套筒', '套脚'],\n",
    "            # 鞋帮高度\n",
    "            '高帮':['中帮'], '中帮':['高帮']  \n",
    "        }\n",
    "        \n",
    "        self.class_dict = {'图文': ['符合','不符合'], \n",
    "            '版型': ['修身型', '宽松型', '标准型'], \n",
    "            '裤型': ['微喇裤', '小脚裤', '哈伦裤', '直筒裤', '阔腿裤', '铅笔裤', 'O型裤', '灯笼裤', '锥形裤', '喇叭裤', '工装裤', '背带裤', '紧身裤'],\n",
    "            '袖长': ['长袖', '短袖', '七分袖', '五分袖', '无袖', '九分袖'], \n",
    "            '裙长': ['中长裙', '短裙', '超短裙', '中裙', '长裙'], \n",
    "            '领型': ['半高领', '高领', '翻领', 'POLO领', '立领', '连帽', '娃娃领', 'V领', '圆领', '西装领', '荷叶领', '围巾领', '棒球领', '方领', '可脱卸帽', '衬衫领', 'U型领', '堆堆领', '一字领', '亨利领', '斜领', '双层领'], \n",
    "            '裤门襟': ['系带', '松紧', '拉链'], \n",
    "            '鞋帮高度': ['低帮', '高帮', '中帮'], \n",
    "            '穿着方式': ['套头', '开衫'], \n",
    "            '衣长': ['常规款', '中长款', '长款', '短款', '超短款', '超长款'], \n",
    "            '闭合方式': ['系带', '套脚', '一脚蹬', '松紧带', '魔术贴', '搭扣', '套筒', '拉链'], \n",
    "            '裤长': ['九分裤', '长裤', '五分裤', '七分裤', '短裤'], \n",
    "            '类别': ['单肩包', '斜挎包', '双肩包', '手提包']\n",
    "            }\n",
    "        \n",
    "        self.kind_dict = {\n",
    "            '衣':['针织衫', '外套', '衬衫', '羽绒服', '吊带', '棉服','T恤',\n",
    "                  '风衣', '仿皮皮衣', '羊毛衫','卫衣', '真皮皮衣', '大衣', 'POLO衫',\n",
    "                  '毛衣', '连衣裙', '打底衫', '雪纺衫', '羊绒衫', '夹克', '皮草', '马甲',\n",
    "                  '派克服', '皮衣', '衬衣','背心','棉衣','套装裙'],\n",
    "            '裤':['牛仔裤', '正装裤', '加绒裤', '休闲裤', '卫裤', '保暖裤', '西装裤', '格子裤子', '运动裤', '垮裤', '西裤', '裙子'],\n",
    "            '鞋':['休闲鞋', '帆布鞋', '登山鞋', '工装鞋', '运动鞋', '篮球鞋', '板鞋', '皮鞋', '靴子', '雨鞋', '布鞋', '高跟鞋', '童鞋', '雪地靴'],\n",
    "        }\n",
    "        self.label_dict = {label:i for i, label in enumerate(class_name)}\n",
    "        for key, value in self.class_dict.items():\n",
    "            for key_attr in value:\n",
    "                jieba.add_word(key_attr)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def get_key_attr_neg_single(self, text, key_attr):\n",
    "        label = [0]*13 # 图文为0\n",
    "        flag = 0\n",
    "        class_name_ = self.class_name[1:].copy()\n",
    "        random.shuffle(class_name_)\n",
    "        for name in class_name_: #self.class_name： ['图文', '版型', '裤型', ]\n",
    "            encode = -1 # 如果该关键属性在文本的关键属性中没有的话，该关键属性标签为-1\n",
    "            keys = list(key_attr.keys())\n",
    "            random.shuffle(keys)\n",
    "            for key in keys: # 匹配该text里面的所有关键属性 # key_attr['图文'：xx, '版型'：xx, '裤型':xx, ]\n",
    "                if key == name:  # 如果和文本的关键属性匹配上，就进行负样本替换\n",
    "                    encode = 1  # 匹配上了，由于下面可能存在不替代该关键词，所有设置标签为1\n",
    "                    if flag == 0:\n",
    "                        val = key_attr[key]  # 匹配上的关键属性的具体取值\n",
    "                        if val in text: # 如果关键属性中的值在文本中，说明\n",
    "                            #属性值在texts中，用另外的值替换掉text中文本,\n",
    "                            tmp = self.class_dict[key]\n",
    "                            tmp_1 = []\n",
    "                            for j in tmp:\n",
    "                                if j != val:\n",
    "                                    tmp_1.append(j)\n",
    "                            # 删除同义词替换为负样本\n",
    "                            if val in self.synonym_dict:\n",
    "                                for synonym in self.synonym_dict[val]:\n",
    "                                    tmp_1.remove(synonym)\n",
    "                            sample = random.choice(tmp_1)\n",
    "                            #print(val,sample)\n",
    "                            text = text.replace(val, sample)\n",
    "                            encode = 0\n",
    "                            flag = 1\n",
    "            label[self.label_dict[name]] = encode\n",
    "        return text, label\n",
    "    \n",
    "    def delete_key_attr_neg_single(self, text, key_attr):\n",
    "        label = [1] + [0]*12 # 图文为0\n",
    "        flag = 0\n",
    "        class_name_ = self.class_name[1:].copy()\n",
    "        random.shuffle(class_name_)\n",
    "        for name in class_name_: #self.class_name： ['图文', '版型', '裤型', ]\n",
    "            encode = -1 # 如果该关键属性在文本的关键属性中没有的话，该关键属性标签为-1\n",
    "            keys = list(key_attr.keys())\n",
    "            random.shuffle(keys)\n",
    "            for key in keys: # 匹配该text里面的所有关键属性 # key_attr['图文'：xx, '版型'：xx, '裤型':xx, ]\n",
    "                if key == name:  # 如果和文本的关键属性匹配上，就进行负样本替换\n",
    "                    encode = 1  # 匹配上了，由于下面可能存在不替代该关键词，所有设置标签为1\n",
    "                    if flag == 0:\n",
    "                        val = key_attr[key]  # 匹配上的关键属性的具体取值\n",
    "                        if val in text: # 如果关键属性中的值在文本中，说明\n",
    "                            #属性值在texts中，用另外的值替换掉text中文本,\n",
    "                            text = ''.join(text.split(val))\n",
    "                            encode = 0\n",
    "                            flag = 1\n",
    "            label[self.label_dict[name]] = encode\n",
    "        return text, label\n",
    "    \n",
    "    def get_key_attr_neg_multi(self, text, key_attr):\n",
    "        label = [0]*13 # 图文为0\n",
    "        flag = 0\n",
    "        class_name_ = self.class_name[1:].copy()\n",
    "        random.shuffle(class_name_)\n",
    "        for name in class_name_: #self.class_name： ['图文', '版型', '裤型', ]\n",
    "            encode = -1 # 如果该关键属性在文本的关键属性中没有的话，该关键属性标签为-1\n",
    "            keys = list(key_attr.keys())\n",
    "            random.shuffle(keys)\n",
    "            for key in keys: # 匹配该text里面的所有关键属性 # key_attr['图文'：xx, '版型'：xx, '裤型':xx, ]\n",
    "                if key == name:  # 如果和文本的关键属性匹配上，就进行负样本替换\n",
    "                    val = key_attr[key]  # 匹配上的关键属性的具体取值\n",
    "                    encode = 1  # 匹配上了，由于下面可能存在不替代该关键词，所有设置标签为1\n",
    "                    if flag == 0:\n",
    "                        if val in text: # 如果关键属性中的值在文本中，说明\n",
    "                            #属性值在texts中，用另外的值替换掉text中文本,\n",
    "                            tmp = self.class_dict[key]\n",
    "                            tmp_1 = []\n",
    "                            for j in tmp:\n",
    "                                if j != val:\n",
    "                                    tmp_1.append(j)\n",
    "                            # 删除同义词替换为负样本\n",
    "                            if val in self.synonym_dict:\n",
    "                                for synonym in self.synonym_dict[val]:\n",
    "                                    tmp_1.remove(synonym)\n",
    "                            sample = random.choice(tmp_1)\n",
    "                            #print(val,sample)\n",
    "                            text = text.replace(val, sample)\n",
    "                            encode = 0\n",
    "                            multi_replace_pro = random.random()\n",
    "                            if multi_replace_pro < 0.3: # 0.3概率不替代了，0.7继续替代\n",
    "                                flag = 1\n",
    "                                \n",
    "            label[self.label_dict[name]] = encode\n",
    "        return text, label\n",
    "    \n",
    "    def get_kinds_neg(self, text, label):\n",
    "        kind_dict_keys = list(self.kind_dict.keys())\n",
    "        random.shuffle(kind_dict_keys)\n",
    "        for key in kind_dict_keys:\n",
    "            for kind in self.kind_dict[key]:\n",
    "                if kind.lower() in text.lower():\n",
    "                    neg = kind.lower()\n",
    "                    while neg == kind.lower():\n",
    "                        neg = random.choice(self.kind_dict[key])\n",
    "                    if random.choice([0, 1]):\n",
    "                        text = text.replace(kind, neg.lower())\n",
    "                        text = text.replace(kind.lower(), neg.lower())\n",
    "\n",
    "                    else:\n",
    "                        text = text.replace(kind, neg)\n",
    "                        text = text.replace(kind.lower(), neg)\n",
    "                    label[0] = 0\n",
    "        return text, label\n",
    "    \n",
    "    def get_synonym_pos(self, text, key_attr):\n",
    "        # 要用的话要改\n",
    "        label = [1] \n",
    "        for name in self.class_name[1:]: #self.class_name： ['图文', '版型', '裤型', ]\n",
    "            encode = [-1] # 如果该关键属性在文本的关键属性中没有的话，该关键属性标签为-1\n",
    "            for key in key_attr.keys(): # 匹配该text里面的所有关键属性 # key_attr['图文'：xx, '版型'：xx, '裤型':xx, ]\n",
    "                if key == name:  # 如果和文本的关键属性匹配上，就进行同义词替换\n",
    "                    val = key_attr[key]  # 匹配上的关键属性的具体取值\n",
    "                    if val in text and val in self.synonym_dict: # 如果关键属性中的值在文本中且有同义词，则进行同义词替换\n",
    "                        tmp_1 = self.synonym_dict[val] # 同义词表\n",
    "                        sample = random.choice(tmp_1)\n",
    "                        text = text.replace(val, sample)\n",
    "                    encode = [1]\n",
    "            label += encode\n",
    "        return text, label\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        label = self.data['labels'][idx].copy()\n",
    "        text = self.data['text'][idx]\n",
    "        key_attr = self.data['key_attr'][idx]\n",
    "        feature = torch.tensor(self.data['feature'][idx]).float()\n",
    "        \n",
    "        # 构造负样本\n",
    "        # 1. kinds替代 2. 关键属性替代\n",
    "        replace_pro = random.random()\n",
    "        # 4:1.5:1.5:2.5\n",
    "            \n",
    "        if replace_pro <= 0.5:\n",
    "            if replace_pro < 0.2:\n",
    "                text, label = self.get_key_attr_neg_single(text, key_attr)\n",
    "            elif replace_pro < 0.35:\n",
    "                text, label = self.get_key_attr_neg_multi(text, key_attr)\n",
    "            else:\n",
    "                text, label = self.get_kinds_neg(text, label)\n",
    "#         else:\n",
    "#             if random.random() <= 0.1:\n",
    "#                 text, label = self.delete_key_attr_neg_single(text, key_attr)\n",
    "        \n",
    "        if random.random() <= 0.3:\n",
    "            text_ = jieba.lcut(text,cut_all=False,HMM=False)\n",
    "            random.shuffle(text_)\n",
    "            text= ''.join(text_)\n",
    "            \n",
    "        return text, feature, np.array(label) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34f7148",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b20c4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.use_deep_res = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3e05808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FuseLayer(nn.Module):\n",
    "#     def __init__(self, text_dim, img_dim, dropout):\n",
    "#         super().__init__()\n",
    "#         self.bn = nn.BatchNorm1d(768*2)\n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Linear(img_dim, text_dim),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(dropout),\n",
    "\n",
    "#         )\n",
    "#         self.fc2 = nn.Sequential(\n",
    "#             nn.Linear(2 * text_dim, text_dim),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(dropout),\n",
    "\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, text, img):\n",
    "#         img = self.fc1(img)\n",
    "        \n",
    "#         concat = torch.cat((img, text),dim=1)\n",
    "#         concat = self.bn(concat)\n",
    "#         fuse = self.fc2(concat)\n",
    "#         return fuse\n",
    "    \n",
    "# class ITM_Model(nn.Module):\n",
    "#     def __init__(self, CFG):\n",
    "#         super().__init__()\n",
    "#         dropout = CFG.dropout\n",
    "#         self.transformer = model_class.from_pretrained(CFG.model_path, config=config)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.fuse = FuseLayer(CFG.text_dim, CFG.img_dim, dropout)\n",
    "#         self.clf = nn.Linear(CFG.text_dim, 2)\n",
    "#         self.clf1 = nn.Sequential(\n",
    "#                     nn.Linear(CFG.text_dim, 256),\n",
    "#                     nn.Linear(256, 64),\n",
    "#                     nn.Linear(64, 13))\n",
    "        \n",
    "#     def forward(self, text, img):\n",
    "#         text = self.transformer(**text)[1]\n",
    "#         text = self.dropout(text)\n",
    "#         fuse = self.fuse(text, img)\n",
    "#         out = self.clf1(fuse)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fedaf6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuseLayer(nn.Module):\n",
    "    def __init__(self, text_dim, img_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm1d(768*2)\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(img_dim, text_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(2 * text_dim, text_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "        )\n",
    "    \n",
    "    def forward(self, text, img):\n",
    "        img = self.fc1(img)\n",
    "        \n",
    "        concat = torch.cat((img, text),dim=1)\n",
    "        concat = self.bn(concat)\n",
    "        fuse = self.fc2(concat)\n",
    "        return fuse\n",
    "    \n",
    "class ITM_Model(nn.Module):\n",
    "    def __init__(self, CFG):\n",
    "        super().__init__()\n",
    "        dropout = CFG.dropout\n",
    "        self.transformer = model_class.from_pretrained(CFG.model_path, config=config)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fuse = FuseLayer(CFG.text_dim, CFG.img_dim, dropout)\n",
    "        self.clf = nn.Linear(CFG.text_dim, 2)\n",
    "        self.clf1 = nn.Sequential(\n",
    "                    nn.Linear(CFG.text_dim, 256),\n",
    "                    nn.Linear(256, 64),\n",
    "                    nn.Linear(64, 13))\n",
    "        self.ICA1 = nn.Sequential(\n",
    "                    nn.Linear(CFG.text_dim, 256),\n",
    "                    nn.BatchNorm1d(256),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.ReLU())\n",
    "        self.ICA2 = nn.Sequential(\n",
    "                    nn.Linear(256, 64),\n",
    "                    nn.BatchNorm1d(64),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.ReLU())\n",
    "            \n",
    "        self.clf2 = nn.Linear(64, 13)\n",
    "        \n",
    "    def ICA(self, deep, input_dim, output_dim):\n",
    "        deep = nn.Linear(input_dim, output_dim)(deep)\n",
    "        deep = nn.BatchNorm1d(output_dim)(deep)\n",
    "        deep = self.dropout(deep)\n",
    "        deep = nn.ReLU(deep)\n",
    "        if CFG.use_deep_res:\n",
    "            deep_res = self.dropout(deep)\n",
    "            deep = torch.add(deep, deep_res)\n",
    "        return deep \n",
    "    \n",
    "    def forward(self, text, img):\n",
    "        text = self.transformer(**text)[1]\n",
    "        text = self.dropout(text)\n",
    "        fuse = self.fuse(text, img)\n",
    "        deep = self.ICA1(fuse)\n",
    "        if CFG.use_deep_res:\n",
    "            deep_res = self.dropout(deep)\n",
    "            deep = torch.add(deep, deep_res)\n",
    "            \n",
    "        deep = self.ICA2(deep)\n",
    "        if CFG.use_deep_res:\n",
    "            deep_res = self.dropout(deep)\n",
    "            deep = torch.add(deep, deep_res)\n",
    "            \n",
    "        out = self.clf2(deep)\n",
    "        #out = self.clf1(fuse)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56c5322",
   "metadata": {},
   "source": [
    "# Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a61d7418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_optimizer(model, CFG):\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.transformer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'lr': CFG.transformer_lr, 'weight_decay': CFG.weight_decay},\n",
    "            {'params': [p for n, p in model.transformer.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'lr': CFG.transformer_lr, 'weight_decay': 0.0},\n",
    "        \n",
    "            {'params': [p for n, p in model.named_parameters() if \"transformer\" not in n and not any(nd in n for nd in no_decay)],\n",
    "             'lr': CFG.clf_lr, 'weight_decay': CFG.weight_decay},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"transformer\" not in n and any(nd in n for nd in no_decay)],\n",
    "             'lr': CFG.clf_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "    optimizer = AdamW(optimizer_parameters, lr=CFG.transformer_lr, eps=CFG.eps, betas=CFG.betas)\n",
    "    return optimizer\n",
    "\n",
    "def get_scheduler(CFG, optimizer, num_train_steps):\n",
    "    if CFG.scheduler=='linear':\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=CFG.num_warmup_steps, num_training_steps=num_train_steps\n",
    "        )\n",
    "    elif CFG.scheduler=='cosine':\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=CFG.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=CFG.num_cycles\n",
    "        )\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8132bc3a",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04841dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(df, CFG):\n",
    "    scores = []\n",
    "    kf = KFold(n_splits=5)\n",
    "    for fold, (trn_idx, val_idx) in enumerate(kf.split(df)):\n",
    "        if fold != 0:\n",
    "            break\n",
    "        logger.info('\\n')\n",
    "        logger.info('='*10 + f'fold:{fold}' +'='*10)\n",
    "        logger.info('\\n')\n",
    "        \n",
    "        train = df.iloc[trn_idx].reset_index(drop=True)\n",
    "        valid = df.iloc[val_idx].reset_index(drop=True)\n",
    "        \n",
    "        logger.info(f'train on {len(train)} samples, valid on {len(valid)} samples')\n",
    "        \n",
    "        logger.info(f'define train_dataset and valid_dataset')\n",
    "        train_dataset, valid_dataset = textDataset(train), textDataset(valid)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, pin_memory=True)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size * 2, shuffle=False,  pin_memory=True)\n",
    "        \n",
    "        logger.info(f'define model')\n",
    "        model = ITM_Model(CFG).to(device)\n",
    "\n",
    "        logger.info(f'define optimizer and scheduler')\n",
    "        optimizer = get_optimizer(model, CFG)\n",
    "        scheduler = get_scheduler(CFG, optimizer, int(len(train) / CFG.batch_size * CFG.epochs))\n",
    "\n",
    "#         criterion = nn.BCEWithLogitsLoss()\n",
    "        criterion = torch.nn.MultiLabelSoftMarginLoss()\n",
    "        #criterion = FocalLoss(num_class=2)\n",
    "        if CFG.do_ema:\n",
    "            ema = EMA(model, 0.999)\n",
    "            ema.register()\n",
    "            \n",
    "        logger.info(f'start training')\n",
    "        \n",
    "        best_acc = 0\n",
    "        best_loss =9999\n",
    "        \n",
    "        for epoch in range(CFG.epochs):\n",
    "            logger.info(f'Epoch:{epoch}')\n",
    "            \n",
    "            text_image_neg_size = 1e-10\n",
    "            text_image_pos_size = 1e-10\n",
    "            text_image_neg_acc = 0\n",
    "            text_image_pos_acc = 0\n",
    "\n",
    "            key_attr_neg_size = 1e-10\n",
    "            key_attr_pos_size = 1e-10\n",
    "            key_attr_neg_acc = 0\n",
    "            key_attr_pos_acc = 0\n",
    "            \n",
    "            model.train()\n",
    "            bar = tqdm(train_loader, total=len(train_loader))\n",
    "            for text, feature, label in bar: # , max_length=CFG.max_len\n",
    "                text = CFG.tokenizer(text, return_tensors='pt', add_special_tokens=True, padding=True)\n",
    "                for k, v in text.items():\n",
    "                    text[k] = v.to(device)\n",
    "                    \n",
    "                img = feature.to(device)\n",
    "                label = label.to(device)\n",
    "\n",
    "                ones = torch.ones(label.shape).cuda()\n",
    "                zeros = torch.zeros(label.shape).cuda()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(text, img).squeeze(1)\n",
    "                loss = criterion(outputs, torch.where(label==1, ones, zeros))\n",
    "                loss.backward()\n",
    "                \n",
    "                nn.utils.clip_grad_norm_(model.parameters(), CFG.max_norm)\n",
    "                \n",
    "                if CFG.do_fgm:\n",
    "                    #model.zero_grad()\n",
    "                    fgm = FGM(model, epsilon=0.2, emb_name='word_embeddings.')\n",
    "                    fgm.attack()\n",
    "                    logits_fgm = model(text, img).squeeze(1)\n",
    "                    loss_adv = criterion(logits_fgm, label)\n",
    "                    loss_adv.backward()\n",
    "                    fgm.restore()\n",
    "                if CFG.do_pgd:\n",
    "                    #model.zero_grad()\n",
    "                    pgd = PGD(model, emb_name='word_embeddings.', epsilon=1.0,alpha=0.3)\n",
    "                    K = 3\n",
    "                    pgd.backup_grad()\n",
    "                    # 对抗训练\n",
    "                    for t in range(K):\n",
    "                        pgd.attack(is_first_attack=(t==0)) # 在embedding上添加对抗扰动, first attack时备份param.data\n",
    "                        if t != K-1:\n",
    "                            model.zero_grad()\n",
    "                        else:\n",
    "                            pgd.restore_grad()\n",
    "                        loss_adv = model(text, img).squeeze(1)\n",
    "                        loss_adv.backward() # 反向传播，并在正常的grad基础上，累加对抗训练的梯度\n",
    "                    pgd.restore() # 恢复embedding参数\n",
    "                    \n",
    "                    \n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                model.zero_grad()\n",
    "                \n",
    "                if CFG.do_ema:\n",
    "                    ema.update()\n",
    "                    \n",
    "                index = (nn.Sigmoid()(outputs) >= 0.5) == label\n",
    "                text_image_neg_size += (label[:, 0] == 0).sum().item()\n",
    "                text_image_pos_size += (label[:, 0] == 1).sum().item()\n",
    "                text_image_neg_acc += (label[:, 0][index[:, 0]] == 0).sum().item()\n",
    "                text_image_pos_acc += (label[:, 0][index[:, 0]] == 1).sum().item()\n",
    "\n",
    "                key_attr_neg_size += (label[:, 1:] == 0).sum().item()\n",
    "                key_attr_pos_size += (label[:, 1:] == 1).sum().item()\n",
    "                key_attr_neg_acc += (label[:, 1:][index[:, 1:]] == 0).sum().item()\n",
    "                key_attr_pos_acc += (label[:, 1:][index[:, 1:]] == 1).sum().item()\n",
    "\n",
    "                text_image_epoch_neg_acc = text_image_neg_acc / text_image_neg_size\n",
    "                text_image_epoch_pos_acc = text_image_pos_acc / text_image_pos_size\n",
    "                text_image_epoch_acc = (text_image_neg_acc + text_image_pos_acc) / (text_image_pos_size + text_image_neg_size)\n",
    "                key_attr_epoch_neg_acc = key_attr_neg_acc / key_attr_neg_size\n",
    "                key_attr_epoch_pos_acc = key_attr_pos_acc / key_attr_pos_size\n",
    "                key_attr_epoch_acc = (key_attr_neg_acc + key_attr_pos_acc) / (key_attr_pos_size + key_attr_neg_size)\n",
    "                epoch_acc = 0.5 * text_image_epoch_acc + 0.5 * key_attr_epoch_acc\n",
    "\n",
    "                bar.set_postfix(Epoch=epoch,\n",
    "                                LR=optimizer.param_groups[0]['lr'], \n",
    "                                Train_acc=epoch_acc, \n",
    "                                text_image_epoch_neg_acc=text_image_epoch_neg_acc,\n",
    "                                text_image_epoch_pos_acc=text_image_epoch_pos_acc,\n",
    "                                text_image_epoch_acc = text_image_epoch_acc,\n",
    "                                key_attr_epoch_neg_acc=key_attr_epoch_neg_acc,\n",
    "                                key_attr_epoch_pos_acc=key_attr_epoch_pos_acc,\n",
    "                                key_attr_epoch_acc = key_attr_epoch_acc,\n",
    "                              )\n",
    "            \n",
    "            if CFG.do_ema:\n",
    "                ema.apply_shadow()\n",
    "                \n",
    "            logger.info(\"***** Train results %s *****\")\n",
    "#             info = f'Train: Epoch_{epoch}_loss: {epoch_loss:.4f}'\n",
    "#             logger.info(info)\n",
    "            \n",
    "            dataset_size = 0\n",
    "            \n",
    "            running_loss = 0\n",
    "            running_acc = 0\n",
    "            neg_acc = 0\n",
    "            pos_acc = 0\n",
    "            neg_size = 1e-10\n",
    "            pos_size = 1e-10\n",
    "            \n",
    "            text_image_neg_size = 1e-10\n",
    "            text_image_pos_size = 1e-10\n",
    "            text_image_neg_acc = 0\n",
    "            text_image_pos_acc = 0\n",
    "\n",
    "            key_attr_neg_size = 1e-10\n",
    "            key_attr_pos_size = 1e-10\n",
    "            key_attr_neg_acc = 0\n",
    "            key_attr_pos_acc = 0\n",
    "            \n",
    "            bar = tqdm(valid_loader, total=len(valid_loader))\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for text, feature, label in bar:# max_len\n",
    "                    text = CFG.tokenizer(text, return_tensors='pt', add_special_tokens=True, padding=True)\n",
    "                    for k, v in text.items():\n",
    "                        text[k] = v.to(device)\n",
    "                    img = feature.to(device)\n",
    "                    label = label.to(device)\n",
    "                    \n",
    "                    ones = torch.ones(label.shape).cuda()\n",
    "                    zeros = torch.zeros(label.shape).cuda()\n",
    "                    \n",
    "                    outputs = model(text, img).squeeze(1)\n",
    "                    loss = criterion(outputs, torch.where(label==1, ones, zeros))\n",
    "\n",
    "                    index = (nn.Sigmoid()(outputs) >= 0.5) == label\n",
    "                    text_image_neg_size += (label[:, 0] == 0).sum().item()\n",
    "                    text_image_pos_size += (label[:, 0] == 1).sum().item()\n",
    "                    text_image_neg_acc += (label[:, 0][index[:, 0]] == 0).sum().item()\n",
    "                    text_image_pos_acc += (label[:, 0][index[:, 0]] == 1).sum().item()\n",
    "\n",
    "                    key_attr_neg_size += (label[:, 1:] == 0).sum().item()\n",
    "                    key_attr_pos_size += (label[:, 1:] == 1).sum().item()\n",
    "                    key_attr_neg_acc += (label[:, 1:][index[:, 1:]] == 0).sum().item()\n",
    "                    key_attr_pos_acc += (label[:, 1:][index[:, 1:]] == 1).sum().item()\n",
    "\n",
    "                    text_image_epoch_neg_acc = text_image_neg_acc / text_image_neg_size\n",
    "                    text_image_epoch_pos_acc = text_image_pos_acc / text_image_pos_size\n",
    "                    text_image_epoch_acc = (text_image_neg_acc + text_image_pos_acc) / (text_image_pos_size + text_image_neg_size)\n",
    "                    key_attr_epoch_neg_acc = key_attr_neg_acc / key_attr_neg_size\n",
    "                    key_attr_epoch_pos_acc = key_attr_pos_acc / key_attr_pos_size\n",
    "                    key_attr_epoch_acc = (key_attr_neg_acc + key_attr_pos_acc) / (key_attr_pos_size + key_attr_neg_size)\n",
    "                    epoch_acc = 0.5 * text_image_epoch_acc + 0.5 * key_attr_epoch_acc\n",
    "\n",
    "                    bar.set_postfix(Epoch=epoch,\n",
    "                                LR=optimizer.param_groups[0]['lr'], \n",
    "                                Train_acc=epoch_acc, \n",
    "                                text_image_epoch_neg_acc=text_image_epoch_neg_acc,\n",
    "                                text_image_epoch_pos_acc=text_image_epoch_pos_acc,\n",
    "                                text_image_epoch_acc = text_image_epoch_acc,\n",
    "                                key_attr_epoch_neg_acc=key_attr_epoch_neg_acc,\n",
    "                                key_attr_epoch_pos_acc=key_attr_epoch_pos_acc,\n",
    "                                key_attr_epoch_acc = key_attr_epoch_acc,\n",
    "                              )\n",
    "            \n",
    "\n",
    "                \n",
    "            logger.info(\"***** Eval results %s *****\")\n",
    "#             info = f'Eval: Epoch_{epoch}_eval_loss: {epoch_loss:.4f}'\n",
    "#             logger.info(info)\n",
    "#             logger.info(f'\\n')\n",
    "            \n",
    "            if epoch_acc > best_acc:\n",
    "                logger.info(f'Weighted_acc improved: best_acc improved from {best_acc} -----> {epoch_acc}')\n",
    "                best_acc = epoch_acc\n",
    "                logger.info(f'\\n')\n",
    "                state_dict = {k: v for k, v in model.state_dict().items() if 'relative_positions' not in k}\n",
    "                torch.save(state_dict, f'{CFG.out_dir}/model_{CFG.task}_fold{fold}.pth')\n",
    "                patience = CFG.patience\n",
    "\n",
    "            else:\n",
    "                patience -= 1\n",
    "                if patience == 0:\n",
    "                    break\n",
    "\n",
    "            if CFG.do_ema:\n",
    "                ema.restore()\n",
    "        scores.append(best_acc)\n",
    "#         del train, valid,train_dataset, valid_dataset,train_loader,valid_loader, model\n",
    "#         gc.collect()\n",
    "#         torch.cuda.empty_cache()\n",
    "    logger.info(f'avg acc:{np.mean(scores)}')\n",
    "    logger.info(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4380b91a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/30/2022 13:32:52 - INFO - root -   \n",
      "\n",
      "04/30/2022 13:32:52 - INFO - root -   ==========fold:0==========\n",
      "04/30/2022 13:32:52 - INFO - root -   \n",
      "\n",
      "04/30/2022 13:32:52 - INFO - root -   train on 111669 samples, valid on 27918 samples\n",
      "04/30/2022 13:32:52 - INFO - root -   define train_dataset and valid_dataset\n",
      "Building prefix dict from the default dictionary ...\n",
      "04/30/2022 13:32:52 - DEBUG - jieba -   Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "04/30/2022 13:32:52 - DEBUG - jieba -   Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.583 seconds.\n",
      "04/30/2022 13:32:53 - DEBUG - jieba -   Loading model cost 0.583 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "04/30/2022 13:32:53 - DEBUG - jieba -   Prefix dict has been built successfully.\n",
      "04/30/2022 13:32:53 - INFO - root -   define model\n",
      "04/30/2022 13:32:53 - INFO - models.nezha.modeling_nezha -   loading weights file ./prev_trained_model/bert-base-replace/checkpoint-6000/pytorch_model.bin\n",
      "04/30/2022 13:32:56 - INFO - models.nezha.modeling_nezha -   All model checkpoint weights were used when initializing NeZhaModel.\n",
      "\n",
      "04/30/2022 13:32:56 - WARNING - models.nezha.modeling_nezha -   Some weights of NeZhaModel were not initialized from the model checkpoint at ./prev_trained_model/bert-base-replace/checkpoint-6000 and are newly initialized: []\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "04/30/2022 13:33:11 - INFO - root -   define optimizer and scheduler\n",
      "04/30/2022 13:33:11 - INFO - root -   start training\n",
      "04/30/2022 13:33:11 - INFO - root -   Epoch:0\n",
      "100%|██████████| 219/219 [03:59<00:00,  1.09s/it, Epoch=0, LR=2e-5, Train_acc=0.719, key_attr_epoch_acc=0.826, key_attr_epoch_neg_acc=0.353, key_attr_epoch_pos_acc=0.952, text_image_epoch_acc=0.611, text_image_epoch_neg_acc=0.55, text_image_epoch_pos_acc=0.669] \n",
      "04/30/2022 13:37:10 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:23<00:00,  1.17it/s, Epoch=0, LR=2e-5, Train_acc=0.452, key_attr_epoch_acc=0.368, key_attr_epoch_neg_acc=0.743, key_attr_epoch_pos_acc=0.266, text_image_epoch_acc=0.536, text_image_epoch_neg_acc=0.62, text_image_epoch_pos_acc=0.452] \n",
      "04/30/2022 13:37:34 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 13:37:34 - INFO - root -   Weighted_acc improved: best_acc improved from 0 -----> 0.4515986142094628\n",
      "04/30/2022 13:37:34 - INFO - root -   \n",
      "\n",
      "04/30/2022 13:37:35 - INFO - root -   Epoch:1\n",
      "100%|██████████| 219/219 [04:02<00:00,  1.11s/it, Epoch=1, LR=2e-5, Train_acc=0.807, key_attr_epoch_acc=0.88, key_attr_epoch_neg_acc=0.591, key_attr_epoch_pos_acc=0.957, text_image_epoch_acc=0.733, text_image_epoch_neg_acc=0.663, text_image_epoch_pos_acc=0.802] \n",
      "04/30/2022 13:41:38 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.12it/s, Epoch=1, LR=2e-5, Train_acc=0.504, key_attr_epoch_acc=0.415, key_attr_epoch_neg_acc=0.626, key_attr_epoch_pos_acc=0.36, text_image_epoch_acc=0.593, text_image_epoch_neg_acc=0.416, text_image_epoch_pos_acc=0.763] \n",
      "04/30/2022 13:42:03 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 13:42:03 - INFO - root -   Weighted_acc improved: best_acc improved from 0.4515986142094628 -----> 0.5039276158306241\n",
      "04/30/2022 13:42:03 - INFO - root -   \n",
      "\n",
      "04/30/2022 13:42:04 - INFO - root -   Epoch:2\n",
      "100%|██████████| 219/219 [04:03<00:00,  1.11s/it, Epoch=2, LR=2e-5, Train_acc=0.839, key_attr_epoch_acc=0.891, key_attr_epoch_neg_acc=0.648, key_attr_epoch_pos_acc=0.955, text_image_epoch_acc=0.788, text_image_epoch_neg_acc=0.727, text_image_epoch_pos_acc=0.846]\n",
      "04/30/2022 13:46:08 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.16it/s, Epoch=2, LR=2e-5, Train_acc=0.582, key_attr_epoch_acc=0.523, key_attr_epoch_neg_acc=0.566, key_attr_epoch_pos_acc=0.512, text_image_epoch_acc=0.641, text_image_epoch_neg_acc=0.406, text_image_epoch_pos_acc=0.87] \n",
      "04/30/2022 13:46:32 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 13:46:32 - INFO - root -   Weighted_acc improved: best_acc improved from 0.5039276158306241 -----> 0.5823397213522484\n",
      "04/30/2022 13:46:32 - INFO - root -   \n",
      "\n",
      "04/30/2022 13:46:34 - INFO - root -   Epoch:3\n",
      "100%|██████████| 219/219 [04:03<00:00,  1.11s/it, Epoch=3, LR=1.99e-5, Train_acc=0.854, key_attr_epoch_acc=0.896, key_attr_epoch_neg_acc=0.676, key_attr_epoch_pos_acc=0.955, text_image_epoch_acc=0.811, text_image_epoch_neg_acc=0.758, text_image_epoch_pos_acc=0.863]\n",
      "04/30/2022 13:50:37 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.16it/s, Epoch=3, LR=1.99e-5, Train_acc=0.661, key_attr_epoch_acc=0.717, key_attr_epoch_neg_acc=0.452, key_attr_epoch_pos_acc=0.788, text_image_epoch_acc=0.606, text_image_epoch_neg_acc=0.22, text_image_epoch_pos_acc=0.985] \n",
      "04/30/2022 13:51:01 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 13:51:01 - INFO - root -   Weighted_acc improved: best_acc improved from 0.5823397213522484 -----> 0.6614841976164217\n",
      "04/30/2022 13:51:01 - INFO - root -   \n",
      "\n",
      "04/30/2022 13:51:03 - INFO - root -   Epoch:4\n",
      "100%|██████████| 219/219 [03:54<00:00,  1.07s/it, Epoch=4, LR=1.99e-5, Train_acc=0.865, key_attr_epoch_acc=0.903, key_attr_epoch_neg_acc=0.7, key_attr_epoch_pos_acc=0.957, text_image_epoch_acc=0.828, text_image_epoch_neg_acc=0.775, text_image_epoch_pos_acc=0.878]  \n",
      "04/30/2022 13:54:58 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:23<00:00,  1.17it/s, Epoch=4, LR=1.99e-5, Train_acc=0.765, key_attr_epoch_acc=0.832, key_attr_epoch_neg_acc=0.38, key_attr_epoch_pos_acc=0.953, text_image_epoch_acc=0.697, text_image_epoch_neg_acc=0.41, text_image_epoch_pos_acc=0.975]  \n",
      "04/30/2022 13:55:22 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 13:55:22 - INFO - root -   Weighted_acc improved: best_acc improved from 0.6614841976164217 -----> 0.7646065500837722\n",
      "04/30/2022 13:55:22 - INFO - root -   \n",
      "\n",
      "04/30/2022 13:55:23 - INFO - root -   Epoch:5\n",
      "100%|██████████| 219/219 [04:00<00:00,  1.10s/it, Epoch=5, LR=1.98e-5, Train_acc=0.871, key_attr_epoch_acc=0.906, key_attr_epoch_neg_acc=0.71, key_attr_epoch_pos_acc=0.959, text_image_epoch_acc=0.835, text_image_epoch_neg_acc=0.782, text_image_epoch_pos_acc=0.887] \n",
      "04/30/2022 13:59:24 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.16it/s, Epoch=5, LR=1.98e-5, Train_acc=0.791, key_attr_epoch_acc=0.861, key_attr_epoch_neg_acc=0.405, key_attr_epoch_pos_acc=0.98, text_image_epoch_acc=0.722, text_image_epoch_neg_acc=0.454, text_image_epoch_pos_acc=0.982] \n",
      "04/30/2022 13:59:48 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 13:59:48 - INFO - root -   Weighted_acc improved: best_acc improved from 0.7646065500837722 -----> 0.7914598935330062\n",
      "04/30/2022 13:59:48 - INFO - root -   \n",
      "\n",
      "04/30/2022 13:59:50 - INFO - root -   Epoch:6\n",
      "100%|██████████| 219/219 [03:59<00:00,  1.09s/it, Epoch=6, LR=1.98e-5, Train_acc=0.879, key_attr_epoch_acc=0.914, key_attr_epoch_neg_acc=0.733, key_attr_epoch_pos_acc=0.962, text_image_epoch_acc=0.843, text_image_epoch_neg_acc=0.793, text_image_epoch_pos_acc=0.892]\n",
      "04/30/2022 14:03:49 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.14it/s, Epoch=6, LR=1.98e-5, Train_acc=0.806, key_attr_epoch_acc=0.872, key_attr_epoch_neg_acc=0.441, key_attr_epoch_pos_acc=0.989, text_image_epoch_acc=0.74, text_image_epoch_neg_acc=0.489, text_image_epoch_pos_acc=0.986] \n",
      "04/30/2022 14:04:14 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 14:04:14 - INFO - root -   Weighted_acc improved: best_acc improved from 0.7914598935330062 -----> 0.8061091782243668\n",
      "04/30/2022 14:04:14 - INFO - root -   \n",
      "\n",
      "04/30/2022 14:04:15 - INFO - root -   Epoch:7\n",
      "100%|██████████| 219/219 [04:00<00:00,  1.10s/it, Epoch=7, LR=1.97e-5, Train_acc=0.888, key_attr_epoch_acc=0.922, key_attr_epoch_neg_acc=0.763, key_attr_epoch_pos_acc=0.965, text_image_epoch_acc=0.854, text_image_epoch_neg_acc=0.802, text_image_epoch_pos_acc=0.903]\n",
      "04/30/2022 14:08:16 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.15it/s, Epoch=7, LR=1.97e-5, Train_acc=0.83, key_attr_epoch_acc=0.886, key_attr_epoch_neg_acc=0.487, key_attr_epoch_pos_acc=0.991, text_image_epoch_acc=0.774, text_image_epoch_neg_acc=0.557, text_image_epoch_pos_acc=0.983] \n",
      "04/30/2022 14:08:40 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 14:08:40 - INFO - root -   Weighted_acc improved: best_acc improved from 0.8061091782243668 -----> 0.8298248006760064\n",
      "04/30/2022 14:08:40 - INFO - root -   \n",
      "\n",
      "04/30/2022 14:08:42 - INFO - root -   Epoch:8\n",
      "100%|██████████| 219/219 [04:02<00:00,  1.11s/it, Epoch=8, LR=1.96e-5, Train_acc=0.895, key_attr_epoch_acc=0.928, key_attr_epoch_neg_acc=0.783, key_attr_epoch_pos_acc=0.966, text_image_epoch_acc=0.863, text_image_epoch_neg_acc=0.817, text_image_epoch_pos_acc=0.907]\n",
      "04/30/2022 14:12:44 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s, Epoch=8, LR=1.96e-5, Train_acc=0.86, key_attr_epoch_acc=0.899, key_attr_epoch_neg_acc=0.575, key_attr_epoch_pos_acc=0.987, text_image_epoch_acc=0.82, text_image_epoch_neg_acc=0.663, text_image_epoch_pos_acc=0.973]  \n",
      "04/30/2022 14:13:09 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 14:13:09 - INFO - root -   Weighted_acc improved: best_acc improved from 0.8298248006760064 -----> 0.8596238132489629\n",
      "04/30/2022 14:13:09 - INFO - root -   \n",
      "\n",
      "04/30/2022 14:13:10 - INFO - root -   Epoch:9\n",
      "100%|██████████| 219/219 [04:04<00:00,  1.11s/it, Epoch=9, LR=1.95e-5, Train_acc=0.9, key_attr_epoch_acc=0.932, key_attr_epoch_neg_acc=0.795, key_attr_epoch_pos_acc=0.968, text_image_epoch_acc=0.869, text_image_epoch_neg_acc=0.823, text_image_epoch_pos_acc=0.914]  \n",
      "04/30/2022 14:17:15 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.16it/s, Epoch=9, LR=1.95e-5, Train_acc=0.864, key_attr_epoch_acc=0.902, key_attr_epoch_neg_acc=0.596, key_attr_epoch_pos_acc=0.983, text_image_epoch_acc=0.825, text_image_epoch_neg_acc=0.679, text_image_epoch_pos_acc=0.966]\n",
      "04/30/2022 14:17:39 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 14:17:39 - INFO - root -   Weighted_acc improved: best_acc improved from 0.8596238132489629 -----> 0.8635477192647346\n",
      "04/30/2022 14:17:39 - INFO - root -   \n",
      "\n",
      "04/30/2022 14:17:40 - INFO - root -   Epoch:10\n",
      "100%|██████████| 219/219 [04:02<00:00,  1.11s/it, Epoch=10, LR=1.94e-5, Train_acc=0.903, key_attr_epoch_acc=0.935, key_attr_epoch_neg_acc=0.807, key_attr_epoch_pos_acc=0.969, text_image_epoch_acc=0.872, text_image_epoch_neg_acc=0.828, text_image_epoch_pos_acc=0.915]\n",
      "04/30/2022 14:21:42 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s, Epoch=10, LR=1.94e-5, Train_acc=0.878, key_attr_epoch_acc=0.913, key_attr_epoch_neg_acc=0.645, key_attr_epoch_pos_acc=0.985, text_image_epoch_acc=0.843, text_image_epoch_neg_acc=0.719, text_image_epoch_pos_acc=0.967]\n",
      "04/30/2022 14:22:07 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 14:22:07 - INFO - root -   Weighted_acc improved: best_acc improved from 0.8635477192647346 -----> 0.8782959157600565\n",
      "04/30/2022 14:22:07 - INFO - root -   \n",
      "\n",
      "04/30/2022 14:22:09 - INFO - root -   Epoch:11\n",
      "100%|██████████| 219/219 [04:02<00:00,  1.11s/it, Epoch=11, LR=1.93e-5, Train_acc=0.908, key_attr_epoch_acc=0.937, key_attr_epoch_neg_acc=0.815, key_attr_epoch_pos_acc=0.97, text_image_epoch_acc=0.879, text_image_epoch_neg_acc=0.837, text_image_epoch_pos_acc=0.919] \n",
      "04/30/2022 14:26:12 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s, Epoch=11, LR=1.93e-5, Train_acc=0.887, key_attr_epoch_acc=0.921, key_attr_epoch_neg_acc=0.678, key_attr_epoch_pos_acc=0.987, text_image_epoch_acc=0.853, text_image_epoch_neg_acc=0.747, text_image_epoch_pos_acc=0.959]\n",
      "04/30/2022 14:26:36 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 14:26:36 - INFO - root -   Weighted_acc improved: best_acc improved from 0.8782959157600565 -----> 0.886926394488128\n",
      "04/30/2022 14:26:36 - INFO - root -   \n",
      "\n",
      "04/30/2022 14:26:38 - INFO - root -   Epoch:12\n",
      "100%|██████████| 219/219 [04:02<00:00,  1.11s/it, Epoch=12, LR=1.92e-5, Train_acc=0.911, key_attr_epoch_acc=0.939, key_attr_epoch_neg_acc=0.821, key_attr_epoch_pos_acc=0.971, text_image_epoch_acc=0.882, text_image_epoch_neg_acc=0.839, text_image_epoch_pos_acc=0.923]\n",
      "04/30/2022 14:30:41 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.15it/s, Epoch=12, LR=1.92e-5, Train_acc=0.893, key_attr_epoch_acc=0.927, key_attr_epoch_neg_acc=0.742, key_attr_epoch_pos_acc=0.976, text_image_epoch_acc=0.859, text_image_epoch_neg_acc=0.775, text_image_epoch_pos_acc=0.941]\n",
      "04/30/2022 14:31:05 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 14:31:05 - INFO - root -   Weighted_acc improved: best_acc improved from 0.886926394488128 -----> 0.8928674641652394\n",
      "04/30/2022 14:31:05 - INFO - root -   \n",
      "\n",
      "04/30/2022 14:31:07 - INFO - root -   Epoch:13\n",
      "100%|██████████| 219/219 [04:01<00:00,  1.10s/it, Epoch=13, LR=1.9e-5, Train_acc=0.914, key_attr_epoch_acc=0.942, key_attr_epoch_neg_acc=0.828, key_attr_epoch_pos_acc=0.973, text_image_epoch_acc=0.886, text_image_epoch_neg_acc=0.842, text_image_epoch_pos_acc=0.927] \n",
      "04/30/2022 14:35:08 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s, Epoch=13, LR=1.9e-5, Train_acc=0.889, key_attr_epoch_acc=0.92, key_attr_epoch_neg_acc=0.75, key_attr_epoch_pos_acc=0.965, text_image_epoch_acc=0.858, text_image_epoch_neg_acc=0.768, text_image_epoch_pos_acc=0.945]  \n",
      "04/30/2022 14:35:33 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 14:35:33 - INFO - root -   Epoch:14\n",
      "100%|██████████| 219/219 [04:02<00:00,  1.11s/it, Epoch=14, LR=1.89e-5, Train_acc=0.915, key_attr_epoch_acc=0.944, key_attr_epoch_neg_acc=0.833, key_attr_epoch_pos_acc=0.974, text_image_epoch_acc=0.887, text_image_epoch_neg_acc=0.845, text_image_epoch_pos_acc=0.928]\n",
      "04/30/2022 14:39:35 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.15it/s, Epoch=14, LR=1.89e-5, Train_acc=0.905, key_attr_epoch_acc=0.935, key_attr_epoch_neg_acc=0.764, key_attr_epoch_pos_acc=0.98, text_image_epoch_acc=0.875, text_image_epoch_neg_acc=0.804, text_image_epoch_pos_acc=0.943] \n",
      "04/30/2022 14:39:59 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 14:39:59 - INFO - root -   Weighted_acc improved: best_acc improved from 0.8928674641652394 -----> 0.9047263514423293\n",
      "04/30/2022 14:39:59 - INFO - root -   \n",
      "\n",
      "04/30/2022 14:40:01 - INFO - root -   Epoch:15\n",
      "100%|██████████| 219/219 [04:02<00:00,  1.11s/it, Epoch=15, LR=1.88e-5, Train_acc=0.919, key_attr_epoch_acc=0.946, key_attr_epoch_neg_acc=0.838, key_attr_epoch_pos_acc=0.975, text_image_epoch_acc=0.891, text_image_epoch_neg_acc=0.849, text_image_epoch_pos_acc=0.931]\n",
      "04/30/2022 14:44:04 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s, Epoch=15, LR=1.88e-5, Train_acc=0.912, key_attr_epoch_acc=0.941, key_attr_epoch_neg_acc=0.769, key_attr_epoch_pos_acc=0.987, text_image_epoch_acc=0.882, text_image_epoch_neg_acc=0.801, text_image_epoch_pos_acc=0.96] \n",
      "04/30/2022 14:44:28 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 14:44:28 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9047263514423293 -----> 0.9117330040943168\n",
      "04/30/2022 14:44:28 - INFO - root -   \n",
      "\n",
      "04/30/2022 14:44:30 - INFO - root -   Epoch:16\n",
      "100%|██████████| 219/219 [04:03<00:00,  1.11s/it, Epoch=16, LR=1.86e-5, Train_acc=0.921, key_attr_epoch_acc=0.947, key_attr_epoch_neg_acc=0.84, key_attr_epoch_pos_acc=0.975, text_image_epoch_acc=0.895, text_image_epoch_neg_acc=0.853, text_image_epoch_pos_acc=0.935] \n",
      "04/30/2022 14:48:33 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:25<00:00,  1.10it/s, Epoch=16, LR=1.86e-5, Train_acc=0.908, key_attr_epoch_acc=0.939, key_attr_epoch_neg_acc=0.788, key_attr_epoch_pos_acc=0.979, text_image_epoch_acc=0.878, text_image_epoch_neg_acc=0.812, text_image_epoch_pos_acc=0.942]\n",
      "04/30/2022 14:48:59 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 14:48:59 - INFO - root -   Epoch:17\n",
      "100%|██████████| 219/219 [04:06<00:00,  1.13s/it, Epoch=17, LR=1.84e-5, Train_acc=0.922, key_attr_epoch_acc=0.949, key_attr_epoch_neg_acc=0.846, key_attr_epoch_pos_acc=0.977, text_image_epoch_acc=0.895, text_image_epoch_neg_acc=0.853, text_image_epoch_pos_acc=0.936]\n",
      "04/30/2022 14:53:06 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.16it/s, Epoch=17, LR=1.84e-5, Train_acc=0.919, key_attr_epoch_acc=0.945, key_attr_epoch_neg_acc=0.792, key_attr_epoch_pos_acc=0.985, text_image_epoch_acc=0.893, text_image_epoch_neg_acc=0.829, text_image_epoch_pos_acc=0.954]\n",
      "04/30/2022 14:53:30 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 14:53:30 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9117330040943168 -----> 0.9190751879789198\n",
      "04/30/2022 14:53:30 - INFO - root -   \n",
      "\n",
      "04/30/2022 14:53:31 - INFO - root -   Epoch:18\n",
      "100%|██████████| 219/219 [04:03<00:00,  1.11s/it, Epoch=18, LR=1.83e-5, Train_acc=0.924, key_attr_epoch_acc=0.95, key_attr_epoch_neg_acc=0.85, key_attr_epoch_pos_acc=0.977, text_image_epoch_acc=0.898, text_image_epoch_neg_acc=0.858, text_image_epoch_pos_acc=0.936] \n",
      "04/30/2022 14:57:35 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:25<00:00,  1.11it/s, Epoch=18, LR=1.83e-5, Train_acc=0.916, key_attr_epoch_acc=0.944, key_attr_epoch_neg_acc=0.803, key_attr_epoch_pos_acc=0.981, text_image_epoch_acc=0.889, text_image_epoch_neg_acc=0.832, text_image_epoch_pos_acc=0.945]\n",
      "04/30/2022 14:58:00 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 14:58:00 - INFO - root -   Epoch:19\n",
      "100%|██████████| 219/219 [04:04<00:00,  1.12s/it, Epoch=19, LR=1.81e-5, Train_acc=0.926, key_attr_epoch_acc=0.952, key_attr_epoch_neg_acc=0.855, key_attr_epoch_pos_acc=0.977, text_image_epoch_acc=0.901, text_image_epoch_neg_acc=0.861, text_image_epoch_pos_acc=0.939]\n",
      "04/30/2022 15:02:05 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.15it/s, Epoch=19, LR=1.81e-5, Train_acc=0.915, key_attr_epoch_acc=0.943, key_attr_epoch_neg_acc=0.81, key_attr_epoch_pos_acc=0.979, text_image_epoch_acc=0.886, text_image_epoch_neg_acc=0.838, text_image_epoch_pos_acc=0.934] \n",
      "04/30/2022 15:02:29 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 15:02:29 - INFO - root -   Epoch:20\n",
      "100%|██████████| 219/219 [04:01<00:00,  1.10s/it, Epoch=20, LR=1.79e-5, Train_acc=0.928, key_attr_epoch_acc=0.952, key_attr_epoch_neg_acc=0.857, key_attr_epoch_pos_acc=0.978, text_image_epoch_acc=0.903, text_image_epoch_neg_acc=0.865, text_image_epoch_pos_acc=0.941]\n",
      "04/30/2022 15:06:30 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s, Epoch=20, LR=1.79e-5, Train_acc=0.921, key_attr_epoch_acc=0.948, key_attr_epoch_neg_acc=0.826, key_attr_epoch_pos_acc=0.98, text_image_epoch_acc=0.893, text_image_epoch_neg_acc=0.844, text_image_epoch_pos_acc=0.941] \n",
      "04/30/2022 15:06:55 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 15:06:55 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9190751879789198 -----> 0.920594897969335\n",
      "04/30/2022 15:06:55 - INFO - root -   \n",
      "\n",
      "04/30/2022 15:06:56 - INFO - root -   Epoch:21\n",
      "100%|██████████| 219/219 [04:06<00:00,  1.13s/it, Epoch=21, LR=1.77e-5, Train_acc=0.929, key_attr_epoch_acc=0.954, key_attr_epoch_neg_acc=0.862, key_attr_epoch_pos_acc=0.978, text_image_epoch_acc=0.904, text_image_epoch_neg_acc=0.866, text_image_epoch_pos_acc=0.941]\n",
      "04/30/2022 15:11:03 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s, Epoch=21, LR=1.77e-5, Train_acc=0.925, key_attr_epoch_acc=0.95, key_attr_epoch_neg_acc=0.824, key_attr_epoch_pos_acc=0.984, text_image_epoch_acc=0.899, text_image_epoch_neg_acc=0.85, text_image_epoch_pos_acc=0.948]  \n",
      "04/30/2022 15:11:28 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 15:11:28 - INFO - root -   Weighted_acc improved: best_acc improved from 0.920594897969335 -----> 0.9246877935182334\n",
      "04/30/2022 15:11:28 - INFO - root -   \n",
      "\n",
      "04/30/2022 15:11:29 - INFO - root -   Epoch:22\n",
      "100%|██████████| 219/219 [04:02<00:00,  1.11s/it, Epoch=22, LR=1.75e-5, Train_acc=0.931, key_attr_epoch_acc=0.955, key_attr_epoch_neg_acc=0.862, key_attr_epoch_pos_acc=0.979, text_image_epoch_acc=0.906, text_image_epoch_neg_acc=0.868, text_image_epoch_pos_acc=0.943]\n",
      "04/30/2022 15:15:32 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s, Epoch=22, LR=1.75e-5, Train_acc=0.925, key_attr_epoch_acc=0.951, key_attr_epoch_neg_acc=0.841, key_attr_epoch_pos_acc=0.981, text_image_epoch_acc=0.899, text_image_epoch_neg_acc=0.866, text_image_epoch_pos_acc=0.932]\n",
      "04/30/2022 15:15:57 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 15:15:57 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9246877935182334 -----> 0.9251735801581622\n",
      "04/30/2022 15:15:57 - INFO - root -   \n",
      "\n",
      "04/30/2022 15:15:59 - INFO - root -   Epoch:23\n",
      "100%|██████████| 219/219 [04:04<00:00,  1.12s/it, Epoch=23, LR=1.73e-5, Train_acc=0.933, key_attr_epoch_acc=0.956, key_attr_epoch_neg_acc=0.868, key_attr_epoch_pos_acc=0.98, text_image_epoch_acc=0.91, text_image_epoch_neg_acc=0.871, text_image_epoch_pos_acc=0.947]  \n",
      "04/30/2022 15:20:03 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:25<00:00,  1.12it/s, Epoch=23, LR=1.73e-5, Train_acc=0.922, key_attr_epoch_acc=0.948, key_attr_epoch_neg_acc=0.837, key_attr_epoch_pos_acc=0.979, text_image_epoch_acc=0.896, text_image_epoch_neg_acc=0.854, text_image_epoch_pos_acc=0.937]\n",
      "04/30/2022 15:20:28 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 15:20:28 - INFO - root -   Epoch:24\n",
      "100%|██████████| 219/219 [04:03<00:00,  1.11s/it, Epoch=24, LR=1.7e-5, Train_acc=0.933, key_attr_epoch_acc=0.957, key_attr_epoch_neg_acc=0.869, key_attr_epoch_pos_acc=0.98, text_image_epoch_acc=0.91, text_image_epoch_neg_acc=0.872, text_image_epoch_pos_acc=0.947]  \n",
      "04/30/2022 15:24:31 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.15it/s, Epoch=24, LR=1.7e-5, Train_acc=0.926, key_attr_epoch_acc=0.951, key_attr_epoch_neg_acc=0.848, key_attr_epoch_pos_acc=0.979, text_image_epoch_acc=0.902, text_image_epoch_neg_acc=0.87, text_image_epoch_pos_acc=0.933] \n",
      "04/30/2022 15:24:56 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 15:24:56 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9251735801581622 -----> 0.9262898461726716\n",
      "04/30/2022 15:24:56 - INFO - root -   \n",
      "\n",
      "04/30/2022 15:24:57 - INFO - root -   Epoch:25\n",
      "100%|██████████| 219/219 [04:03<00:00,  1.11s/it, Epoch=25, LR=1.68e-5, Train_acc=0.936, key_attr_epoch_acc=0.958, key_attr_epoch_neg_acc=0.875, key_attr_epoch_pos_acc=0.981, text_image_epoch_acc=0.913, text_image_epoch_neg_acc=0.875, text_image_epoch_pos_acc=0.95] \n",
      "04/30/2022 15:29:01 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.13it/s, Epoch=25, LR=1.68e-5, Train_acc=0.93, key_attr_epoch_acc=0.954, key_attr_epoch_neg_acc=0.854, key_attr_epoch_pos_acc=0.981, text_image_epoch_acc=0.906, text_image_epoch_neg_acc=0.875, text_image_epoch_pos_acc=0.937] \n",
      "04/30/2022 15:29:25 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 15:29:25 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9262898461726716 -----> 0.9301408489096845\n",
      "04/30/2022 15:29:25 - INFO - root -   \n",
      "\n",
      "04/30/2022 15:29:27 - INFO - root -   Epoch:26\n",
      "100%|██████████| 219/219 [04:03<00:00,  1.11s/it, Epoch=26, LR=1.66e-5, Train_acc=0.936, key_attr_epoch_acc=0.959, key_attr_epoch_neg_acc=0.875, key_attr_epoch_pos_acc=0.981, text_image_epoch_acc=0.913, text_image_epoch_neg_acc=0.875, text_image_epoch_pos_acc=0.95] \n",
      "04/30/2022 15:33:30 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.15it/s, Epoch=26, LR=1.66e-5, Train_acc=0.932, key_attr_epoch_acc=0.955, key_attr_epoch_neg_acc=0.862, key_attr_epoch_pos_acc=0.98, text_image_epoch_acc=0.909, text_image_epoch_neg_acc=0.885, text_image_epoch_pos_acc=0.932] \n",
      "04/30/2022 15:33:54 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 15:33:54 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9301408489096845 -----> 0.9320594029398275\n",
      "04/30/2022 15:33:54 - INFO - root -   \n",
      "\n",
      "04/30/2022 15:33:56 - INFO - root -   Epoch:27\n",
      "100%|██████████| 219/219 [04:04<00:00,  1.12s/it, Epoch=27, LR=1.63e-5, Train_acc=0.937, key_attr_epoch_acc=0.96, key_attr_epoch_neg_acc=0.878, key_attr_epoch_pos_acc=0.982, text_image_epoch_acc=0.914, text_image_epoch_neg_acc=0.875, text_image_epoch_pos_acc=0.951] \n",
      "04/30/2022 15:38:01 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:25<00:00,  1.12it/s, Epoch=27, LR=1.63e-5, Train_acc=0.93, key_attr_epoch_acc=0.954, key_attr_epoch_neg_acc=0.863, key_attr_epoch_pos_acc=0.979, text_image_epoch_acc=0.906, text_image_epoch_neg_acc=0.873, text_image_epoch_pos_acc=0.939] \n",
      "04/30/2022 15:38:26 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 15:38:26 - INFO - root -   Epoch:28\n",
      "100%|██████████| 219/219 [04:02<00:00,  1.11s/it, Epoch=28, LR=1.61e-5, Train_acc=0.939, key_attr_epoch_acc=0.961, key_attr_epoch_neg_acc=0.882, key_attr_epoch_pos_acc=0.982, text_image_epoch_acc=0.917, text_image_epoch_neg_acc=0.879, text_image_epoch_pos_acc=0.953]\n",
      "04/30/2022 15:42:28 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.14it/s, Epoch=28, LR=1.61e-5, Train_acc=0.93, key_attr_epoch_acc=0.954, key_attr_epoch_neg_acc=0.862, key_attr_epoch_pos_acc=0.978, text_image_epoch_acc=0.907, text_image_epoch_neg_acc=0.876, text_image_epoch_pos_acc=0.937] \n",
      "04/30/2022 15:42:53 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 15:42:53 - INFO - root -   Epoch:29\n",
      "100%|██████████| 219/219 [04:00<00:00,  1.10s/it, Epoch=29, LR=1.58e-5, Train_acc=0.939, key_attr_epoch_acc=0.961, key_attr_epoch_neg_acc=0.883, key_attr_epoch_pos_acc=0.983, text_image_epoch_acc=0.917, text_image_epoch_neg_acc=0.879, text_image_epoch_pos_acc=0.955]\n",
      "04/30/2022 15:46:53 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 28/28 [00:24<00:00,  1.15it/s, Epoch=29, LR=1.58e-5, Train_acc=0.926, key_attr_epoch_acc=0.95, key_attr_epoch_neg_acc=0.871, key_attr_epoch_pos_acc=0.972, text_image_epoch_acc=0.903, text_image_epoch_neg_acc=0.883, text_image_epoch_pos_acc=0.922] \n",
      "04/30/2022 15:47:17 - INFO - root -   ***** Eval results %s *****\n",
      "04/30/2022 15:47:17 - INFO - root -   avg acc:0.9320594029398275\n",
      "04/30/2022 15:47:17 - INFO - root -   [0.9320594029398275]\n"
     ]
    }
   ],
   "source": [
    "device = CFG.device\n",
    "run(df, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6b07d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn((2,3, 2))\n",
    "b = torch.randn((2,3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b868900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_shape = a.size()[:-1]\n",
    "b_shape = b.size()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10d6f1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d72ba414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "494001c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2]), torch.Size([2]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_shape , b_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a8c891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "com_envs",
   "language": "python",
   "name": "com_envs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
