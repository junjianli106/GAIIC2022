{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22189bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import jieba\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from callback.lr_scheduler import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from callback.progressbar import ProgressBar\n",
    "from callback.adversarial import FGM, PGD\n",
    "from callback.ema import EMA\n",
    "from tools.common import seed_everything\n",
    "from tools.common import init_logger, logger\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, VisualBertModel\n",
    "from transformers import WEIGHTS_NAME, BertConfig, get_linear_schedule_with_warmup, AdamW, BertTokenizer\n",
    "\n",
    "from models.nezha.modeling_nezha import NeZhaForSequenceClassification, NeZhaModel\n",
    "from models.nezha.configuration_nezha import NeZhaConfig\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67957b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 支持多分类和二分类\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    This is a implementation of Focal Loss with smooth label cross entropy supported which is proposed in\n",
    "    'Focal Loss for Dense Object Detection. (https://arxiv.org/abs/1708.02002)'\n",
    "    Focal_Loss= -1*alpha*(1-pt)^gamma*log(pt)\n",
    "    :param num_class:\n",
    "    :param alpha: (tensor) 3D or 4D the scalar factor for this criterion\n",
    "    :param gamma: (float,double) gamma > 0 reduces the relative loss\n",
    "    for well-classified examples (p>0.5) putting more\n",
    "    focus on hard misclassified example\n",
    "    :param smooth: (float,double) smooth value when cross entropy\n",
    "    :param balance_index: (int) balance class index,\n",
    "    should be specific when alpha is float\n",
    "    :param size_average: (bool, optional) By default,\n",
    "    the losses are averaged over each loss element in the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_class, alpha=None, gamma=2,\n",
    "                smooth=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.smooth = smooth\n",
    "        self.size_average = size_average\n",
    "\n",
    "        if self.alpha is None:\n",
    "            self.alpha = torch.ones(self.num_class, 1)\n",
    "        elif isinstance(self.alpha, (list, np.ndarray)):\n",
    "            assert len(self.alpha) == self.num_class\n",
    "            self.alpha = torch.FloatTensor(alpha).view(self.num_class, 1)\n",
    "            self.alpha = self.alpha / self.alpha.sum()\n",
    "        else:\n",
    "            raise TypeError('Not support alpha type')\n",
    "        if self.smooth is not None:\n",
    "            if self.smooth < 0 or self.smooth > 1.0:\n",
    "                raise ValueError('smooth value should be in [0,1]')\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logit = F.softmax(input, dim=1)\n",
    "\n",
    "        if logit.dim() > 2:\n",
    "            # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n",
    "            logit = logit.view(logit.size(0), logit.size(1), -1)\n",
    "            logit = logit.permute(0, 2, 1).contiguous()\n",
    "            logit = logit.view(-1, logit.size(-1))\n",
    "        target = target.view(-1, 1)\n",
    "\n",
    "        # N = input.size(0)\n",
    "        # alpha = torch.ones(N, self.num_class)\n",
    "        # alpha = alpha * (1 - self.alpha)\n",
    "        # alpha = alpha.scatter_(1, target.long(), self.alpha)\n",
    "        epsilon = 1e-10\n",
    "        alpha = self.alpha\n",
    "        if alpha.device != input.device:\n",
    "            alpha = alpha.to(input.device)\n",
    "\n",
    "        idx = target.cpu().long()\n",
    "        one_hot_key = torch.FloatTensor(target.size(0), self.num_class).zero_()\n",
    "        one_hot_key = one_hot_key.scatter_(1, idx, 1)\n",
    "        if one_hot_key.device != logit.device:\n",
    "            one_hot_key = one_hot_key.to(logit.device)\n",
    "\n",
    "        if self.smooth:\n",
    "            one_hot_key = torch.clamp(\n",
    "                one_hot_key, self.smooth, 1.0 - self.smooth)\n",
    "        pt = (one_hot_key * logit).sum(1) + epsilon\n",
    "        logpt = pt.log()\n",
    "\n",
    "        gamma = self.gamma\n",
    "\n",
    "        alpha = alpha[idx]\n",
    "        loss = -1 * alpha * torch.pow((1 - pt), gamma) * logpt\n",
    "\n",
    "        if self.size_average:\n",
    "            loss = loss.mean()\n",
    "        else:\n",
    "            loss = loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d494fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    ## bert ernie bert_wwm bert_wwwm_ext\n",
    "    'bert-base-chinese': (BertConfig, AutoModel, BertTokenizer),\n",
    "    'nezha-cn-base': (NeZhaConfig, NeZhaModel, BertTokenizer),\n",
    "    'nezha-base-wwm': (NeZhaConfig, NeZhaModel, BertTokenizer),\n",
    "    'visualbert':(BertConfig, VisualBertModel, BertTokenizer),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d539cfe5",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ed9d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFGs:\n",
    "    def __init__(self):\n",
    "        super(CFGs, self).__init__()\n",
    "        \n",
    "        self.data_dir = './data/'\n",
    "        self.out_dir = './output'\n",
    "\n",
    "        self.epochs=100\n",
    "        self.folds = 5\n",
    "\n",
    "        self.task = 'whole' # whole detail\n",
    "        #self.train_file = f'{self.task}.pkl'\n",
    "        self.train_file = f'{self.task}.pkl'\n",
    "        self.model_name = 'visualbert'\n",
    "        self.tokenizer_path = './prev_trained_model/VisualBert/'\n",
    "        self.model_path = './prev_trained_model/visualbert_1/'\n",
    "\n",
    "        self.scheduler='cosine'\n",
    "        self.seed = 42\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.batch_size = 128 #16,32\n",
    "        self.dropout = 0.2\n",
    "        #self.max_len = 40\n",
    "\n",
    "        self.text_dim = 768\n",
    "        self.img_dim = 2048\n",
    "\n",
    "        self.transformer_lr = 2e-5\n",
    "        self.clf_lr = 1e-4\n",
    "\n",
    "        self.weight_decay = 0.01\n",
    "        self.eps=1e-6\n",
    "        self.betas=(0.9, 0.999)\n",
    "        self.num_warmup_steps=0\n",
    "\n",
    "        self.max_norm = 1000\n",
    "        self.num_cycles=0.5\n",
    "        self.patience = 3\n",
    "        \n",
    "        self.do_fgm = False\n",
    "        self.do_pgd = False\n",
    "        self.do_freelb = False\n",
    "        self.do_ema = True\n",
    "\n",
    "        self.log_name = './output'\n",
    "\n",
    "        self.overwrite_output_dir = True\n",
    "        \n",
    "CFG = CFGs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7cd09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85012330",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'all_data'\n",
    "CFG.out_dir = os.path.join(CFG.out_dir, f'{CFG.model_name}' + task_name)\n",
    "if not os.path.exists(CFG.out_dir):\n",
    "    os.makedirs(CFG.out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69294871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RootLogger root (INFO)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_ = time.strftime(\"%Y-%m-%d-%H:%M:%S\", time.localtime())\n",
    "CFG.log_name = os.path.join(CFG.out_dir, \\\n",
    "                            f'{task_name}_{time_}.log' )\n",
    "\n",
    "init_logger(log_file=CFG.log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0884847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(CFG.out_dir) and os.listdir(CFG.out_dir) and not CFG.overwrite_output_dir:\n",
    "    raise ValueError(\n",
    "        \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
    "            CFG.out_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3cc340f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2022 15:29:53 - INFO - root -   data_dir:./data/\n",
      "out_dir:./output/visualbertall_data\n",
      "epochs:100\n",
      "folds:5\n",
      "task:whole\n",
      "train_file:whole.pkl\n",
      "model_name:visualbert\n",
      "tokenizer_path:./prev_trained_model/VisualBert/\n",
      "model_path:./prev_trained_model/visualbert_1/\n",
      "scheduler:cosine\n",
      "seed:42\n",
      "device:cuda\n",
      "batch_size:128\n",
      "dropout:0.2\n",
      "text_dim:768\n",
      "img_dim:2048\n",
      "transformer_lr:2e-05\n",
      "clf_lr:0.0001\n",
      "weight_decay:0.01\n",
      "eps:1e-06\n",
      "betas:(0.9, 0.999)\n",
      "num_warmup_steps:0\n",
      "max_norm:1000\n",
      "num_cycles:0.5\n",
      "patience:3\n",
      "do_fgm:False\n",
      "do_pgd:False\n",
      "do_freelb:False\n",
      "do_ema:True\n",
      "log_name:./output/visualbertall_data/all_data_2022-05-04-15:29:53.log\n",
      "overwrite_output_dir:True\n"
     ]
    }
   ],
   "source": [
    "# 记录训练参数\n",
    "def prn_obj(obj):\n",
    "    logger.info('\\n'.join(['%s:%s' % item for item in obj.__dict__.items()]))\n",
    "    \n",
    "prn_obj(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee49edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aac4e7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[CFG.model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db023014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type visual_bert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "config = config_class.from_pretrained(CFG.tokenizer_path)\n",
    "tokenizer = tokenizer_class.from_pretrained(CFG.tokenizer_path)\n",
    "#bert_model = model_class.from_pretrained(CFG.model_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11dbe3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.tokenizer = tokenizer\n",
    "\n",
    "del tokenizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa345a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "015269c9",
   "metadata": {},
   "source": [
    "# Read In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5e1fc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [00:23, 2095.21it/s]\n",
      "100000it [00:43, 2287.60it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/train_fine.txt'\n",
    "import json\n",
    "import itertools\n",
    "import re\n",
    "def load_attr_dict(file):\n",
    "    # 读取属性字典\n",
    "    with open(file, 'r') as f:\n",
    "        attr_dict = {}\n",
    "        for attr, attrval_list in json.load(f).items():\n",
    "            attrval_list = list(map(lambda x: x.split('='), attrval_list))\n",
    "            attr_dict[attr] = list(itertools.chain.from_iterable(attrval_list))\n",
    "    return attr_dict\n",
    "\n",
    "attr_dict_file = \"./data/attr_to_attrvals.json\"\n",
    "attr_dict = load_attr_dict(attr_dict_file)\n",
    "\n",
    "def extract_key_attr(title, attr, attr_dict):\n",
    "    # 在title中匹配属性值\n",
    "    if attr == '图文':\n",
    "        return '图文', '符合'\n",
    "    attr_dict1 = attr_dict\n",
    "    attrvals = \"|\".join(attr_dict1[attr])\n",
    "    ret = re.findall(attrvals, title)\n",
    "    if ret:\n",
    "        # 纯色灰色款拉链款加绒裤2021年冬季直筒裤男装\n",
    "        if ret[0] in ['松紧', '拉链', '系带']:\n",
    "            if '裤' in title and attr == '裤门襟':\n",
    "                return attr, ret[0]\n",
    "            elif ('鞋' in title or '靴' in title) and attr == '闭合方式':\n",
    "                return attr, ret[0]\n",
    "            return 'N',''\n",
    "        return attr, ret[0]\n",
    "    else:\n",
    "        return 'N',''\n",
    "\n",
    "\n",
    "def extract_all_key_attr(text):\n",
    "    key_attr = {}\n",
    "    for attr in class_name:\n",
    "        #print(text, attr)\n",
    "        ret_attr, class_label = extract_key_attr(text, attr, attr_dict)\n",
    "        if ret_attr != 'N':\n",
    "            key_attr[ret_attr] = class_label\n",
    "    # 系带进行处理\n",
    "    if not key_attr:\n",
    "        return '无'     \n",
    "    return key_attr #['衣长':'中长款']\n",
    "\n",
    "img_name = []\n",
    "img_features = []\n",
    "texts =[]\n",
    "key_attr = []\n",
    "labels = []\n",
    "class_name = ['图文', '版型', '裤型', '袖长', '裙长', '领型', '裤门襟', '鞋帮高度', '穿着方式', '衣长', '闭合方式', '裤长', '类别']\n",
    "\n",
    "with open(data_dir, 'r') as f:\n",
    "    for data in tqdm(f):\n",
    "        data = json.loads(data)\n",
    "        img_features.append(np.array(data['feature']).astype(np.float32))\n",
    "        img_name.append(data['img_name'])\n",
    "        texts.append(data['title'])\n",
    "        ## 构造标签\n",
    "        match = extract_all_key_attr(data['title'])\n",
    "        key_attr.append(match)\n",
    "        keys = match.keys()\n",
    "        # 图文标签为1\n",
    "        sample_encode = [1]\n",
    "        # 遍历class_name中的其他关键属性\n",
    "        for name in class_name[1:]:\n",
    "            encode = [-1]\n",
    "            if name in keys: #该属性匹配\n",
    "                encode = [1]\n",
    "            sample_encode += encode\n",
    "        # sample_encode为最后的标签\n",
    "        labels.append(sample_encode)\n",
    "\n",
    "coarse_path = './data/train_coarse.txt'\n",
    "with open(coarse_path, 'r') as f:\n",
    "    for data in tqdm(f):\n",
    "        data = json.loads(data)\n",
    "        if data['match']['图文'] == 1:\n",
    "            img_features.append(np.array(data['feature']).astype(np.float32))\n",
    "            img_name.append(data['img_name'])\n",
    "            texts.append(data['title'])\n",
    "            ## 构造标签\n",
    "            match = extract_all_key_attr(data['title'])\n",
    "            key_attr.append(match)\n",
    "            keys = match.keys()\n",
    "            # 图文标签为1\n",
    "            sample_encode = [1]\n",
    "            # 遍历class_name中的其他关键属性\n",
    "            for name in class_name[1:]:\n",
    "                encode = [-1]\n",
    "                if name in keys: #该属性匹配\n",
    "                    encode = [1]\n",
    "                sample_encode += encode\n",
    "            # sample_encode为最后的标签\n",
    "            labels.append(sample_encode)\n",
    "        \n",
    "df = pd.DataFrame(img_name)\n",
    "df['feature'] = img_features\n",
    "df['text'] = texts\n",
    "df['key_attr'] = key_attr\n",
    "df['labels'] = labels\n",
    "df.columns = ['img_name', 'feature', 'text', 'key_attr', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdc3215d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139588, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "682eddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.img_name != 'train139054'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bb0ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x:x.replace('小吊带', '吊带衫'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64021af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>feature</th>\n",
       "      <th>text</th>\n",
       "      <th>key_attr</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139582</th>\n",
       "      <td>train089583</td>\n",
       "      <td>[0.3453068, 0.006607449, -0.008650677, 0.12480...</td>\n",
       "      <td>2021年秋季低帮女士休闲鞋纯色系带白色</td>\n",
       "      <td>{'图文': '符合', '鞋帮高度': '低帮', '闭合方式': '系带'}</td>\n",
       "      <td>[1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139583</th>\n",
       "      <td>train089584</td>\n",
       "      <td>[0.5622448, -0.009292278, 0.024309224, 1.10481...</td>\n",
       "      <td>堆堆领2020年秋季女士T恤女装长袖纯色</td>\n",
       "      <td>{'图文': '符合', '袖长': '长袖', '领型': '堆堆领'}</td>\n",
       "      <td>[1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139584</th>\n",
       "      <td>train089585</td>\n",
       "      <td>[0.46319145, -0.022567572, 0.06200119, -0.6101...</td>\n",
       "      <td>常规厚度酒红色格子裤子长裤男装</td>\n",
       "      <td>{'图文': '符合', '裤长': '长裤'}</td>\n",
       "      <td>[1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139585</th>\n",
       "      <td>train089586</td>\n",
       "      <td>[0.2999022, -0.021870004, 0.09405348, -1.24268...</td>\n",
       "      <td>蓝色2021年冬季宽松型吊带常规款纯色女装</td>\n",
       "      <td>{'图文': '符合', '版型': '宽松型', '衣长': '常规款'}</td>\n",
       "      <td>[1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139586</th>\n",
       "      <td>train089587</td>\n",
       "      <td>[-1.3712472, 0.042915933, 0.06434516, -0.51706...</td>\n",
       "      <td>常规厚度男装2021年秋季白色套头高领时尚潮流修身型针织衫</td>\n",
       "      <td>{'图文': '符合', '版型': '修身型', '领型': '高领', '穿着方式': ...</td>\n",
       "      <td>[1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           img_name                                            feature  \\\n",
       "139582  train089583  [0.3453068, 0.006607449, -0.008650677, 0.12480...   \n",
       "139583  train089584  [0.5622448, -0.009292278, 0.024309224, 1.10481...   \n",
       "139584  train089585  [0.46319145, -0.022567572, 0.06200119, -0.6101...   \n",
       "139585  train089586  [0.2999022, -0.021870004, 0.09405348, -1.24268...   \n",
       "139586  train089587  [-1.3712472, 0.042915933, 0.06434516, -0.51706...   \n",
       "\n",
       "                                 text  \\\n",
       "139582           2021年秋季低帮女士休闲鞋纯色系带白色   \n",
       "139583           堆堆领2020年秋季女士T恤女装长袖纯色   \n",
       "139584                常规厚度酒红色格子裤子长裤男装   \n",
       "139585          蓝色2021年冬季宽松型吊带常规款纯色女装   \n",
       "139586  常规厚度男装2021年秋季白色套头高领时尚潮流修身型针织衫   \n",
       "\n",
       "                                                 key_attr  \\\n",
       "139582           {'图文': '符合', '鞋帮高度': '低帮', '闭合方式': '系带'}   \n",
       "139583              {'图文': '符合', '袖长': '长袖', '领型': '堆堆领'}   \n",
       "139584                           {'图文': '符合', '裤长': '长裤'}   \n",
       "139585             {'图文': '符合', '版型': '宽松型', '衣长': '常规款'}   \n",
       "139586  {'图文': '符合', '版型': '修身型', '领型': '高领', '穿着方式': ...   \n",
       "\n",
       "                                                   labels  \n",
       "139582  [1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1]  \n",
       "139583  [1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "139584  [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1,...  \n",
       "139585  [1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1]  \n",
       "139586   [1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(139587, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df.tail())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67b02b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_feather(CFG.data_dir + 'multi_label/fine.feather')\n",
    "# display(df.head())\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbdaae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./data/df_sample_0.1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b289586c",
   "metadata": {},
   "source": [
    "# CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe89024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# kfold = GroupKFold(CFG.folds)\n",
    "# for fold, (trn_id, val_id) in enumerate(kfold.split(df, groups=df['img_name'])):\n",
    "#     df.loc[val_id, 'fold'] = fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f28a84c",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b52ff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class textDataset(Dataset):\n",
    "    def __init__(self, data, index=None):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        #self.set_type = set_type\n",
    "        self.class_name = ['图文', '版型', '裤型', '袖长', '裙长', '领型', '裤门襟', '鞋帮高度', '穿着方式', '衣长', '闭合方式', '裤长', '类别']\n",
    "        self.synonym_dict = {\n",
    "            # 领型\n",
    "            '高领':['半高领', '立领'], '半高领':['高领', '立领'], '立领':['半高领', '高领'],\n",
    "            '连帽':['可脱卸帽'], '可脱卸帽':['连帽'],\n",
    "            '翻领':['衬衫领', 'POLO领', '方领', '娃娃领', '荷叶领'],'衬衫领':['翻领', 'POLO领', '方领', '娃娃领', '荷叶领'],\n",
    "                    'POLO领':['翻领', '衬衫领', '方领', '娃娃领', '荷叶领'],'方领':['翻领', '衬衫领', 'POLO领', '娃娃领', '荷叶领'],\n",
    "                    '娃娃领':['翻领', '衬衫领', 'POLO领', '方领', '荷叶领'], '荷叶领':['翻领', '衬衫领', 'POLO领', '方领', '娃娃领'],\n",
    "            # 袖长\n",
    "            '短袖':['五分袖'], '五分袖':['短袖'],\n",
    "            '九分袖':['长袖'], '长袖':['九分袖'], \n",
    "            # 衣长\n",
    "            '超短款':['短款', '常规款'], '短款':['超短款', '常规款'], '常规款':['超短款', '短款'],\n",
    "            '长款':['超长款'],'超长款':['长款'],\n",
    "            # 版型\n",
    "            '修身型':['标准型'], '标准型':['修身型'],\n",
    "            # 裙长\n",
    "            '短裙': ['超短裙'], '超短裙': ['短裙'],\n",
    "            '中裙':['长裙'],'长裙':['中裙'],\n",
    "            # 裤型\n",
    "            'O型裤':['锥形裤', '哈伦裤', '灯笼裤'], '锥形裤':['O型裤', '哈伦裤', '灯笼裤'],\n",
    "            '哈伦裤':['锥形裤', 'O型裤', '灯笼裤'], '灯笼裤':['锥形裤', '哈伦裤', 'O型裤'],\n",
    "            '铅笔裤':['直筒裤', '小脚裤'], '直筒裤':['铅笔裤', '小脚裤'],  '小脚裤':['直筒裤', '铅笔裤'],\n",
    "            '喇叭裤':['微喇裤'], '微喇裤':['喇叭裤'],\n",
    "            # 裤长\n",
    "            '九分裤':['长裤'], '长裤':['九分裤'],\n",
    "            # 闭合方式\n",
    "            '套筒':['套脚', '一脚蹬'], '套脚':['套筒', '一脚蹬'], '一脚蹬':['套筒', '套脚'],\n",
    "            # 鞋帮高度\n",
    "            '高帮':['中帮'], '中帮':['高帮']  \n",
    "        }\n",
    "        \n",
    "        self.class_dict = {'图文': ['符合','不符合'], \n",
    "            '版型': ['修身型', '宽松型', '标准型'], \n",
    "            '裤型': ['微喇裤', '小脚裤', '哈伦裤', '直筒裤', '阔腿裤', '铅笔裤', 'O型裤', '灯笼裤', '锥形裤', '喇叭裤', '工装裤', '背带裤', '紧身裤'],\n",
    "            '袖长': ['长袖', '短袖', '七分袖', '五分袖', '无袖', '九分袖'], \n",
    "            '裙长': ['中长裙', '短裙', '超短裙', '中裙', '长裙'], \n",
    "            '领型': ['半高领', '高领', '翻领', 'POLO领', '立领', '连帽', '娃娃领', 'V领', '圆领', '西装领', '荷叶领', '围巾领', '棒球领', '方领', '可脱卸帽', '衬衫领', 'U型领', '堆堆领', '一字领', '亨利领', '斜领', '双层领'], \n",
    "            '裤门襟': ['系带', '松紧', '拉链'], \n",
    "            '鞋帮高度': ['低帮', '高帮', '中帮'], \n",
    "            '穿着方式': ['套头', '开衫'], \n",
    "            '衣长': ['常规款', '中长款', '长款', '短款', '超短款', '超长款'], \n",
    "            '闭合方式': ['系带', '套脚', '一脚蹬', '松紧带', '魔术贴', '搭扣', '套筒', '拉链'], \n",
    "            '裤长': ['九分裤', '长裤', '五分裤', '七分裤', '短裤'], \n",
    "            '类别': ['单肩包', '斜挎包', '双肩包', '手提包']\n",
    "            }\n",
    "        \n",
    "        self.kind_dict = {\n",
    "            '衣':['针织衫', '外套', '衬衫', '羽绒服', '吊带衫', '棉服','T恤',\n",
    "                  '风衣', '仿皮皮衣', '羊毛衫','卫衣', '真皮皮衣', '大衣', 'POLO衫',\n",
    "                  '毛衣', '连衣裙', '打底衫', '雪纺衫', '羊绒衫', '夹克', '皮草', '马甲',\n",
    "                  '派克服', '皮衣', '衬衣','背心','棉衣','套装裙'],\n",
    "            '裤':['牛仔裤', '正装裤', '加绒裤', '休闲裤', '卫裤', '保暖裤', '西装裤', '格子裤子', '运动裤', '垮裤', '西裤', '裙子'],\n",
    "            '鞋':['休闲鞋', '帆布鞋', '登山鞋', '工装鞋', '运动鞋', '篮球鞋', '板鞋', '皮鞋', '靴子', '雨鞋', '布鞋', '高跟鞋', '童鞋', '雪地靴'],\n",
    "        }\n",
    "        self.label_dict = {label:i for i, label in enumerate(class_name)}\n",
    "        for key, value in self.class_dict.items():\n",
    "            for key_attr in value:\n",
    "                jieba.add_word(key_attr)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def get_key_attr_neg_single(self, text, key_attr):\n",
    "        label = [0]*13 # 图文为0\n",
    "        flag = 0\n",
    "        class_name_ = self.class_name[1:].copy()\n",
    "        random.shuffle(class_name_)\n",
    "        for name in class_name_: #self.class_name： ['图文', '版型', '裤型', ]\n",
    "            encode = -1 # 如果该关键属性在文本的关键属性中没有的话，该关键属性标签为-1\n",
    "            keys = list(key_attr.keys())\n",
    "            random.shuffle(keys)\n",
    "            for key in keys: # 匹配该text里面的所有关键属性 # key_attr['图文'：xx, '版型'：xx, '裤型':xx, ]\n",
    "                if key == name:  # 如果和文本的关键属性匹配上，就进行负样本替换\n",
    "                    encode = 1  # 匹配上了，由于下面可能存在不替代该关键词，所有设置标签为1\n",
    "                    if flag == 0:\n",
    "                        val = key_attr[key]  # 匹配上的关键属性的具体取值\n",
    "                        if val in text: # 如果关键属性中的值在文本中，说明\n",
    "                            #属性值在texts中，用另外的值替换掉text中文本,\n",
    "                            tmp = self.class_dict[key]\n",
    "                            tmp_1 = []\n",
    "                            for j in tmp:\n",
    "                                if j != val:\n",
    "                                    tmp_1.append(j)\n",
    "                            # 删除同义词替换为负样本\n",
    "                            if val in self.synonym_dict:\n",
    "                                for synonym in self.synonym_dict[val]:\n",
    "                                    tmp_1.remove(synonym)\n",
    "                            sample = random.choice(tmp_1)\n",
    "                            #print(val,sample)\n",
    "                            text = text.replace(val, sample)\n",
    "                            encode = 0\n",
    "                            flag = 1\n",
    "            label[self.label_dict[name]] = encode\n",
    "        return text, label\n",
    "    \n",
    "    def delete_key_attr_neg_single(self, text, key_attr):\n",
    "        label = [1] + [0]*12 # 图文为0\n",
    "        flag = 0\n",
    "        class_name_ = self.class_name[1:].copy()\n",
    "        random.shuffle(class_name_)\n",
    "        for name in class_name_: #self.class_name： ['图文', '版型', '裤型', ]\n",
    "            encode = -1 # 如果该关键属性在文本的关键属性中没有的话，该关键属性标签为-1\n",
    "            keys = list(key_attr.keys())\n",
    "            random.shuffle(keys)\n",
    "            for key in keys: # 匹配该text里面的所有关键属性 # key_attr['图文'：xx, '版型'：xx, '裤型':xx, ]\n",
    "                if key == name:  # 如果和文本的关键属性匹配上，就进行负样本替换\n",
    "                    encode = 1  # 匹配上了，由于下面可能存在不替代该关键词，所有设置标签为1\n",
    "                    if flag == 0:\n",
    "                        val = key_attr[key]  # 匹配上的关键属性的具体取值\n",
    "                        if val in text: # 如果关键属性中的值在文本中，说明\n",
    "                            #属性值在texts中，用另外的值替换掉text中文本,\n",
    "                            text = ''.join(text.split(val))\n",
    "                            encode = 0\n",
    "                            flag = 1\n",
    "            label[self.label_dict[name]] = encode\n",
    "        return text, label\n",
    "    \n",
    "    def get_key_attr_neg_multi(self, text, key_attr):\n",
    "        label = [0]*13 # 图文为0\n",
    "        flag = 0\n",
    "        class_name_ = self.class_name[1:].copy()\n",
    "        random.shuffle(class_name_)\n",
    "        for name in class_name_: #self.class_name： ['图文', '版型', '裤型', ]\n",
    "            encode = -1 # 如果该关键属性在文本的关键属性中没有的话，该关键属性标签为-1\n",
    "            keys = list(key_attr.keys())\n",
    "            random.shuffle(keys)\n",
    "            for key in keys: # 匹配该text里面的所有关键属性 # key_attr['图文'：xx, '版型'：xx, '裤型':xx, ]\n",
    "                if key == name:  # 如果和文本的关键属性匹配上，就进行负样本替换\n",
    "                    val = key_attr[key]  # 匹配上的关键属性的具体取值\n",
    "                    encode = 1  # 匹配上了，由于下面可能存在不替代该关键词，所有设置标签为1\n",
    "                    if flag == 0:\n",
    "                        if val in text: # 如果关键属性中的值在文本中，说明\n",
    "                            #属性值在texts中，用另外的值替换掉text中文本,\n",
    "                            tmp = self.class_dict[key]\n",
    "                            tmp_1 = []\n",
    "                            for j in tmp:\n",
    "                                if j != val:\n",
    "                                    tmp_1.append(j)\n",
    "                            # 删除同义词替换为负样本\n",
    "                            if val in self.synonym_dict:\n",
    "                                for synonym in self.synonym_dict[val]:\n",
    "                                    tmp_1.remove(synonym)\n",
    "                            sample = random.choice(tmp_1)\n",
    "                            #print(val,sample)\n",
    "                            text = text.replace(val, sample)\n",
    "                            encode = 0\n",
    "                            multi_replace_pro = random.random()\n",
    "                            if multi_replace_pro < 0.3: # 0.3概率不替代了，0.7继续替代\n",
    "                                flag = 1\n",
    "                                \n",
    "            label[self.label_dict[name]] = encode\n",
    "        return text, label\n",
    "    \n",
    "    def get_kinds_neg(self, text, label):\n",
    "        kind_dict_keys = list(self.kind_dict.keys())\n",
    "        random.shuffle(kind_dict_keys)\n",
    "        for key in kind_dict_keys:\n",
    "            for kind in self.kind_dict[key]:\n",
    "                if kind.lower() in text.lower():\n",
    "                    neg = kind.lower()\n",
    "                    while neg == kind.lower():\n",
    "                        neg = random.choice(self.kind_dict[key])\n",
    "                    if random.choice([0, 1]):\n",
    "                        text = text.replace(kind, neg.lower())\n",
    "                        text = text.replace(kind.lower(), neg.lower())\n",
    "\n",
    "                    else:\n",
    "                        text = text.replace(kind, neg)\n",
    "                        text = text.replace(kind.lower(), neg)\n",
    "                    label[0] = 0\n",
    "        return text, label\n",
    "    \n",
    "    def get_synonym_pos(self, text, key_attr):\n",
    "        # 要用的话要改\n",
    "        label = [1] \n",
    "        for name in self.class_name[1:]: #self.class_name： ['图文', '版型', '裤型', ]\n",
    "            encode = [-1] # 如果该关键属性在文本的关键属性中没有的话，该关键属性标签为-1\n",
    "            for key in key_attr.keys(): # 匹配该text里面的所有关键属性 # key_attr['图文'：xx, '版型'：xx, '裤型':xx, ]\n",
    "                if key == name:  # 如果和文本的关键属性匹配上，就进行同义词替换\n",
    "                    val = key_attr[key]  # 匹配上的关键属性的具体取值\n",
    "                    if val in text and val in self.synonym_dict: # 如果关键属性中的值在文本中且有同义词，则进行同义词替换\n",
    "                        tmp_1 = self.synonym_dict[val] # 同义词表\n",
    "                        sample = random.choice(tmp_1)\n",
    "                        text = text.replace(val, sample)\n",
    "                    encode = [1]\n",
    "            label += encode\n",
    "        return text, label\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        label = self.data['labels'][idx].copy()\n",
    "        text = self.data['text'][idx]\n",
    "        key_attr = self.data['key_attr'][idx]\n",
    "        feature = torch.tensor(self.data['feature'][idx]).float()\n",
    "        \n",
    "        # 构造负样本\n",
    "        # 1. kinds替代 2. 关键属性替代\n",
    "        replace_pro = random.random()\n",
    "        # 4:1.5:1.5:2.5\n",
    "            \n",
    "        if replace_pro <= 0.5:\n",
    "            if replace_pro < 0.2:\n",
    "                text, label = self.get_key_attr_neg_single(text, key_attr)\n",
    "            elif replace_pro < 0.35:\n",
    "                text, label = self.get_key_attr_neg_multi(text, key_attr)\n",
    "            else:\n",
    "                text, label = self.get_kinds_neg(text, label)\n",
    "#         else:\n",
    "#             if random.random() <= 0.1:\n",
    "#                 text, label = self.delete_key_attr_neg_single(text, key_attr)\n",
    "        \n",
    "        if random.random() <= 0.3:\n",
    "            text_ = jieba.lcut(text,cut_all=False,HMM=False)\n",
    "            random.shuffle(text_)\n",
    "            text= ''.join(text_)\n",
    "            \n",
    "        return text, feature, np.array(label) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d771ef6",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50581038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dict = model.state_dict()\n",
    "# checkpoint_dict = {}\n",
    "# model_loaded = torch.load('models/' + model_name + '.pt', map_location='cpu')\n",
    "# for key, value in model_loaded.items():\n",
    "#     checkpoint_dict[rename_key(key)] = value\n",
    "# model_dict.update(checkpoint_dict)\n",
    "# model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebdd8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ITM_Model(nn.Module):\n",
    "    def __init__(self, CFG):\n",
    "        super().__init__()\n",
    "        #model_loaded = torch.load(CFG.model_path + 'pytorch_model.bin', map_location='cpu')\n",
    "        self.transformer =  model_class.from_pretrained('uclanlp/visualbert-vqa-coco-pre', config=config)\n",
    "        self.transformer = self.rename_dict(self.transformer)\n",
    "        #self.transformer.load_state_dict()\n",
    "        self.dropout = nn.Dropout(CFG.dropout)\n",
    "        self.clf = nn.Sequential(\n",
    "                nn.Linear(CFG.text_dim, 256),\n",
    "                nn.Linear(256, 64),\n",
    "                nn.Linear(64, 13)\n",
    "        )\n",
    "    def rename_key(self, key):\n",
    "        if 'visual_bert.' in key:\n",
    "            return key.split('visual_bert.')[-1]\n",
    "        return key\n",
    "\n",
    "    def rename_dict(self, transformer):\n",
    "        model_dict = transformer.state_dict()\n",
    "        checkpoint_dict = {}\n",
    "        model_loaded = torch.load(f'./prev_trained_model/visualbert_1/pytorch_model.bin')\n",
    "        for key, value in model_loaded.items():\n",
    "            checkpoint_dict[self.rename_key(key)] = value\n",
    "        model_dict.update(checkpoint_dict)\n",
    "        transformer.load_state_dict(model_dict, strict=False)\n",
    "        return transformer\n",
    "    \n",
    "    def forward(self, text, img):\n",
    "        text.update({'visual_embeds': img.unsqueeze(1)})\n",
    "        fuse = self.transformer(**text)[1]\n",
    "        fuse = self.dropout(fuse)\n",
    "        out = self.clf(fuse)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61feebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb3ac413",
   "metadata": {},
   "source": [
    "# Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "673460c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_optimizer(model, CFG):\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.transformer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'lr': CFG.transformer_lr, 'weight_decay': CFG.weight_decay},\n",
    "            {'params': [p for n, p in model.transformer.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'lr': CFG.transformer_lr, 'weight_decay': 0.0},\n",
    "        \n",
    "            {'params': [p for n, p in model.named_parameters() if \"transformer\" not in n and not any(nd in n for nd in no_decay)],\n",
    "             'lr': CFG.clf_lr, 'weight_decay': CFG.weight_decay},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"transformer\" not in n and any(nd in n for nd in no_decay)],\n",
    "             'lr': CFG.clf_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "    optimizer = AdamW(optimizer_parameters, lr=CFG.transformer_lr, eps=CFG.eps, betas=CFG.betas)\n",
    "    return optimizer\n",
    "\n",
    "def get_scheduler(CFG, optimizer, num_train_steps):\n",
    "    if CFG.scheduler=='linear':\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=CFG.num_warmup_steps, num_training_steps=num_train_steps\n",
    "        )\n",
    "    elif CFG.scheduler=='cosine':\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=CFG.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=CFG.num_cycles\n",
    "        )\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e84eba",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d5909c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(df, CFG):\n",
    "    scores = []\n",
    "    kf = KFold(n_splits=5)\n",
    "    for fold, (trn_idx, val_idx) in enumerate(kf.split(df)):\n",
    "        if fold != 0:\n",
    "            break\n",
    "        logger.info('\\n')\n",
    "        logger.info('='*10 + f'fold:{fold}' +'='*10)\n",
    "        logger.info('\\n')\n",
    "        \n",
    "#         train = df.iloc[trn_idx].reset_index(drop=True)\n",
    "#         valid = df.iloc[val_idx].reset_index(drop=True)\n",
    "        \n",
    "#         logger.info(f'train on {len(train)} samples, valid on {len(valid)} samples')\n",
    "        \n",
    "        logger.info(f'define train_dataset and valid_dataset')\n",
    "        train_dataset, valid_dataset = textDataset(df), textDataset(df)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, pin_memory=True)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size * 2, shuffle=False,  pin_memory=True)\n",
    "        \n",
    "        logger.info(f'define model')\n",
    "        \n",
    "        model = ITM_Model(CFG)\n",
    "        model = model.cuda()\n",
    "        logger.info(f'define optimizer and scheduler')\n",
    "        optimizer = get_optimizer(model, CFG)\n",
    "        scheduler = get_scheduler(CFG, optimizer, int(0.06*(len(df) / CFG.batch_size * CFG.epochs)))\n",
    "\n",
    "        criterion = torch.nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "        if CFG.do_ema:\n",
    "            ema = EMA(model, 0.999)\n",
    "            ema.register()\n",
    "            \n",
    "        logger.info(f'start training')\n",
    "        \n",
    "        best_acc = 0\n",
    "        best_loss =9999\n",
    "        \n",
    "        for epoch in range(CFG.epochs):\n",
    "            logger.info(f'Epoch:{epoch}')\n",
    "            \n",
    "            text_image_neg_size = 1e-10\n",
    "            text_image_pos_size = 1e-10\n",
    "            text_image_neg_acc = 0\n",
    "            text_image_pos_acc = 0\n",
    "\n",
    "            key_attr_neg_size = 1e-10\n",
    "            key_attr_pos_size = 1e-10\n",
    "            key_attr_neg_acc = 0\n",
    "            key_attr_pos_acc = 0\n",
    "            \n",
    "            model.train()\n",
    "            bar = tqdm(train_loader, total=len(train_loader))\n",
    "            for text, feature, label in bar: # , max_length=CFG.max_len\n",
    "                text = CFG.tokenizer(text, return_tensors='pt', add_special_tokens=True, padding=True)\n",
    "                for k, v in text.items():\n",
    "                    text[k] = v.cuda()\n",
    "                    \n",
    "                img = feature.cuda()\n",
    "                label = label.cuda()\n",
    "\n",
    "                ones = torch.ones(label.shape).cuda()\n",
    "                zeros = torch.zeros(label.shape).cuda()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(text, img).squeeze(1)\n",
    "                loss = criterion(outputs, torch.where(label==1, ones, zeros))\n",
    "                loss.backward()\n",
    "                \n",
    "                nn.utils.clip_grad_norm_(model.parameters(), CFG.max_norm)\n",
    "                \n",
    "                if CFG.do_fgm:\n",
    "                    #model.zero_grad()\n",
    "                    fgm = FGM(model, epsilon=0.2, emb_name='word_embeddings.')\n",
    "                    fgm.attack()\n",
    "                    logits_fgm = model(text, img).squeeze(1)\n",
    "                    loss_adv = criterion(logits_fgm, label)\n",
    "                    loss_adv.backward()\n",
    "                    fgm.restore()\n",
    "                if CFG.do_pgd:\n",
    "                    #model.zero_grad()\n",
    "                    pgd = PGD(model, emb_name='word_embeddings.', epsilon=1.0,alpha=0.3)\n",
    "                    K = 3\n",
    "                    pgd.backup_grad()\n",
    "                    # 对抗训练\n",
    "                    for t in range(K):\n",
    "                        pgd.attack(is_first_attack=(t==0)) # 在embedding上添加对抗扰动, first attack时备份param.data\n",
    "                        if t != K-1:\n",
    "                            model.zero_grad()\n",
    "                        else:\n",
    "                            pgd.restore_grad()\n",
    "                        loss_adv = model(text, img).squeeze(1)\n",
    "                        loss_adv.backward() # 反向传播，并在正常的grad基础上，累加对抗训练的梯度\n",
    "                    pgd.restore() # 恢复embedding参数\n",
    "                    \n",
    "                    \n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                model.zero_grad()\n",
    "                \n",
    "                if CFG.do_ema:\n",
    "                    ema.update()\n",
    "                    \n",
    "                index = (nn.Sigmoid()(outputs) >= 0.5) == label\n",
    "                text_image_neg_size += (label[:, 0] == 0).sum().item()\n",
    "                text_image_pos_size += (label[:, 0] == 1).sum().item()\n",
    "                text_image_neg_acc += (label[:, 0][index[:, 0]] == 0).sum().item()\n",
    "                text_image_pos_acc += (label[:, 0][index[:, 0]] == 1).sum().item()\n",
    "\n",
    "                key_attr_neg_size += (label[:, 1:] == 0).sum().item()\n",
    "                key_attr_pos_size += (label[:, 1:] == 1).sum().item()\n",
    "                key_attr_neg_acc += (label[:, 1:][index[:, 1:]] == 0).sum().item()\n",
    "                key_attr_pos_acc += (label[:, 1:][index[:, 1:]] == 1).sum().item()\n",
    "\n",
    "                text_image_epoch_neg_acc = text_image_neg_acc / text_image_neg_size\n",
    "                text_image_epoch_pos_acc = text_image_pos_acc / text_image_pos_size\n",
    "                text_image_epoch_acc = (text_image_neg_acc + text_image_pos_acc) / (text_image_pos_size + text_image_neg_size)\n",
    "                key_attr_epoch_neg_acc = key_attr_neg_acc / key_attr_neg_size\n",
    "                key_attr_epoch_pos_acc = key_attr_pos_acc / key_attr_pos_size\n",
    "                key_attr_epoch_acc = (key_attr_neg_acc + key_attr_pos_acc) / (key_attr_pos_size + key_attr_neg_size)\n",
    "                epoch_acc = 0.5 * text_image_epoch_acc + 0.5 * key_attr_epoch_acc\n",
    "\n",
    "                bar.set_postfix(Epoch=epoch,\n",
    "                                LR=optimizer.param_groups[0]['lr'], \n",
    "                                Train_acc=epoch_acc, \n",
    "                                text_image_epoch_neg_acc=text_image_epoch_neg_acc,\n",
    "                                text_image_epoch_pos_acc=text_image_epoch_pos_acc,\n",
    "                                text_image_epoch_acc = text_image_epoch_acc,\n",
    "                                key_attr_epoch_neg_acc=key_attr_epoch_neg_acc,\n",
    "                                key_attr_epoch_pos_acc=key_attr_epoch_pos_acc,\n",
    "                                key_attr_epoch_acc = key_attr_epoch_acc,\n",
    "                              )\n",
    "            \n",
    "            if CFG.do_ema:\n",
    "                ema.apply_shadow()\n",
    "                \n",
    "            logger.info(\"***** Train results %s *****\")\n",
    "            \n",
    "            dataset_size = 0\n",
    "            \n",
    "            text_image_neg_size = 1e-10\n",
    "            text_image_pos_size = 1e-10\n",
    "            text_image_neg_acc = 0\n",
    "            text_image_pos_acc = 0\n",
    "\n",
    "            key_attr_neg_size = 1e-10\n",
    "            key_attr_pos_size = 1e-10\n",
    "            key_attr_neg_acc = 0\n",
    "            key_attr_pos_acc = 0\n",
    "\n",
    "            bar = tqdm(valid_loader, total=len(valid_loader))\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for text, feature, label in bar:# max_len\n",
    "                    text = CFG.tokenizer(text, return_tensors='pt', add_special_tokens=True, padding=True)\n",
    "                    for k, v in text.items():\n",
    "                        text[k] = v.cuda()\n",
    "                    img = feature.cuda()\n",
    "                    label = label.cuda()\n",
    "                    \n",
    "                    ones = torch.ones(label.shape).cuda()\n",
    "                    zeros = torch.zeros(label.shape).cuda()\n",
    "                    \n",
    "                    outputs = model(text, img).squeeze(1)\n",
    "                    loss = criterion(outputs, torch.where(label==1, ones, zeros))\n",
    "\n",
    "                    index = (nn.Sigmoid()(outputs) >= 0.5) == label\n",
    "                    text_image_neg_size += (label[:, 0] == 0).sum().item()\n",
    "                    text_image_pos_size += (label[:, 0] == 1).sum().item()\n",
    "                    text_image_neg_acc += (label[:, 0][index[:, 0]] == 0).sum().item()\n",
    "                    text_image_pos_acc += (label[:, 0][index[:, 0]] == 1).sum().item()\n",
    "\n",
    "                    key_attr_neg_size += (label[:, 1:] == 0).sum().item()\n",
    "                    key_attr_pos_size += (label[:, 1:] == 1).sum().item()\n",
    "                    key_attr_neg_acc += (label[:, 1:][index[:, 1:]] == 0).sum().item()\n",
    "                    key_attr_pos_acc += (label[:, 1:][index[:, 1:]] == 1).sum().item()\n",
    "\n",
    "                    text_image_epoch_neg_acc = text_image_neg_acc / text_image_neg_size\n",
    "                    text_image_epoch_pos_acc = text_image_pos_acc / text_image_pos_size\n",
    "                    text_image_epoch_acc = (text_image_neg_acc + text_image_pos_acc) / (text_image_pos_size + text_image_neg_size)\n",
    "                    key_attr_epoch_neg_acc = key_attr_neg_acc / key_attr_neg_size\n",
    "                    key_attr_epoch_pos_acc = key_attr_pos_acc / key_attr_pos_size\n",
    "                    key_attr_epoch_acc = (key_attr_neg_acc + key_attr_pos_acc) / (key_attr_pos_size + key_attr_neg_size)\n",
    "                    epoch_acc = 0.5 * text_image_epoch_acc + 0.5 * key_attr_epoch_acc\n",
    "\n",
    "                    bar.set_postfix(Epoch=epoch,\n",
    "                                LR=optimizer.param_groups[0]['lr'], \n",
    "                                Train_acc=epoch_acc, \n",
    "                                text_image_epoch_neg_acc=text_image_epoch_neg_acc,\n",
    "                                text_image_epoch_pos_acc=text_image_epoch_pos_acc,\n",
    "                                text_image_epoch_acc = text_image_epoch_acc,\n",
    "                                key_attr_epoch_neg_acc=key_attr_epoch_neg_acc,\n",
    "                                key_attr_epoch_pos_acc=key_attr_epoch_pos_acc,\n",
    "                                key_attr_epoch_acc = key_attr_epoch_acc,\n",
    "                              )\n",
    "            \n",
    "            logger.info(\"***** Eval results %s *****\")\n",
    "            \n",
    "            if epoch_acc > best_acc:\n",
    "                logger.info(f'Weighted_acc improved: best_acc improved from {best_acc} -----> {epoch_acc}')\n",
    "                best_acc = epoch_acc\n",
    "                logger.info(f'\\n')\n",
    "                state_dict = {k: v for k, v in model.state_dict().items() if 'relative_positions' not in k}\n",
    "                torch.save(state_dict, f'{CFG.out_dir}/model_fold{fold}.pth')\n",
    "                patience = CFG.patience\n",
    "\n",
    "#             else:\n",
    "#                 patience -= 1\n",
    "#                 if patience == 0:\n",
    "#                     break\n",
    "\n",
    "            if CFG.do_ema:\n",
    "                ema.restore()\n",
    "        scores.append(best_acc)\n",
    "\n",
    "    logger.info(f'avg acc:{np.mean(scores)}')\n",
    "    logger.info(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b874b818",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2022 15:31:01 - INFO - root -   \n",
      "\n",
      "05/04/2022 15:31:01 - INFO - root -   ==========fold:0==========\n",
      "05/04/2022 15:31:01 - INFO - root -   \n",
      "\n",
      "05/04/2022 15:31:01 - INFO - root -   define train_dataset and valid_dataset\n",
      "Building prefix dict from the default dictionary ...\n",
      "05/04/2022 15:31:01 - DEBUG - jieba -   Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "05/04/2022 15:31:01 - DEBUG - jieba -   Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.533 seconds.\n",
      "05/04/2022 15:31:02 - DEBUG - jieba -   Loading model cost 0.533 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "05/04/2022 15:31:02 - DEBUG - jieba -   Prefix dict has been built successfully.\n",
      "05/04/2022 15:31:02 - INFO - root -   define model\n",
      "Some weights of the model checkpoint at uclanlp/visualbert-vqa-coco-pre were not used when initializing VisualBertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing VisualBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisualBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "05/04/2022 15:31:10 - INFO - root -   define optimizer and scheduler\n",
      "05/04/2022 15:31:10 - INFO - root -   start training\n",
      "05/04/2022 15:31:10 - INFO - root -   Epoch:0\n",
      "100%|██████████| 1091/1091 [06:04<00:00,  3.00it/s, Epoch=0, LR=1.87e-5, Train_acc=0.741, key_attr_epoch_acc=0.817, key_attr_epoch_neg_acc=0.724, key_attr_epoch_pos_acc=0.842, text_image_epoch_acc=0.666, text_image_epoch_neg_acc=0.575, text_image_epoch_pos_acc=0.754]\n",
      "05/04/2022 15:37:14 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:20<00:00,  3.89it/s, Epoch=0, LR=1.87e-5, Train_acc=0.704, key_attr_epoch_acc=0.75, key_attr_epoch_neg_acc=0.766, key_attr_epoch_pos_acc=0.745, text_image_epoch_acc=0.658, text_image_epoch_neg_acc=0.531, text_image_epoch_pos_acc=0.781] \n",
      "05/04/2022 15:39:34 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 15:39:34 - INFO - root -   Weighted_acc improved: best_acc improved from 0 -----> 0.7039914340932449\n",
      "05/04/2022 15:39:34 - INFO - root -   \n",
      "\n",
      "05/04/2022 15:39:35 - INFO - root -   Epoch:1\n",
      "100%|██████████| 1091/1091 [05:59<00:00,  3.04it/s, Epoch=1, LR=1.5e-5, Train_acc=0.887, key_attr_epoch_acc=0.941, key_attr_epoch_neg_acc=0.822, key_attr_epoch_pos_acc=0.972, text_image_epoch_acc=0.834, text_image_epoch_neg_acc=0.772, text_image_epoch_pos_acc=0.894] \n",
      "05/04/2022 15:45:35 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:16<00:00,  3.99it/s, Epoch=1, LR=1.5e-5, Train_acc=0.867, key_attr_epoch_acc=0.936, key_attr_epoch_neg_acc=0.738, key_attr_epoch_pos_acc=0.989, text_image_epoch_acc=0.799, text_image_epoch_neg_acc=0.647, text_image_epoch_pos_acc=0.946]\n",
      "05/04/2022 15:47:51 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 15:47:51 - INFO - root -   Weighted_acc improved: best_acc improved from 0.7039914340932449 -----> 0.8672127699320823\n",
      "05/04/2022 15:47:51 - INFO - root -   \n",
      "\n",
      "05/04/2022 15:47:53 - INFO - root -   Epoch:2\n",
      "100%|██████████| 1091/1091 [06:01<00:00,  3.02it/s, Epoch=2, LR=9.99e-6, Train_acc=0.918, key_attr_epoch_acc=0.952, key_attr_epoch_neg_acc=0.856, key_attr_epoch_pos_acc=0.977, text_image_epoch_acc=0.885, text_image_epoch_neg_acc=0.842, text_image_epoch_pos_acc=0.926]\n",
      "05/04/2022 15:53:55 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:20<00:00,  3.88it/s, Epoch=2, LR=9.99e-6, Train_acc=0.913, key_attr_epoch_acc=0.956, key_attr_epoch_neg_acc=0.825, key_attr_epoch_pos_acc=0.99, text_image_epoch_acc=0.87, text_image_epoch_neg_acc=0.758, text_image_epoch_pos_acc=0.977]  \n",
      "05/04/2022 15:56:16 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 15:56:16 - INFO - root -   Weighted_acc improved: best_acc improved from 0.8672127699320823 -----> 0.9125796789126783\n",
      "05/04/2022 15:56:16 - INFO - root -   \n",
      "\n",
      "05/04/2022 15:56:18 - INFO - root -   Epoch:3\n",
      "100%|██████████| 1091/1091 [08:11<00:00,  2.22it/s, Epoch=3, LR=4.99e-6, Train_acc=0.929, key_attr_epoch_acc=0.957, key_attr_epoch_neg_acc=0.872, key_attr_epoch_pos_acc=0.98, text_image_epoch_acc=0.901, text_image_epoch_neg_acc=0.863, text_image_epoch_pos_acc=0.938]\n",
      "05/04/2022 16:04:30 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [03:17<00:00,  2.76it/s, Epoch=3, LR=4.99e-6, Train_acc=0.93, key_attr_epoch_acc=0.961, key_attr_epoch_neg_acc=0.854, key_attr_epoch_pos_acc=0.99, text_image_epoch_acc=0.899, text_image_epoch_neg_acc=0.816, text_image_epoch_pos_acc=0.979]  \n",
      "05/04/2022 16:07:47 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 16:07:47 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9125796789126783 -----> 0.9301671357165836\n",
      "05/04/2022 16:07:47 - INFO - root -   \n",
      "\n",
      "05/04/2022 16:07:49 - INFO - root -   Epoch:4\n",
      "100%|██████████| 1091/1091 [06:44<00:00,  2.70it/s, Epoch=4, LR=1.33e-6, Train_acc=0.933, key_attr_epoch_acc=0.959, key_attr_epoch_neg_acc=0.876, key_attr_epoch_pos_acc=0.981, text_image_epoch_acc=0.907, text_image_epoch_neg_acc=0.87, text_image_epoch_pos_acc=0.942] \n",
      "05/04/2022 16:14:34 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:17<00:00,  3.98it/s, Epoch=4, LR=1.33e-6, Train_acc=0.937, key_attr_epoch_acc=0.964, key_attr_epoch_neg_acc=0.868, key_attr_epoch_pos_acc=0.989, text_image_epoch_acc=0.91, text_image_epoch_neg_acc=0.842, text_image_epoch_pos_acc=0.976] \n",
      "05/04/2022 16:16:51 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 16:16:51 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9301671357165836 -----> 0.9371104872871784\n",
      "05/04/2022 16:16:51 - INFO - root -   \n",
      "\n",
      "05/04/2022 16:16:53 - INFO - root -   Epoch:5\n",
      "100%|██████████| 1091/1091 [06:13<00:00,  2.92it/s, Epoch=5, LR=1.04e-11, Train_acc=0.935, key_attr_epoch_acc=0.96, key_attr_epoch_neg_acc=0.88, key_attr_epoch_pos_acc=0.982, text_image_epoch_acc=0.911, text_image_epoch_neg_acc=0.874, text_image_epoch_pos_acc=0.946]\n",
      "05/04/2022 16:23:07 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [03:11<00:00,  2.85it/s, Epoch=5, LR=1.04e-11, Train_acc=0.94, key_attr_epoch_acc=0.965, key_attr_epoch_neg_acc=0.874, key_attr_epoch_pos_acc=0.989, text_image_epoch_acc=0.915, text_image_epoch_neg_acc=0.85, text_image_epoch_pos_acc=0.977]  \n",
      "05/04/2022 16:26:18 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 16:26:18 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9371104872871784 -----> 0.939817805636944\n",
      "05/04/2022 16:26:18 - INFO - root -   \n",
      "\n",
      "05/04/2022 16:26:20 - INFO - root -   Epoch:6\n",
      "100%|██████████| 1091/1091 [08:26<00:00,  2.16it/s, Epoch=6, LR=1.35e-6, Train_acc=0.935, key_attr_epoch_acc=0.96, key_attr_epoch_neg_acc=0.881, key_attr_epoch_pos_acc=0.982, text_image_epoch_acc=0.909, text_image_epoch_neg_acc=0.873, text_image_epoch_pos_acc=0.944] \n",
      "05/04/2022 16:34:46 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [03:16<00:00,  2.78it/s, Epoch=6, LR=1.35e-6, Train_acc=0.941, key_attr_epoch_acc=0.965, key_attr_epoch_neg_acc=0.876, key_attr_epoch_pos_acc=0.989, text_image_epoch_acc=0.916, text_image_epoch_neg_acc=0.853, text_image_epoch_pos_acc=0.976]\n",
      "05/04/2022 16:38:03 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 16:38:03 - INFO - root -   Weighted_acc improved: best_acc improved from 0.939817805636944 -----> 0.9405544741302221\n",
      "05/04/2022 16:38:03 - INFO - root -   \n",
      "\n",
      "05/04/2022 16:38:05 - INFO - root -   Epoch:7\n",
      "100%|██████████| 1091/1091 [06:48<00:00,  2.67it/s, Epoch=7, LR=5.02e-6, Train_acc=0.935, key_attr_epoch_acc=0.961, key_attr_epoch_neg_acc=0.882, key_attr_epoch_pos_acc=0.982, text_image_epoch_acc=0.91, text_image_epoch_neg_acc=0.874, text_image_epoch_pos_acc=0.945]\n",
      "05/04/2022 16:44:54 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:54<00:00,  3.13it/s, Epoch=7, LR=5.02e-6, Train_acc=0.942, key_attr_epoch_acc=0.966, key_attr_epoch_neg_acc=0.88, key_attr_epoch_pos_acc=0.989, text_image_epoch_acc=0.917, text_image_epoch_neg_acc=0.856, text_image_epoch_pos_acc=0.976] \n",
      "05/04/2022 16:47:48 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 16:47:48 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9405544741302221 -----> 0.9416596734888378\n",
      "05/04/2022 16:47:48 - INFO - root -   \n",
      "\n",
      "05/04/2022 16:47:50 - INFO - root -   Epoch:8\n",
      "100%|██████████| 1091/1091 [08:22<00:00,  2.17it/s, Epoch=8, LR=1e-5, Train_acc=0.935, key_attr_epoch_acc=0.96, key_attr_epoch_neg_acc=0.881, key_attr_epoch_pos_acc=0.981, text_image_epoch_acc=0.911, text_image_epoch_neg_acc=0.876, text_image_epoch_pos_acc=0.944]   \n",
      "05/04/2022 16:56:13 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [03:17<00:00,  2.77it/s, Epoch=8, LR=1e-5, Train_acc=0.943, key_attr_epoch_acc=0.967, key_attr_epoch_neg_acc=0.879, key_attr_epoch_pos_acc=0.99, text_image_epoch_acc=0.919, text_image_epoch_neg_acc=0.859, text_image_epoch_pos_acc=0.977] \n",
      "05/04/2022 16:59:30 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 16:59:30 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9416596734888378 -----> 0.9428261921518009\n",
      "05/04/2022 16:59:30 - INFO - root -   \n",
      "\n",
      "05/04/2022 16:59:32 - INFO - root -   Epoch:9\n",
      "100%|██████████| 1091/1091 [07:13<00:00,  2.51it/s, Epoch=9, LR=1.5e-5, Train_acc=0.936, key_attr_epoch_acc=0.96, key_attr_epoch_neg_acc=0.881, key_attr_epoch_pos_acc=0.981, text_image_epoch_acc=0.912, text_image_epoch_neg_acc=0.877, text_image_epoch_pos_acc=0.947] \n",
      "05/04/2022 17:06:46 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:23<00:00,  3.81it/s, Epoch=9, LR=1.5e-5, Train_acc=0.946, key_attr_epoch_acc=0.969, key_attr_epoch_neg_acc=0.886, key_attr_epoch_pos_acc=0.991, text_image_epoch_acc=0.924, text_image_epoch_neg_acc=0.868, text_image_epoch_pos_acc=0.979]\n",
      "05/04/2022 17:09:09 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 17:09:09 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9428261921518009 -----> 0.9461896317787364\n",
      "05/04/2022 17:09:09 - INFO - root -   \n",
      "\n",
      "05/04/2022 17:09:11 - INFO - root -   Epoch:10\n",
      "100%|██████████| 1091/1091 [06:09<00:00,  2.95it/s, Epoch=10, LR=1.87e-5, Train_acc=0.939, key_attr_epoch_acc=0.962, key_attr_epoch_neg_acc=0.887, key_attr_epoch_pos_acc=0.982, text_image_epoch_acc=0.916, text_image_epoch_neg_acc=0.882, text_image_epoch_pos_acc=0.948]\n",
      "05/04/2022 17:15:21 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:19<00:00,  3.91it/s, Epoch=10, LR=1.87e-5, Train_acc=0.948, key_attr_epoch_acc=0.969, key_attr_epoch_neg_acc=0.888, key_attr_epoch_pos_acc=0.991, text_image_epoch_acc=0.927, text_image_epoch_neg_acc=0.873, text_image_epoch_pos_acc=0.98] \n",
      "05/04/2022 17:17:40 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 17:17:40 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9461896317787364 -----> 0.9482964612164082\n",
      "05/04/2022 17:17:40 - INFO - root -   \n",
      "\n",
      "05/04/2022 17:17:42 - INFO - root -   Epoch:11\n",
      "100%|██████████| 1091/1091 [06:11<00:00,  2.94it/s, Epoch=11, LR=2e-5, Train_acc=0.942, key_attr_epoch_acc=0.964, key_attr_epoch_neg_acc=0.891, key_attr_epoch_pos_acc=0.983, text_image_epoch_acc=0.92, text_image_epoch_neg_acc=0.886, text_image_epoch_pos_acc=0.953]   \n",
      "05/04/2022 17:23:54 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:21<00:00,  3.87it/s, Epoch=11, LR=2e-5, Train_acc=0.95, key_attr_epoch_acc=0.971, key_attr_epoch_neg_acc=0.891, key_attr_epoch_pos_acc=0.992, text_image_epoch_acc=0.93, text_image_epoch_neg_acc=0.876, text_image_epoch_pos_acc=0.983]  \n",
      "05/04/2022 17:26:15 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 17:26:15 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9482964612164082 -----> 0.9504441696557635\n",
      "05/04/2022 17:26:15 - INFO - root -   \n",
      "\n",
      "05/04/2022 17:26:17 - INFO - root -   Epoch:12\n",
      "100%|██████████| 1091/1091 [06:08<00:00,  2.96it/s, Epoch=12, LR=1.86e-5, Train_acc=0.945, key_attr_epoch_acc=0.966, key_attr_epoch_neg_acc=0.897, key_attr_epoch_pos_acc=0.984, text_image_epoch_acc=0.924, text_image_epoch_neg_acc=0.891, text_image_epoch_pos_acc=0.956]\n",
      "05/04/2022 17:32:25 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:18<00:00,  3.96it/s, Epoch=12, LR=1.86e-5, Train_acc=0.953, key_attr_epoch_acc=0.973, key_attr_epoch_neg_acc=0.896, key_attr_epoch_pos_acc=0.993, text_image_epoch_acc=0.934, text_image_epoch_neg_acc=0.882, text_image_epoch_pos_acc=0.984]\n",
      "05/04/2022 17:34:43 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 17:34:43 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9504441696557635 -----> 0.9533366567058293\n",
      "05/04/2022 17:34:43 - INFO - root -   \n",
      "\n",
      "05/04/2022 17:34:45 - INFO - root -   Epoch:13\n",
      "100%|██████████| 1091/1091 [06:12<00:00,  2.93it/s, Epoch=13, LR=1.5e-5, Train_acc=0.947, key_attr_epoch_acc=0.967, key_attr_epoch_neg_acc=0.902, key_attr_epoch_pos_acc=0.985, text_image_epoch_acc=0.927, text_image_epoch_neg_acc=0.895, text_image_epoch_pos_acc=0.958] \n",
      "05/04/2022 17:40:57 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:21<00:00,  3.86it/s, Epoch=13, LR=1.5e-5, Train_acc=0.957, key_attr_epoch_acc=0.975, key_attr_epoch_neg_acc=0.906, key_attr_epoch_pos_acc=0.994, text_image_epoch_acc=0.939, text_image_epoch_neg_acc=0.891, text_image_epoch_pos_acc=0.985]\n",
      "05/04/2022 17:43:18 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 17:43:18 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9533366567058293 -----> 0.9570390995764224\n",
      "05/04/2022 17:43:18 - INFO - root -   \n",
      "\n",
      "05/04/2022 17:43:20 - INFO - root -   Epoch:14\n",
      "100%|██████████| 1091/1091 [06:07<00:00,  2.97it/s, Epoch=14, LR=9.96e-6, Train_acc=0.951, key_attr_epoch_acc=0.97, key_attr_epoch_neg_acc=0.909, key_attr_epoch_pos_acc=0.986, text_image_epoch_acc=0.932, text_image_epoch_neg_acc=0.9, text_image_epoch_pos_acc=0.962]  \n",
      "05/04/2022 17:49:28 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:23<00:00,  3.80it/s, Epoch=14, LR=9.96e-6, Train_acc=0.958, key_attr_epoch_acc=0.976, key_attr_epoch_neg_acc=0.911, key_attr_epoch_pos_acc=0.994, text_image_epoch_acc=0.941, text_image_epoch_neg_acc=0.894, text_image_epoch_pos_acc=0.985]\n",
      "05/04/2022 17:51:52 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 17:51:52 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9570390995764224 -----> 0.958474543808749\n",
      "05/04/2022 17:51:52 - INFO - root -   \n",
      "\n",
      "05/04/2022 17:51:53 - INFO - root -   Epoch:15\n",
      "100%|██████████| 1091/1091 [08:24<00:00,  2.16it/s, Epoch=15, LR=4.97e-6, Train_acc=0.955, key_attr_epoch_acc=0.972, key_attr_epoch_neg_acc=0.916, key_attr_epoch_pos_acc=0.988, text_image_epoch_acc=0.937, text_image_epoch_neg_acc=0.906, text_image_epoch_pos_acc=0.966]\n",
      "05/04/2022 18:00:18 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [03:15<00:00,  2.80it/s, Epoch=15, LR=4.97e-6, Train_acc=0.962, key_attr_epoch_acc=0.978, key_attr_epoch_neg_acc=0.919, key_attr_epoch_pos_acc=0.994, text_image_epoch_acc=0.945, text_image_epoch_neg_acc=0.903, text_image_epoch_pos_acc=0.986]\n",
      "05/04/2022 18:03:33 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 18:03:33 - INFO - root -   Weighted_acc improved: best_acc improved from 0.958474543808749 -----> 0.9617740389771169\n",
      "05/04/2022 18:03:33 - INFO - root -   \n",
      "\n",
      "05/04/2022 18:03:35 - INFO - root -   Epoch:16\n",
      "100%|██████████| 1091/1091 [08:28<00:00,  2.14it/s, Epoch=16, LR=1.32e-6, Train_acc=0.957, key_attr_epoch_acc=0.974, key_attr_epoch_neg_acc=0.919, key_attr_epoch_pos_acc=0.989, text_image_epoch_acc=0.939, text_image_epoch_neg_acc=0.909, text_image_epoch_pos_acc=0.968]\n",
      "05/04/2022 18:12:04 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:44<00:00,  3.31it/s, Epoch=16, LR=1.32e-6, Train_acc=0.963, key_attr_epoch_acc=0.979, key_attr_epoch_neg_acc=0.924, key_attr_epoch_pos_acc=0.994, text_image_epoch_acc=0.947, text_image_epoch_neg_acc=0.906, text_image_epoch_pos_acc=0.986]\n",
      "05/04/2022 18:14:49 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 18:14:49 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9617740389771169 -----> 0.9630934246274785\n",
      "05/04/2022 18:14:49 - INFO - root -   \n",
      "\n",
      "05/04/2022 18:14:50 - INFO - root -   Epoch:17\n",
      "100%|██████████| 1091/1091 [06:08<00:00,  2.96it/s, Epoch=17, LR=9.34e-11, Train_acc=0.958, key_attr_epoch_acc=0.975, key_attr_epoch_neg_acc=0.922, key_attr_epoch_pos_acc=0.989, text_image_epoch_acc=0.94, text_image_epoch_neg_acc=0.91, text_image_epoch_pos_acc=0.969]\n",
      "05/04/2022 18:20:59 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:21<00:00,  3.87it/s, Epoch=17, LR=9.34e-11, Train_acc=0.963, key_attr_epoch_acc=0.98, key_attr_epoch_neg_acc=0.923, key_attr_epoch_pos_acc=0.995, text_image_epoch_acc=0.947, text_image_epoch_neg_acc=0.906, text_image_epoch_pos_acc=0.986] \n",
      "05/04/2022 18:23:20 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 18:23:20 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9630934246274785 -----> 0.9633685471663476\n",
      "05/04/2022 18:23:20 - INFO - root -   \n",
      "\n",
      "05/04/2022 18:23:22 - INFO - root -   Epoch:18\n",
      "100%|██████████| 1091/1091 [06:04<00:00,  2.99it/s, Epoch=18, LR=1.36e-6, Train_acc=0.958, key_attr_epoch_acc=0.975, key_attr_epoch_neg_acc=0.922, key_attr_epoch_pos_acc=0.989, text_image_epoch_acc=0.94, text_image_epoch_neg_acc=0.91, text_image_epoch_pos_acc=0.97]  \n",
      "05/04/2022 18:29:27 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:24<00:00,  3.78it/s, Epoch=18, LR=1.36e-6, Train_acc=0.963, key_attr_epoch_acc=0.98, key_attr_epoch_neg_acc=0.924, key_attr_epoch_pos_acc=0.995, text_image_epoch_acc=0.947, text_image_epoch_neg_acc=0.906, text_image_epoch_pos_acc=0.987] \n",
      "05/04/2022 18:31:51 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 18:31:51 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9633685471663476 -----> 0.9633762319022192\n",
      "05/04/2022 18:31:51 - INFO - root -   \n",
      "\n",
      "05/04/2022 18:31:53 - INFO - root -   Epoch:19\n",
      "100%|██████████| 1091/1091 [06:05<00:00,  2.98it/s, Epoch=19, LR=5.04e-6, Train_acc=0.958, key_attr_epoch_acc=0.975, key_attr_epoch_neg_acc=0.923, key_attr_epoch_pos_acc=0.989, text_image_epoch_acc=0.941, text_image_epoch_neg_acc=0.912, text_image_epoch_pos_acc=0.969]\n",
      "05/04/2022 18:37:59 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:21<00:00,  3.86it/s, Epoch=19, LR=5.04e-6, Train_acc=0.964, key_attr_epoch_acc=0.98, key_attr_epoch_neg_acc=0.926, key_attr_epoch_pos_acc=0.994, text_image_epoch_acc=0.948, text_image_epoch_neg_acc=0.908, text_image_epoch_pos_acc=0.987] \n",
      "05/04/2022 18:40:20 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 18:40:20 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9633762319022192 -----> 0.9640877733882331\n",
      "05/04/2022 18:40:20 - INFO - root -   \n",
      "\n",
      "05/04/2022 18:40:22 - INFO - root -   Epoch:20\n",
      "100%|██████████| 1091/1091 [06:12<00:00,  2.93it/s, Epoch=20, LR=1.01e-5, Train_acc=0.957, key_attr_epoch_acc=0.974, key_attr_epoch_neg_acc=0.921, key_attr_epoch_pos_acc=0.988, text_image_epoch_acc=0.939, text_image_epoch_neg_acc=0.909, text_image_epoch_pos_acc=0.968]\n",
      "05/04/2022 18:46:35 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:20<00:00,  3.88it/s, Epoch=20, LR=1.01e-5, Train_acc=0.965, key_attr_epoch_acc=0.98, key_attr_epoch_neg_acc=0.925, key_attr_epoch_pos_acc=0.995, text_image_epoch_acc=0.949, text_image_epoch_neg_acc=0.908, text_image_epoch_pos_acc=0.988] \n",
      "05/04/2022 18:48:55 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 18:48:55 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9640877733882331 -----> 0.9647020695372033\n",
      "05/04/2022 18:48:55 - INFO - root -   \n",
      "\n",
      "05/04/2022 18:48:57 - INFO - root -   Epoch:21\n",
      "100%|██████████| 1091/1091 [06:11<00:00,  2.94it/s, Epoch=21, LR=1.5e-5, Train_acc=0.957, key_attr_epoch_acc=0.974, key_attr_epoch_neg_acc=0.92, key_attr_epoch_pos_acc=0.988, text_image_epoch_acc=0.939, text_image_epoch_neg_acc=0.91, text_image_epoch_pos_acc=0.968]   \n",
      "05/04/2022 18:55:09 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:21<00:00,  3.87it/s, Epoch=21, LR=1.5e-5, Train_acc=0.966, key_attr_epoch_acc=0.981, key_attr_epoch_neg_acc=0.927, key_attr_epoch_pos_acc=0.996, text_image_epoch_acc=0.951, text_image_epoch_neg_acc=0.909, text_image_epoch_pos_acc=0.99] \n",
      "05/04/2022 18:57:30 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 18:57:30 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9647020695372033 -----> 0.9660079136805267\n",
      "05/04/2022 18:57:30 - INFO - root -   \n",
      "\n",
      "05/04/2022 18:57:32 - INFO - root -   Epoch:22\n",
      "100%|██████████| 1091/1091 [06:08<00:00,  2.96it/s, Epoch=22, LR=1.87e-5, Train_acc=0.957, key_attr_epoch_acc=0.974, key_attr_epoch_neg_acc=0.921, key_attr_epoch_pos_acc=0.988, text_image_epoch_acc=0.939, text_image_epoch_neg_acc=0.909, text_image_epoch_pos_acc=0.968]\n",
      "05/04/2022 19:03:40 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:20<00:00,  3.89it/s, Epoch=22, LR=1.87e-5, Train_acc=0.966, key_attr_epoch_acc=0.982, key_attr_epoch_neg_acc=0.93, key_attr_epoch_pos_acc=0.996, text_image_epoch_acc=0.951, text_image_epoch_neg_acc=0.909, text_image_epoch_pos_acc=0.992] \n",
      "05/04/2022 19:06:00 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 19:06:00 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9660079136805267 -----> 0.9664616468569573\n",
      "05/04/2022 19:06:00 - INFO - root -   \n",
      "\n",
      "05/04/2022 19:06:02 - INFO - root -   Epoch:23\n",
      "100%|██████████| 1091/1091 [06:11<00:00,  2.94it/s, Epoch=23, LR=2e-5, Train_acc=0.957, key_attr_epoch_acc=0.974, key_attr_epoch_neg_acc=0.921, key_attr_epoch_pos_acc=0.988, text_image_epoch_acc=0.939, text_image_epoch_neg_acc=0.91, text_image_epoch_pos_acc=0.968]   \n",
      "05/04/2022 19:12:13 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:24<00:00,  3.78it/s, Epoch=23, LR=2e-5, Train_acc=0.967, key_attr_epoch_acc=0.983, key_attr_epoch_neg_acc=0.929, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.952, text_image_epoch_neg_acc=0.911, text_image_epoch_pos_acc=0.993]\n",
      "05/04/2022 19:14:38 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 19:14:38 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9664616468569573 -----> 0.9674940373089427\n",
      "05/04/2022 19:14:38 - INFO - root -   \n",
      "\n",
      "05/04/2022 19:14:40 - INFO - root -   Epoch:24\n",
      "100%|██████████| 1091/1091 [06:08<00:00,  2.96it/s, Epoch=24, LR=1.86e-5, Train_acc=0.958, key_attr_epoch_acc=0.975, key_attr_epoch_neg_acc=0.925, key_attr_epoch_pos_acc=0.989, text_image_epoch_acc=0.94, text_image_epoch_neg_acc=0.911, text_image_epoch_pos_acc=0.968]\n",
      "05/04/2022 19:20:48 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:37<00:00,  3.46it/s, Epoch=24, LR=1.86e-5, Train_acc=0.969, key_attr_epoch_acc=0.984, key_attr_epoch_neg_acc=0.934, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.955, text_image_epoch_neg_acc=0.915, text_image_epoch_pos_acc=0.993]\n",
      "05/04/2022 19:23:26 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 19:23:26 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9674940373089427 -----> 0.969273151129181\n",
      "05/04/2022 19:23:26 - INFO - root -   \n",
      "\n",
      "05/04/2022 19:23:28 - INFO - root -   Epoch:25\n",
      "100%|██████████| 1091/1091 [06:20<00:00,  2.87it/s, Epoch=25, LR=1.49e-5, Train_acc=0.961, key_attr_epoch_acc=0.977, key_attr_epoch_neg_acc=0.93, key_attr_epoch_pos_acc=0.99, text_image_epoch_acc=0.946, text_image_epoch_neg_acc=0.918, text_image_epoch_pos_acc=0.973] \n",
      "05/04/2022 19:29:48 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:24<00:00,  3.79it/s, Epoch=25, LR=1.49e-5, Train_acc=0.971, key_attr_epoch_acc=0.985, key_attr_epoch_neg_acc=0.937, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.957, text_image_epoch_neg_acc=0.917, text_image_epoch_pos_acc=0.995]\n",
      "05/04/2022 19:32:13 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 19:32:13 - INFO - root -   Weighted_acc improved: best_acc improved from 0.969273151129181 -----> 0.9706766445616664\n",
      "05/04/2022 19:32:13 - INFO - root -   \n",
      "\n",
      "05/04/2022 19:32:14 - INFO - root -   Epoch:26\n",
      "100%|██████████| 1091/1091 [06:07<00:00,  2.97it/s, Epoch=26, LR=9.94e-6, Train_acc=0.964, key_attr_epoch_acc=0.979, key_attr_epoch_neg_acc=0.936, key_attr_epoch_pos_acc=0.991, text_image_epoch_acc=0.948, text_image_epoch_neg_acc=0.921, text_image_epoch_pos_acc=0.975]\n",
      "05/04/2022 19:38:22 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:21<00:00,  3.85it/s, Epoch=26, LR=9.94e-6, Train_acc=0.973, key_attr_epoch_acc=0.986, key_attr_epoch_neg_acc=0.944, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.959, text_image_epoch_neg_acc=0.922, text_image_epoch_pos_acc=0.995]\n",
      "05/04/2022 19:40:44 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 19:40:44 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9706766445616664 -----> 0.9727102606060415\n",
      "05/04/2022 19:40:44 - INFO - root -   \n",
      "\n",
      "05/04/2022 19:40:46 - INFO - root -   Epoch:27\n",
      "100%|██████████| 1091/1091 [06:11<00:00,  2.93it/s, Epoch=27, LR=4.94e-6, Train_acc=0.967, key_attr_epoch_acc=0.981, key_attr_epoch_neg_acc=0.942, key_attr_epoch_pos_acc=0.992, text_image_epoch_acc=0.952, text_image_epoch_neg_acc=0.925, text_image_epoch_pos_acc=0.978]\n",
      "05/04/2022 19:46:58 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [04:11<00:00,  2.17it/s, Epoch=27, LR=4.94e-6, Train_acc=0.974, key_attr_epoch_acc=0.987, key_attr_epoch_neg_acc=0.946, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.96, text_image_epoch_neg_acc=0.923, text_image_epoch_pos_acc=0.995] \n",
      "05/04/2022 19:51:10 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 19:51:10 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9727102606060415 -----> 0.9735223315505549\n",
      "05/04/2022 19:51:10 - INFO - root -   \n",
      "\n",
      "05/04/2022 19:51:13 - INFO - root -   Epoch:28\n",
      "100%|██████████| 1091/1091 [10:47<00:00,  1.69it/s, Epoch=28, LR=1.31e-6, Train_acc=0.968, key_attr_epoch_acc=0.983, key_attr_epoch_neg_acc=0.945, key_attr_epoch_pos_acc=0.993, text_image_epoch_acc=0.954, text_image_epoch_neg_acc=0.928, text_image_epoch_pos_acc=0.979]\n",
      "05/04/2022 20:02:00 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [03:14<00:00,  2.81it/s, Epoch=28, LR=1.31e-6, Train_acc=0.975, key_attr_epoch_acc=0.988, key_attr_epoch_neg_acc=0.95, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.962, text_image_epoch_neg_acc=0.927, text_image_epoch_pos_acc=0.995] \n",
      "05/04/2022 20:05:15 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 20:05:15 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9735223315505549 -----> 0.9747922389464607\n",
      "05/04/2022 20:05:15 - INFO - root -   \n",
      "\n",
      "05/04/2022 20:05:17 - INFO - root -   Epoch:29\n",
      "100%|██████████| 1091/1091 [08:22<00:00,  2.17it/s, Epoch=29, LR=2.59e-10, Train_acc=0.97, key_attr_epoch_acc=0.984, key_attr_epoch_neg_acc=0.949, key_attr_epoch_pos_acc=0.993, text_image_epoch_acc=0.956, text_image_epoch_neg_acc=0.93, text_image_epoch_pos_acc=0.981]\n",
      "05/04/2022 20:13:39 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:32<00:00,  3.58it/s, Epoch=29, LR=2.59e-10, Train_acc=0.975, key_attr_epoch_acc=0.988, key_attr_epoch_neg_acc=0.953, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.962, text_image_epoch_neg_acc=0.928, text_image_epoch_pos_acc=0.995]\n",
      "05/04/2022 20:16:12 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 20:16:12 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9747922389464607 -----> 0.9754167919464649\n",
      "05/04/2022 20:16:12 - INFO - root -   \n",
      "\n",
      "05/04/2022 20:16:14 - INFO - root -   Epoch:30\n",
      "100%|██████████| 1091/1091 [06:08<00:00,  2.96it/s, Epoch=30, LR=1.38e-6, Train_acc=0.97, key_attr_epoch_acc=0.984, key_attr_epoch_neg_acc=0.95, key_attr_epoch_pos_acc=0.993, text_image_epoch_acc=0.955, text_image_epoch_neg_acc=0.93, text_image_epoch_pos_acc=0.98]   \n",
      "05/04/2022 20:22:23 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:20<00:00,  3.88it/s, Epoch=30, LR=1.38e-6, Train_acc=0.975, key_attr_epoch_acc=0.989, key_attr_epoch_neg_acc=0.953, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.962, text_image_epoch_neg_acc=0.928, text_image_epoch_pos_acc=0.995]\n",
      "05/04/2022 20:24:43 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 20:24:43 - INFO - root -   Epoch:31\n",
      "100%|██████████| 1091/1091 [06:06<00:00,  2.98it/s, Epoch=31, LR=5.07e-6, Train_acc=0.969, key_attr_epoch_acc=0.984, key_attr_epoch_neg_acc=0.948, key_attr_epoch_pos_acc=0.993, text_image_epoch_acc=0.955, text_image_epoch_neg_acc=0.929, text_image_epoch_pos_acc=0.98] \n",
      "05/04/2022 20:30:50 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:22<00:00,  3.82it/s, Epoch=31, LR=5.07e-6, Train_acc=0.976, key_attr_epoch_acc=0.988, key_attr_epoch_neg_acc=0.953, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.963, text_image_epoch_neg_acc=0.93, text_image_epoch_pos_acc=0.996] \n",
      "05/04/2022 20:33:13 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 20:33:13 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9754167919464649 -----> 0.9758554535251543\n",
      "05/04/2022 20:33:13 - INFO - root -   \n",
      "\n",
      "05/04/2022 20:33:14 - INFO - root -   Epoch:32\n",
      "100%|██████████| 1091/1091 [06:08<00:00,  2.96it/s, Epoch=32, LR=1.01e-5, Train_acc=0.969, key_attr_epoch_acc=0.983, key_attr_epoch_neg_acc=0.948, key_attr_epoch_pos_acc=0.993, text_image_epoch_acc=0.955, text_image_epoch_neg_acc=0.929, text_image_epoch_pos_acc=0.98]\n",
      "05/04/2022 20:39:22 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:20<00:00,  3.87it/s, Epoch=32, LR=1.01e-5, Train_acc=0.976, key_attr_epoch_acc=0.989, key_attr_epoch_neg_acc=0.953, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.963, text_image_epoch_neg_acc=0.928, text_image_epoch_pos_acc=0.996]\n",
      "05/04/2022 20:41:43 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 20:41:43 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9758554535251543 -----> 0.9758911882965129\n",
      "05/04/2022 20:41:43 - INFO - root -   \n",
      "\n",
      "05/04/2022 20:41:45 - INFO - root -   Epoch:33\n",
      "100%|██████████| 1091/1091 [06:09<00:00,  2.96it/s, Epoch=33, LR=1.51e-5, Train_acc=0.968, key_attr_epoch_acc=0.982, key_attr_epoch_neg_acc=0.945, key_attr_epoch_pos_acc=0.992, text_image_epoch_acc=0.953, text_image_epoch_neg_acc=0.927, text_image_epoch_pos_acc=0.978]\n",
      "05/04/2022 20:47:54 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:22<00:00,  3.82it/s, Epoch=33, LR=1.51e-5, Train_acc=0.977, key_attr_epoch_acc=0.989, key_attr_epoch_neg_acc=0.954, key_attr_epoch_pos_acc=0.999, text_image_epoch_acc=0.964, text_image_epoch_neg_acc=0.93, text_image_epoch_pos_acc=0.997] \n",
      "05/04/2022 20:50:17 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 20:50:17 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9758911882965129 -----> 0.9767004321107468\n",
      "05/04/2022 20:50:17 - INFO - root -   \n",
      "\n",
      "05/04/2022 20:50:19 - INFO - root -   Epoch:34\n",
      "100%|██████████| 1091/1091 [06:08<00:00,  2.96it/s, Epoch=34, LR=1.87e-5, Train_acc=0.967, key_attr_epoch_acc=0.982, key_attr_epoch_neg_acc=0.944, key_attr_epoch_pos_acc=0.992, text_image_epoch_acc=0.953, text_image_epoch_neg_acc=0.927, text_image_epoch_pos_acc=0.978]\n",
      "05/04/2022 20:56:27 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:21<00:00,  3.85it/s, Epoch=34, LR=1.87e-5, Train_acc=0.977, key_attr_epoch_acc=0.989, key_attr_epoch_neg_acc=0.953, key_attr_epoch_pos_acc=0.999, text_image_epoch_acc=0.964, text_image_epoch_neg_acc=0.93, text_image_epoch_pos_acc=0.997] \n",
      "05/04/2022 20:58:49 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 20:58:49 - INFO - root -   Epoch:35\n",
      "100%|██████████| 1091/1091 [06:09<00:00,  2.95it/s, Epoch=35, LR=2e-5, Train_acc=0.967, key_attr_epoch_acc=0.982, key_attr_epoch_neg_acc=0.944, key_attr_epoch_pos_acc=0.992, text_image_epoch_acc=0.952, text_image_epoch_neg_acc=0.926, text_image_epoch_pos_acc=0.977]  \n",
      "05/04/2022 21:04:58 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:21<00:00,  3.86it/s, Epoch=35, LR=2e-5, Train_acc=0.977, key_attr_epoch_acc=0.99, key_attr_epoch_neg_acc=0.956, key_attr_epoch_pos_acc=0.999, text_image_epoch_acc=0.965, text_image_epoch_neg_acc=0.931, text_image_epoch_pos_acc=0.998] \n",
      "05/04/2022 21:07:20 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 21:07:20 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9767004321107468 -----> 0.9771600220583437\n",
      "05/04/2022 21:07:20 - INFO - root -   \n",
      "\n",
      "05/04/2022 21:07:21 - INFO - root -   Epoch:36\n",
      "100%|██████████| 1091/1091 [06:10<00:00,  2.95it/s, Epoch=36, LR=1.86e-5, Train_acc=0.968, key_attr_epoch_acc=0.983, key_attr_epoch_neg_acc=0.946, key_attr_epoch_pos_acc=0.992, text_image_epoch_acc=0.953, text_image_epoch_neg_acc=0.928, text_image_epoch_pos_acc=0.978]\n",
      "05/04/2022 21:13:32 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:22<00:00,  3.84it/s, Epoch=36, LR=1.86e-5, Train_acc=0.977, key_attr_epoch_acc=0.989, key_attr_epoch_neg_acc=0.954, key_attr_epoch_pos_acc=0.999, text_image_epoch_acc=0.964, text_image_epoch_neg_acc=0.93, text_image_epoch_pos_acc=0.998] \n",
      "05/04/2022 21:15:54 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 21:15:54 - INFO - root -   Epoch:37\n",
      "100%|██████████| 1091/1091 [06:09<00:00,  2.96it/s, Epoch=37, LR=1.49e-5, Train_acc=0.969, key_attr_epoch_acc=0.984, key_attr_epoch_neg_acc=0.949, key_attr_epoch_pos_acc=0.993, text_image_epoch_acc=0.955, text_image_epoch_neg_acc=0.93, text_image_epoch_pos_acc=0.979]\n",
      "05/04/2022 21:22:03 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:19<00:00,  3.90it/s, Epoch=37, LR=1.49e-5, Train_acc=0.979, key_attr_epoch_acc=0.991, key_attr_epoch_neg_acc=0.959, key_attr_epoch_pos_acc=0.999, text_image_epoch_acc=0.967, text_image_epoch_neg_acc=0.935, text_image_epoch_pos_acc=0.998]\n",
      "05/04/2022 21:24:23 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 21:24:23 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9771600220583437 -----> 0.9788657210437743\n",
      "05/04/2022 21:24:23 - INFO - root -   \n",
      "\n",
      "05/04/2022 21:24:24 - INFO - root -   Epoch:38\n",
      "100%|██████████| 1091/1091 [06:06<00:00,  2.98it/s, Epoch=38, LR=9.91e-6, Train_acc=0.971, key_attr_epoch_acc=0.985, key_attr_epoch_neg_acc=0.953, key_attr_epoch_pos_acc=0.994, text_image_epoch_acc=0.957, text_image_epoch_neg_acc=0.933, text_image_epoch_pos_acc=0.981]\n",
      "05/04/2022 21:30:31 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:23<00:00,  3.80it/s, Epoch=38, LR=9.91e-6, Train_acc=0.98, key_attr_epoch_acc=0.991, key_attr_epoch_neg_acc=0.962, key_attr_epoch_pos_acc=0.999, text_image_epoch_acc=0.968, text_image_epoch_neg_acc=0.937, text_image_epoch_pos_acc=0.998] \n",
      "05/04/2022 21:32:54 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 21:32:54 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9788657210437743 -----> 0.9796143366650601\n",
      "05/04/2022 21:32:54 - INFO - root -   \n",
      "\n",
      "05/04/2022 21:32:56 - INFO - root -   Epoch:39\n",
      "100%|██████████| 1091/1091 [06:10<00:00,  2.95it/s, Epoch=39, LR=4.92e-6, Train_acc=0.974, key_attr_epoch_acc=0.987, key_attr_epoch_neg_acc=0.959, key_attr_epoch_pos_acc=0.994, text_image_epoch_acc=0.96, text_image_epoch_neg_acc=0.937, text_image_epoch_pos_acc=0.983] \n",
      "05/04/2022 21:39:06 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:19<00:00,  3.90it/s, Epoch=39, LR=4.92e-6, Train_acc=0.981, key_attr_epoch_acc=0.992, key_attr_epoch_neg_acc=0.966, key_attr_epoch_pos_acc=0.999, text_image_epoch_acc=0.969, text_image_epoch_neg_acc=0.939, text_image_epoch_pos_acc=0.998]\n",
      "05/04/2022 21:41:26 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 21:41:26 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9796143366650601 -----> 0.9805780948847811\n",
      "05/04/2022 21:41:26 - INFO - root -   \n",
      "\n",
      "05/04/2022 21:41:28 - INFO - root -   Epoch:40\n",
      "100%|██████████| 1091/1091 [06:10<00:00,  2.95it/s, Epoch=40, LR=1.29e-6, Train_acc=0.976, key_attr_epoch_acc=0.988, key_attr_epoch_neg_acc=0.963, key_attr_epoch_pos_acc=0.995, text_image_epoch_acc=0.963, text_image_epoch_neg_acc=0.941, text_image_epoch_pos_acc=0.985]\n",
      "05/04/2022 21:47:38 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:22<00:00,  3.82it/s, Epoch=40, LR=1.29e-6, Train_acc=0.981, key_attr_epoch_acc=0.992, key_attr_epoch_neg_acc=0.967, key_attr_epoch_pos_acc=0.999, text_image_epoch_acc=0.97, text_image_epoch_neg_acc=0.941, text_image_epoch_pos_acc=0.998] \n",
      "05/04/2022 21:50:01 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 21:50:01 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9805780948847811 -----> 0.9811896699815879\n",
      "05/04/2022 21:50:01 - INFO - root -   \n",
      "\n",
      "05/04/2022 21:50:03 - INFO - root -   Epoch:41\n",
      "100%|██████████| 1091/1091 [06:09<00:00,  2.95it/s, Epoch=41, LR=5.08e-10, Train_acc=0.977, key_attr_epoch_acc=0.989, key_attr_epoch_neg_acc=0.965, key_attr_epoch_pos_acc=0.996, text_image_epoch_acc=0.964, text_image_epoch_neg_acc=0.941, text_image_epoch_pos_acc=0.987]\n",
      "05/04/2022 21:56:13 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:21<00:00,  3.85it/s, Epoch=41, LR=5.08e-10, Train_acc=0.982, key_attr_epoch_acc=0.993, key_attr_epoch_neg_acc=0.968, key_attr_epoch_pos_acc=0.999, text_image_epoch_acc=0.97, text_image_epoch_neg_acc=0.942, text_image_epoch_pos_acc=0.998] \n",
      "05/04/2022 21:58:35 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 21:58:35 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9811896699815879 -----> 0.9815164817968418\n",
      "05/04/2022 21:58:35 - INFO - root -   \n",
      "\n",
      "05/04/2022 21:58:37 - INFO - root -   Epoch:42\n",
      "100%|██████████| 1091/1091 [06:08<00:00,  2.96it/s, Epoch=42, LR=1.39e-6, Train_acc=0.976, key_attr_epoch_acc=0.989, key_attr_epoch_neg_acc=0.964, key_attr_epoch_pos_acc=0.995, text_image_epoch_acc=0.964, text_image_epoch_neg_acc=0.941, text_image_epoch_pos_acc=0.986]\n",
      "05/04/2022 22:04:46 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:21<00:00,  3.87it/s, Epoch=42, LR=1.39e-6, Train_acc=0.982, key_attr_epoch_acc=0.993, key_attr_epoch_neg_acc=0.97, key_attr_epoch_pos_acc=0.999, text_image_epoch_acc=0.97, text_image_epoch_neg_acc=0.942, text_image_epoch_pos_acc=0.998]  \n",
      "05/04/2022 22:07:07 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 22:07:07 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9815164817968418 -----> 0.9816661069871213\n",
      "05/04/2022 22:07:07 - INFO - root -   \n",
      "\n",
      "05/04/2022 22:07:09 - INFO - root -   Epoch:43\n",
      "100%|██████████| 1091/1091 [06:06<00:00,  2.97it/s, Epoch=43, LR=5.09e-6, Train_acc=0.977, key_attr_epoch_acc=0.989, key_attr_epoch_neg_acc=0.964, key_attr_epoch_pos_acc=0.995, text_image_epoch_acc=0.964, text_image_epoch_neg_acc=0.942, text_image_epoch_pos_acc=0.986]\n",
      "05/04/2022 22:13:15 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:24<00:00,  3.77it/s, Epoch=43, LR=5.09e-6, Train_acc=0.982, key_attr_epoch_acc=0.993, key_attr_epoch_neg_acc=0.97, key_attr_epoch_pos_acc=0.999, text_image_epoch_acc=0.971, text_image_epoch_neg_acc=0.943, text_image_epoch_pos_acc=0.998] \n",
      "05/04/2022 22:15:40 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 22:15:40 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9816661069871213 -----> 0.982117629676171\n",
      "05/04/2022 22:15:40 - INFO - root -   \n",
      "\n",
      "05/04/2022 22:15:42 - INFO - root -   Epoch:44\n",
      "100%|██████████| 1091/1091 [06:11<00:00,  2.94it/s, Epoch=44, LR=1.01e-5, Train_acc=0.976, key_attr_epoch_acc=0.989, key_attr_epoch_neg_acc=0.964, key_attr_epoch_pos_acc=0.995, text_image_epoch_acc=0.964, text_image_epoch_neg_acc=0.941, text_image_epoch_pos_acc=0.986]\n",
      "05/04/2022 22:21:53 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:18<00:00,  3.93it/s, Epoch=44, LR=1.01e-5, Train_acc=0.982, key_attr_epoch_acc=0.993, key_attr_epoch_neg_acc=0.97, key_attr_epoch_pos_acc=0.999, text_image_epoch_acc=0.97, text_image_epoch_neg_acc=0.941, text_image_epoch_pos_acc=0.998]  \n",
      "05/04/2022 22:24:12 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 22:24:12 - INFO - root -   Epoch:45\n",
      "100%|██████████| 1091/1091 [06:07<00:00,  2.97it/s, Epoch=45, LR=1.51e-5, Train_acc=0.975, key_attr_epoch_acc=0.988, key_attr_epoch_neg_acc=0.962, key_attr_epoch_pos_acc=0.995, text_image_epoch_acc=0.962, text_image_epoch_neg_acc=0.939, text_image_epoch_pos_acc=0.984]\n",
      "05/04/2022 22:30:19 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:20<00:00,  3.87it/s, Epoch=45, LR=1.51e-5, Train_acc=0.982, key_attr_epoch_acc=0.993, key_attr_epoch_neg_acc=0.97, key_attr_epoch_pos_acc=0.999, text_image_epoch_acc=0.971, text_image_epoch_neg_acc=0.943, text_image_epoch_pos_acc=0.999] \n",
      "05/04/2022 22:32:40 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 22:32:40 - INFO - root -   Epoch:46\n",
      "100%|██████████| 1091/1091 [06:07<00:00,  2.97it/s, Epoch=46, LR=1.87e-5, Train_acc=0.973, key_attr_epoch_acc=0.986, key_attr_epoch_neg_acc=0.958, key_attr_epoch_pos_acc=0.994, text_image_epoch_acc=0.96, text_image_epoch_neg_acc=0.937, text_image_epoch_pos_acc=0.982]\n",
      "05/04/2022 22:38:47 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:21<00:00,  3.86it/s, Epoch=46, LR=1.87e-5, Train_acc=0.982, key_attr_epoch_acc=0.993, key_attr_epoch_neg_acc=0.97, key_attr_epoch_pos_acc=0.999, text_image_epoch_acc=0.971, text_image_epoch_neg_acc=0.941, text_image_epoch_pos_acc=0.999] \n",
      "05/04/2022 22:41:09 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 22:41:09 - INFO - root -   Epoch:47\n",
      "100%|██████████| 1091/1091 [06:08<00:00,  2.96it/s, Epoch=47, LR=2e-5, Train_acc=0.973, key_attr_epoch_acc=0.986, key_attr_epoch_neg_acc=0.958, key_attr_epoch_pos_acc=0.994, text_image_epoch_acc=0.959, text_image_epoch_neg_acc=0.937, text_image_epoch_pos_acc=0.982]  \n",
      "05/04/2022 22:47:17 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:19<00:00,  3.90it/s, Epoch=47, LR=2e-5, Train_acc=0.982, key_attr_epoch_acc=0.993, key_attr_epoch_neg_acc=0.969, key_attr_epoch_pos_acc=0.999, text_image_epoch_acc=0.97, text_image_epoch_neg_acc=0.941, text_image_epoch_pos_acc=0.999] \n",
      "05/04/2022 22:49:37 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 22:49:37 - INFO - root -   Epoch:48\n",
      "100%|██████████| 1091/1091 [06:27<00:00,  2.81it/s, Epoch=48, LR=1.86e-5, Train_acc=0.974, key_attr_epoch_acc=0.987, key_attr_epoch_neg_acc=0.961, key_attr_epoch_pos_acc=0.994, text_image_epoch_acc=0.961, text_image_epoch_neg_acc=0.939, text_image_epoch_pos_acc=0.982]\n",
      "05/04/2022 22:56:05 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [03:14<00:00,  2.80it/s, Epoch=48, LR=1.86e-5, Train_acc=0.983, key_attr_epoch_acc=0.994, key_attr_epoch_neg_acc=0.972, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.971, text_image_epoch_neg_acc=0.943, text_image_epoch_pos_acc=0.999]\n",
      "05/04/2022 22:59:20 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 22:59:20 - INFO - root -   Weighted_acc improved: best_acc improved from 0.982117629676171 -----> 0.9825408044557316\n",
      "05/04/2022 22:59:20 - INFO - root -   \n",
      "\n",
      "05/04/2022 22:59:22 - INFO - root -   Epoch:49\n",
      "100%|██████████| 1091/1091 [08:07<00:00,  2.24it/s, Epoch=49, LR=1.49e-5, Train_acc=0.975, key_attr_epoch_acc=0.988, key_attr_epoch_neg_acc=0.962, key_attr_epoch_pos_acc=0.995, text_image_epoch_acc=0.962, text_image_epoch_neg_acc=0.939, text_image_epoch_pos_acc=0.984]\n",
      "05/04/2022 23:07:30 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:44<00:00,  3.32it/s, Epoch=49, LR=1.49e-5, Train_acc=0.983, key_attr_epoch_acc=0.994, key_attr_epoch_neg_acc=0.973, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.971, text_image_epoch_neg_acc=0.943, text_image_epoch_pos_acc=0.999]    \n",
      "05/04/2022 23:10:14 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 23:10:14 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9825408044557316 -----> 0.982664037743334\n",
      "05/04/2022 23:10:14 - INFO - root -   \n",
      "\n",
      "05/04/2022 23:10:16 - INFO - root -   Epoch:50\n",
      "100%|██████████| 1091/1091 [06:12<00:00,  2.93it/s, Epoch=50, LR=9.88e-6, Train_acc=0.977, key_attr_epoch_acc=0.989, key_attr_epoch_neg_acc=0.967, key_attr_epoch_pos_acc=0.995, text_image_epoch_acc=0.964, text_image_epoch_neg_acc=0.943, text_image_epoch_pos_acc=0.985]\n",
      "05/04/2022 23:16:28 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:40<00:00,  3.41it/s, Epoch=50, LR=9.88e-6, Train_acc=0.983, key_attr_epoch_acc=0.994, key_attr_epoch_neg_acc=0.974, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.972, text_image_epoch_neg_acc=0.945, text_image_epoch_pos_acc=0.999]   \n",
      "05/04/2022 23:19:09 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 23:19:09 - INFO - root -   Weighted_acc improved: best_acc improved from 0.982664037743334 -----> 0.983286954039971\n",
      "05/04/2022 23:19:09 - INFO - root -   \n",
      "\n",
      "05/04/2022 23:19:11 - INFO - root -   Epoch:51\n",
      "100%|██████████| 1091/1091 [08:16<00:00,  2.20it/s, Epoch=51, LR=4.89e-6, Train_acc=0.978, key_attr_epoch_acc=0.99, key_attr_epoch_neg_acc=0.969, key_attr_epoch_pos_acc=0.996, text_image_epoch_acc=0.967, text_image_epoch_neg_acc=0.945, text_image_epoch_pos_acc=0.987]\n",
      "05/04/2022 23:27:28 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:36<00:00,  3.48it/s, Epoch=51, LR=4.89e-6, Train_acc=0.984, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.976, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.974, text_image_epoch_neg_acc=0.948, text_image_epoch_pos_acc=0.999]   \n",
      "05/04/2022 23:30:05 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 23:30:05 - INFO - root -   Weighted_acc improved: best_acc improved from 0.983286954039971 -----> 0.9840361011209335\n",
      "05/04/2022 23:30:05 - INFO - root -   \n",
      "\n",
      "05/04/2022 23:30:07 - INFO - root -   Epoch:52\n",
      "100%|██████████| 1091/1091 [06:12<00:00,  2.93it/s, Epoch=52, LR=1.28e-6, Train_acc=0.98, key_attr_epoch_acc=0.991, key_attr_epoch_neg_acc=0.973, key_attr_epoch_pos_acc=0.996, text_image_epoch_acc=0.968, text_image_epoch_neg_acc=0.947, text_image_epoch_pos_acc=0.988] \n",
      "05/04/2022 23:36:19 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:28<00:00,  3.67it/s, Epoch=52, LR=1.28e-6, Train_acc=0.984, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.978, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.974, text_image_epoch_neg_acc=0.949, text_image_epoch_pos_acc=0.999]\n",
      "05/04/2022 23:38:47 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 23:38:47 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9840361011209335 -----> 0.98444714822587\n",
      "05/04/2022 23:38:47 - INFO - root -   \n",
      "\n",
      "05/04/2022 23:38:50 - INFO - root -   Epoch:53\n",
      "100%|██████████| 1091/1091 [06:15<00:00,  2.90it/s, Epoch=53, LR=8.4e-10, Train_acc=0.98, key_attr_epoch_acc=0.992, key_attr_epoch_neg_acc=0.974, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.969, text_image_epoch_neg_acc=0.948, text_image_epoch_pos_acc=0.989] \n",
      "05/04/2022 23:45:05 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:25<00:00,  3.75it/s, Epoch=53, LR=8.4e-10, Train_acc=0.985, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.978, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.975, text_image_epoch_neg_acc=0.951, text_image_epoch_pos_acc=0.999]    \n",
      "05/04/2022 23:47:31 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 23:47:31 - INFO - root -   Weighted_acc improved: best_acc improved from 0.98444714822587 -----> 0.9851175021214771\n",
      "05/04/2022 23:47:31 - INFO - root -   \n",
      "\n",
      "05/04/2022 23:47:33 - INFO - root -   Epoch:54\n",
      "100%|██████████| 1091/1091 [06:15<00:00,  2.91it/s, Epoch=54, LR=1.41e-6, Train_acc=0.981, key_attr_epoch_acc=0.992, key_attr_epoch_neg_acc=0.973, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.969, text_image_epoch_neg_acc=0.948, text_image_epoch_pos_acc=0.989]\n",
      "05/04/2022 23:53:48 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:26<00:00,  3.73it/s, Epoch=54, LR=1.41e-6, Train_acc=0.985, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.979, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.975, text_image_epoch_neg_acc=0.95, text_image_epoch_pos_acc=0.999]   \n",
      "05/04/2022 23:56:15 - INFO - root -   ***** Eval results %s *****\n",
      "05/04/2022 23:56:15 - INFO - root -   Epoch:55\n",
      "100%|██████████| 1091/1091 [06:13<00:00,  2.92it/s, Epoch=55, LR=5.12e-6, Train_acc=0.981, key_attr_epoch_acc=0.992, key_attr_epoch_neg_acc=0.975, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.97, text_image_epoch_neg_acc=0.949, text_image_epoch_pos_acc=0.99] \n",
      "05/05/2022 00:02:28 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:29<00:00,  3.65it/s, Epoch=55, LR=5.12e-6, Train_acc=0.985, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.979, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.974, text_image_epoch_neg_acc=0.949, text_image_epoch_pos_acc=0.999]\n",
      "05/05/2022 00:04:58 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 00:04:58 - INFO - root -   Epoch:56\n",
      "100%|██████████| 1091/1091 [06:11<00:00,  2.93it/s, Epoch=56, LR=1.01e-5, Train_acc=0.98, key_attr_epoch_acc=0.992, key_attr_epoch_neg_acc=0.973, key_attr_epoch_pos_acc=0.996, text_image_epoch_acc=0.968, text_image_epoch_neg_acc=0.948, text_image_epoch_pos_acc=0.988]\n",
      "05/05/2022 00:11:09 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:29<00:00,  3.65it/s, Epoch=56, LR=1.01e-5, Train_acc=0.985, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.979, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.975, text_image_epoch_neg_acc=0.95, text_image_epoch_pos_acc=0.999] \n",
      "05/05/2022 00:13:39 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 00:13:39 - INFO - root -   Epoch:57\n",
      "100%|██████████| 1091/1091 [06:13<00:00,  2.92it/s, Epoch=57, LR=1.51e-5, Train_acc=0.979, key_attr_epoch_acc=0.991, key_attr_epoch_neg_acc=0.972, key_attr_epoch_pos_acc=0.996, text_image_epoch_acc=0.968, text_image_epoch_neg_acc=0.946, text_image_epoch_pos_acc=0.988]\n",
      "05/05/2022 00:19:52 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:28<00:00,  3.68it/s, Epoch=57, LR=1.51e-5, Train_acc=0.986, key_attr_epoch_acc=0.996, key_attr_epoch_neg_acc=0.98, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.976, text_image_epoch_neg_acc=0.951, text_image_epoch_pos_acc=0.999] \n",
      "05/05/2022 00:22:21 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 00:22:21 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9851175021214771 -----> 0.985637656508243\n",
      "05/05/2022 00:22:21 - INFO - root -   \n",
      "\n",
      "05/05/2022 00:22:23 - INFO - root -   Epoch:58\n",
      "100%|██████████| 1091/1091 [06:17<00:00,  2.89it/s, Epoch=58, LR=1.87e-5, Train_acc=0.977, key_attr_epoch_acc=0.989, key_attr_epoch_neg_acc=0.968, key_attr_epoch_pos_acc=0.995, text_image_epoch_acc=0.965, text_image_epoch_neg_acc=0.944, text_image_epoch_pos_acc=0.986]\n",
      "05/05/2022 00:28:41 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:26<00:00,  3.73it/s, Epoch=58, LR=1.87e-5, Train_acc=0.985, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.979, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.975, text_image_epoch_neg_acc=0.95, text_image_epoch_pos_acc=0.999] \n",
      "05/05/2022 00:31:07 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 00:31:07 - INFO - root -   Epoch:59\n",
      "100%|██████████| 1091/1091 [06:13<00:00,  2.92it/s, Epoch=59, LR=2e-5, Train_acc=0.977, key_attr_epoch_acc=0.989, key_attr_epoch_neg_acc=0.967, key_attr_epoch_pos_acc=0.995, text_image_epoch_acc=0.964, text_image_epoch_neg_acc=0.944, text_image_epoch_pos_acc=0.984]  \n",
      "05/05/2022 00:37:21 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:26<00:00,  3.73it/s, Epoch=59, LR=2e-5, Train_acc=0.984, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.977, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.973, text_image_epoch_neg_acc=0.947, text_image_epoch_pos_acc=0.999]\n",
      "05/05/2022 00:39:47 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 00:39:47 - INFO - root -   Epoch:60\n",
      "100%|██████████| 1091/1091 [06:14<00:00,  2.91it/s, Epoch=60, LR=1.86e-5, Train_acc=0.977, key_attr_epoch_acc=0.989, key_attr_epoch_neg_acc=0.968, key_attr_epoch_pos_acc=0.995, text_image_epoch_acc=0.965, text_image_epoch_neg_acc=0.944, text_image_epoch_pos_acc=0.985]\n",
      "05/05/2022 00:46:02 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:27<00:00,  3.69it/s, Epoch=60, LR=1.86e-5, Train_acc=0.985, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.979, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.975, text_image_epoch_neg_acc=0.95, text_image_epoch_pos_acc=0.999]    \n",
      "05/05/2022 00:48:30 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 00:48:30 - INFO - root -   Epoch:61\n",
      "100%|██████████| 1091/1091 [06:09<00:00,  2.95it/s, Epoch=61, LR=1.49e-5, Train_acc=0.978, key_attr_epoch_acc=0.99, key_attr_epoch_neg_acc=0.971, key_attr_epoch_pos_acc=0.996, text_image_epoch_acc=0.966, text_image_epoch_neg_acc=0.946, text_image_epoch_pos_acc=0.986] \n",
      "05/05/2022 00:54:39 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:28<00:00,  3.67it/s, Epoch=61, LR=1.49e-5, Train_acc=0.985, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.98, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.975, text_image_epoch_neg_acc=0.951, text_image_epoch_pos_acc=0.999]   \n",
      "05/05/2022 00:57:08 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 00:57:08 - INFO - root -   Epoch:62\n",
      "100%|██████████| 1091/1091 [06:15<00:00,  2.90it/s, Epoch=62, LR=9.85e-6, Train_acc=0.98, key_attr_epoch_acc=0.991, key_attr_epoch_neg_acc=0.974, key_attr_epoch_pos_acc=0.996, text_image_epoch_acc=0.969, text_image_epoch_neg_acc=0.948, text_image_epoch_pos_acc=0.988]\n",
      "05/05/2022 01:03:24 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:28<00:00,  3.68it/s, Epoch=62, LR=9.85e-6, Train_acc=0.986, key_attr_epoch_acc=0.996, key_attr_epoch_neg_acc=0.982, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.975, text_image_epoch_neg_acc=0.95, text_image_epoch_pos_acc=0.999] \n",
      "05/05/2022 01:05:52 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 01:05:52 - INFO - root -   Epoch:63\n",
      "100%|██████████| 1091/1091 [06:12<00:00,  2.93it/s, Epoch=63, LR=4.87e-6, Train_acc=0.981, key_attr_epoch_acc=0.992, key_attr_epoch_neg_acc=0.976, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.97, text_image_epoch_neg_acc=0.951, text_image_epoch_pos_acc=0.989]\n",
      "05/05/2022 01:12:05 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:27<00:00,  3.70it/s, Epoch=63, LR=4.87e-6, Train_acc=0.986, key_attr_epoch_acc=0.996, key_attr_epoch_neg_acc=0.982, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.976, text_image_epoch_neg_acc=0.952, text_image_epoch_pos_acc=0.999]\n",
      "05/05/2022 01:14:33 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 01:14:33 - INFO - root -   Weighted_acc improved: best_acc improved from 0.985637656508243 -----> 0.985892222486159\n",
      "05/05/2022 01:14:33 - INFO - root -   \n",
      "\n",
      "05/05/2022 01:14:35 - INFO - root -   Epoch:64\n",
      "100%|██████████| 1091/1091 [06:14<00:00,  2.91it/s, Epoch=64, LR=1.26e-6, Train_acc=0.982, key_attr_epoch_acc=0.993, key_attr_epoch_neg_acc=0.979, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.971, text_image_epoch_neg_acc=0.952, text_image_epoch_pos_acc=0.99]\n",
      "05/05/2022 01:20:50 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:27<00:00,  3.70it/s, Epoch=64, LR=1.26e-6, Train_acc=0.987, key_attr_epoch_acc=0.996, key_attr_epoch_neg_acc=0.984, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.977, text_image_epoch_neg_acc=0.954, text_image_epoch_pos_acc=0.999]   \n",
      "05/05/2022 01:23:18 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 01:23:18 - INFO - root -   Weighted_acc improved: best_acc improved from 0.985892222486159 -----> 0.9866529020282897\n",
      "05/05/2022 01:23:18 - INFO - root -   \n",
      "\n",
      "05/05/2022 01:23:19 - INFO - root -   Epoch:65\n",
      "100%|██████████| 1091/1091 [06:14<00:00,  2.91it/s, Epoch=65, LR=1.26e-9, Train_acc=0.983, key_attr_epoch_acc=0.994, key_attr_epoch_neg_acc=0.98, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.973, text_image_epoch_neg_acc=0.953, text_image_epoch_pos_acc=0.991] \n",
      "05/05/2022 01:29:34 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:28<00:00,  3.68it/s, Epoch=65, LR=1.26e-9, Train_acc=0.987, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.985, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.977, text_image_epoch_neg_acc=0.954, text_image_epoch_pos_acc=0.999]\n",
      "05/05/2022 01:32:02 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 01:32:02 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9866529020282897 -----> 0.9866817492532918\n",
      "05/05/2022 01:32:02 - INFO - root -   \n",
      "\n",
      "05/05/2022 01:32:04 - INFO - root -   Epoch:66\n",
      "100%|██████████| 1091/1091 [06:09<00:00,  2.95it/s, Epoch=66, LR=1.42e-6, Train_acc=0.984, key_attr_epoch_acc=0.994, key_attr_epoch_neg_acc=0.981, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.973, text_image_epoch_neg_acc=0.954, text_image_epoch_pos_acc=0.991]\n",
      "05/05/2022 01:38:14 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:25<00:00,  3.74it/s, Epoch=66, LR=1.42e-6, Train_acc=0.986, key_attr_epoch_acc=0.996, key_attr_epoch_neg_acc=0.984, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.976, text_image_epoch_neg_acc=0.952, text_image_epoch_pos_acc=0.999]\n",
      "05/05/2022 01:40:40 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 01:40:40 - INFO - root -   Epoch:67\n",
      "100%|██████████| 1091/1091 [06:14<00:00,  2.91it/s, Epoch=67, LR=5.14e-6, Train_acc=0.983, key_attr_epoch_acc=0.994, key_attr_epoch_neg_acc=0.98, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.973, text_image_epoch_neg_acc=0.953, text_image_epoch_pos_acc=0.991] \n",
      "05/05/2022 01:46:55 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:29<00:00,  3.65it/s, Epoch=67, LR=5.14e-6, Train_acc=0.987, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.985, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.977, text_image_epoch_neg_acc=0.954, text_image_epoch_pos_acc=0.999]\n",
      "05/05/2022 01:49:24 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 01:49:24 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9866817492532918 -----> 0.9868262194985252\n",
      "05/05/2022 01:49:24 - INFO - root -   \n",
      "\n",
      "05/05/2022 01:49:26 - INFO - root -   Epoch:68\n",
      "100%|██████████| 1091/1091 [06:12<00:00,  2.93it/s, Epoch=68, LR=1.02e-5, Train_acc=0.983, key_attr_epoch_acc=0.993, key_attr_epoch_neg_acc=0.98, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.972, text_image_epoch_neg_acc=0.953, text_image_epoch_pos_acc=0.99] \n",
      "05/05/2022 01:55:39 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:26<00:00,  3.73it/s, Epoch=68, LR=1.02e-5, Train_acc=0.987, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.985, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.978, text_image_epoch_neg_acc=0.955, text_image_epoch_pos_acc=0.999]\n",
      "05/05/2022 01:58:05 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 01:58:05 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9868262194985252 -----> 0.9870794145029124\n",
      "05/05/2022 01:58:05 - INFO - root -   \n",
      "\n",
      "05/05/2022 01:58:07 - INFO - root -   Epoch:69\n",
      "100%|██████████| 1091/1091 [06:14<00:00,  2.91it/s, Epoch=69, LR=1.51e-5, Train_acc=0.981, key_attr_epoch_acc=0.993, key_attr_epoch_neg_acc=0.978, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.97, text_image_epoch_neg_acc=0.952, text_image_epoch_pos_acc=0.989] \n",
      "05/05/2022 02:04:22 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:25<00:00,  3.75it/s, Epoch=69, LR=1.51e-5, Train_acc=0.987, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.985, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.977, text_image_epoch_neg_acc=0.953, text_image_epoch_pos_acc=0.999]\n",
      "05/05/2022 02:06:48 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 02:06:48 - INFO - root -   Epoch:70\n",
      "100%|██████████| 1091/1091 [06:15<00:00,  2.91it/s, Epoch=70, LR=1.87e-5, Train_acc=0.98, key_attr_epoch_acc=0.992, key_attr_epoch_neg_acc=0.974, key_attr_epoch_pos_acc=0.996, text_image_epoch_acc=0.969, text_image_epoch_neg_acc=0.948, text_image_epoch_pos_acc=0.988]\n",
      "05/05/2022 02:13:03 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:31<00:00,  3.61it/s, Epoch=70, LR=1.87e-5, Train_acc=0.987, key_attr_epoch_acc=0.996, key_attr_epoch_neg_acc=0.984, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.977, text_image_epoch_neg_acc=0.953, text_image_epoch_pos_acc=0.999]\n",
      "05/05/2022 02:15:34 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 02:15:34 - INFO - root -   Epoch:71\n",
      "100%|██████████| 1091/1091 [06:09<00:00,  2.96it/s, Epoch=71, LR=2e-5, Train_acc=0.98, key_attr_epoch_acc=0.991, key_attr_epoch_neg_acc=0.974, key_attr_epoch_pos_acc=0.996, text_image_epoch_acc=0.968, text_image_epoch_neg_acc=0.949, text_image_epoch_pos_acc=0.987]   \n",
      "05/05/2022 02:21:43 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:25<00:00,  3.75it/s, Epoch=71, LR=2e-5, Train_acc=0.987, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.984, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.977, text_image_epoch_neg_acc=0.954, text_image_epoch_pos_acc=1]   \n",
      "05/05/2022 02:24:09 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 02:24:09 - INFO - root -   Epoch:72\n",
      "100%|██████████| 1091/1091 [06:15<00:00,  2.91it/s, Epoch=72, LR=1.86e-5, Train_acc=0.98, key_attr_epoch_acc=0.991, key_attr_epoch_neg_acc=0.974, key_attr_epoch_pos_acc=0.996, text_image_epoch_acc=0.968, text_image_epoch_neg_acc=0.948, text_image_epoch_pos_acc=0.988]\n",
      "05/05/2022 02:30:24 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:27<00:00,  3.71it/s, Epoch=72, LR=1.86e-5, Train_acc=0.987, key_attr_epoch_acc=0.996, key_attr_epoch_neg_acc=0.984, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.977, text_image_epoch_neg_acc=0.954, text_image_epoch_pos_acc=1]\n",
      "05/05/2022 02:32:51 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 02:32:51 - INFO - root -   Epoch:73\n",
      "100%|██████████| 1091/1091 [06:12<00:00,  2.93it/s, Epoch=73, LR=1.48e-5, Train_acc=0.981, key_attr_epoch_acc=0.992, key_attr_epoch_neg_acc=0.976, key_attr_epoch_pos_acc=0.996, text_image_epoch_acc=0.97, text_image_epoch_neg_acc=0.95, text_image_epoch_pos_acc=0.988] \n",
      "05/05/2022 02:39:03 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:25<00:00,  3.74it/s, Epoch=73, LR=1.48e-5, Train_acc=0.986, key_attr_epoch_acc=0.996, key_attr_epoch_neg_acc=0.984, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.976, text_image_epoch_neg_acc=0.953, text_image_epoch_pos_acc=0.999]\n",
      "05/05/2022 02:41:29 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 02:41:29 - INFO - root -   Epoch:74\n",
      "100%|██████████| 1091/1091 [06:16<00:00,  2.90it/s, Epoch=74, LR=9.82e-6, Train_acc=0.982, key_attr_epoch_acc=0.993, key_attr_epoch_neg_acc=0.98, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.971, text_image_epoch_neg_acc=0.952, text_image_epoch_pos_acc=0.99] \n",
      "05/05/2022 02:47:46 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:26<00:00,  3.72it/s, Epoch=74, LR=9.82e-6, Train_acc=0.987, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.985, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.977, text_image_epoch_neg_acc=0.954, text_image_epoch_pos_acc=0.999]\n",
      "05/05/2022 02:50:12 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 02:50:12 - INFO - root -   Epoch:75\n",
      "100%|██████████| 1091/1091 [06:11<00:00,  2.93it/s, Epoch=75, LR=4.84e-6, Train_acc=0.983, key_attr_epoch_acc=0.994, key_attr_epoch_neg_acc=0.982, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.973, text_image_epoch_neg_acc=0.954, text_image_epoch_pos_acc=0.991]\n",
      "05/05/2022 02:56:24 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:31<00:00,  3.61it/s, Epoch=75, LR=4.84e-6, Train_acc=0.988, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.987, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.978, text_image_epoch_neg_acc=0.957, text_image_epoch_pos_acc=0.999]  \n",
      "05/05/2022 02:58:56 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 02:58:56 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9870794145029124 -----> 0.9877231530903409\n",
      "05/05/2022 02:58:56 - INFO - root -   \n",
      "\n",
      "05/05/2022 02:58:58 - INFO - root -   Epoch:76\n",
      "100%|██████████| 1091/1091 [06:17<00:00,  2.89it/s, Epoch=76, LR=1.25e-6, Train_acc=0.985, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.983, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.974, text_image_epoch_neg_acc=0.956, text_image_epoch_pos_acc=0.992]\n",
      "05/05/2022 03:05:15 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:26<00:00,  3.74it/s, Epoch=76, LR=1.25e-6, Train_acc=0.987, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.987, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.978, text_image_epoch_neg_acc=0.956, text_image_epoch_pos_acc=0.999]  \n",
      "05/05/2022 03:07:41 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 03:07:41 - INFO - root -   Epoch:77\n",
      "100%|██████████| 1091/1091 [06:14<00:00,  2.91it/s, Epoch=77, LR=1.75e-9, Train_acc=0.985, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.985, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.975, text_image_epoch_neg_acc=0.956, text_image_epoch_pos_acc=0.993] \n",
      "05/05/2022 03:13:56 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:31<00:00,  3.59it/s, Epoch=77, LR=1.75e-9, Train_acc=0.988, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.989, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.978, text_image_epoch_neg_acc=0.957, text_image_epoch_pos_acc=0.999]\n",
      "05/05/2022 03:16:28 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 03:16:28 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9877231530903409 -----> 0.9879452791330755\n",
      "05/05/2022 03:16:28 - INFO - root -   \n",
      "\n",
      "05/05/2022 03:16:29 - INFO - root -   Epoch:78\n",
      "100%|██████████| 1091/1091 [06:11<00:00,  2.94it/s, Epoch=78, LR=1.44e-6, Train_acc=0.985, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.985, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.975, text_image_epoch_neg_acc=0.956, text_image_epoch_pos_acc=0.993]\n",
      "05/05/2022 03:22:41 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:25<00:00,  3.74it/s, Epoch=78, LR=1.44e-6, Train_acc=0.988, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.989, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.979, text_image_epoch_neg_acc=0.958, text_image_epoch_pos_acc=0.999]\n",
      "05/05/2022 03:25:07 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 03:25:07 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9879452791330755 -----> 0.9882516726096563\n",
      "05/05/2022 03:25:07 - INFO - root -   \n",
      "\n",
      "05/05/2022 03:25:09 - INFO - root -   Epoch:79\n",
      "100%|██████████| 1091/1091 [06:17<00:00,  2.89it/s, Epoch=79, LR=5.17e-6, Train_acc=0.985, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.985, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.975, text_image_epoch_neg_acc=0.957, text_image_epoch_pos_acc=0.993]\n",
      "05/05/2022 03:31:26 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:26<00:00,  3.74it/s, Epoch=79, LR=5.17e-6, Train_acc=0.988, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.988, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.979, text_image_epoch_neg_acc=0.958, text_image_epoch_pos_acc=0.999]\n",
      "05/05/2022 03:33:52 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 03:33:52 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9882516726096563 -----> 0.9882782772031137\n",
      "05/05/2022 03:33:52 - INFO - root -   \n",
      "\n",
      "05/05/2022 03:33:54 - INFO - root -   Epoch:80\n",
      "100%|██████████| 1091/1091 [06:13<00:00,  2.92it/s, Epoch=80, LR=1.02e-5, Train_acc=0.984, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.983, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.974, text_image_epoch_neg_acc=0.956, text_image_epoch_pos_acc=0.992]\n",
      "05/05/2022 03:40:08 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:30<00:00,  3.63it/s, Epoch=80, LR=1.02e-5, Train_acc=0.988, key_attr_epoch_acc=0.998, key_attr_epoch_neg_acc=0.989, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.979, text_image_epoch_neg_acc=0.957, text_image_epoch_pos_acc=0.999]\n",
      "05/05/2022 03:42:38 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 03:42:38 - INFO - root -   Epoch:81\n",
      "100%|██████████| 1091/1091 [06:15<00:00,  2.91it/s, Epoch=81, LR=1.52e-5, Train_acc=0.984, key_attr_epoch_acc=0.994, key_attr_epoch_neg_acc=0.982, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.973, text_image_epoch_neg_acc=0.955, text_image_epoch_pos_acc=0.991]\n",
      "05/05/2022 03:48:54 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:26<00:00,  3.73it/s, Epoch=81, LR=1.52e-5, Train_acc=0.988, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.988, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.978, text_image_epoch_neg_acc=0.955, text_image_epoch_pos_acc=1]\n",
      "05/05/2022 03:51:20 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 03:51:20 - INFO - root -   Epoch:82\n",
      "100%|██████████| 1091/1091 [06:11<00:00,  2.93it/s, Epoch=82, LR=1.88e-5, Train_acc=0.982, key_attr_epoch_acc=0.993, key_attr_epoch_neg_acc=0.98, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.972, text_image_epoch_neg_acc=0.953, text_image_epoch_pos_acc=0.99]  \n",
      "05/05/2022 03:57:32 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:32<00:00,  3.57it/s, Epoch=82, LR=1.88e-5, Train_acc=0.987, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.987, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.977, text_image_epoch_neg_acc=0.954, text_image_epoch_pos_acc=1]   \n",
      "05/05/2022 04:00:05 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 04:00:05 - INFO - root -   Epoch:83\n",
      "100%|██████████| 1091/1091 [06:13<00:00,  2.92it/s, Epoch=83, LR=2e-5, Train_acc=0.982, key_attr_epoch_acc=0.993, key_attr_epoch_neg_acc=0.978, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.971, text_image_epoch_neg_acc=0.953, text_image_epoch_pos_acc=0.989]  \n",
      "05/05/2022 04:06:18 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:27<00:00,  3.71it/s, Epoch=83, LR=2e-5, Train_acc=0.988, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.986, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.978, text_image_epoch_neg_acc=0.956, text_image_epoch_pos_acc=1]\n",
      "05/05/2022 04:08:45 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 04:08:45 - INFO - root -   Epoch:84\n",
      "100%|██████████| 1091/1091 [06:15<00:00,  2.90it/s, Epoch=84, LR=1.86e-5, Train_acc=0.982, key_attr_epoch_acc=0.993, key_attr_epoch_neg_acc=0.979, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.971, text_image_epoch_neg_acc=0.952, text_image_epoch_pos_acc=0.989]\n",
      "05/05/2022 04:15:01 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:27<00:00,  3.71it/s, Epoch=84, LR=1.86e-5, Train_acc=0.988, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.987, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.978, text_image_epoch_neg_acc=0.956, text_image_epoch_pos_acc=1]\n",
      "05/05/2022 04:17:29 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 04:17:29 - INFO - root -   Epoch:85\n",
      "100%|██████████| 1091/1091 [06:14<00:00,  2.91it/s, Epoch=85, LR=1.48e-5, Train_acc=0.983, key_attr_epoch_acc=0.993, key_attr_epoch_neg_acc=0.98, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.972, text_image_epoch_neg_acc=0.953, text_image_epoch_pos_acc=0.99]\n",
      "05/05/2022 04:23:43 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:29<00:00,  3.64it/s, Epoch=85, LR=1.48e-5, Train_acc=0.988, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.987, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.978, text_image_epoch_neg_acc=0.956, text_image_epoch_pos_acc=1]\n",
      "05/05/2022 04:26:13 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 04:26:13 - INFO - root -   Epoch:86\n",
      "100%|██████████| 1091/1091 [06:15<00:00,  2.90it/s, Epoch=86, LR=9.79e-6, Train_acc=0.984, key_attr_epoch_acc=0.994, key_attr_epoch_neg_acc=0.983, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.974, text_image_epoch_neg_acc=0.955, text_image_epoch_pos_acc=0.991]\n",
      "05/05/2022 04:32:29 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:26<00:00,  3.74it/s, Epoch=86, LR=9.79e-6, Train_acc=0.988, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.987, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.979, text_image_epoch_neg_acc=0.957, text_image_epoch_pos_acc=1]\n",
      "05/05/2022 04:34:55 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 04:34:55 - INFO - root -   Epoch:87\n",
      "100%|██████████| 1091/1091 [06:13<00:00,  2.92it/s, Epoch=87, LR=4.82e-6, Train_acc=0.985, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.985, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.975, text_image_epoch_neg_acc=0.957, text_image_epoch_pos_acc=0.992]\n",
      "05/05/2022 04:41:08 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:29<00:00,  3.65it/s, Epoch=87, LR=4.82e-6, Train_acc=0.988, key_attr_epoch_acc=0.997, key_attr_epoch_neg_acc=0.988, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.979, text_image_epoch_neg_acc=0.958, text_image_epoch_pos_acc=0.999]\n",
      "05/05/2022 04:43:38 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 04:43:38 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9882782772031137 -----> 0.9882891506970464\n",
      "05/05/2022 04:43:38 - INFO - root -   \n",
      "\n",
      "05/05/2022 04:43:40 - INFO - root -   Epoch:88\n",
      "100%|██████████| 1091/1091 [06:16<00:00,  2.89it/s, Epoch=88, LR=1.23e-6, Train_acc=0.986, key_attr_epoch_acc=0.996, key_attr_epoch_neg_acc=0.986, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.976, text_image_epoch_neg_acc=0.959, text_image_epoch_pos_acc=0.993]\n",
      "05/05/2022 04:49:57 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:25<00:00,  3.74it/s, Epoch=88, LR=1.23e-6, Train_acc=0.989, key_attr_epoch_acc=0.998, key_attr_epoch_neg_acc=0.99, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.98, text_image_epoch_neg_acc=0.96, text_image_epoch_pos_acc=0.999]   \n",
      "05/05/2022 04:52:23 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 04:52:23 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9882891506970464 -----> 0.988958696688417\n",
      "05/05/2022 04:52:23 - INFO - root -   \n",
      "\n",
      "05/05/2022 04:52:25 - INFO - root -   Epoch:89\n",
      "100%|██████████| 1091/1091 [06:15<00:00,  2.91it/s, Epoch=89, LR=2.33e-9, Train_acc=0.986, key_attr_epoch_acc=0.996, key_attr_epoch_neg_acc=0.987, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.977, text_image_epoch_neg_acc=0.958, text_image_epoch_pos_acc=0.994] \n",
      "05/05/2022 04:58:40 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:27<00:00,  3.70it/s, Epoch=89, LR=2.33e-9, Train_acc=0.989, key_attr_epoch_acc=0.998, key_attr_epoch_neg_acc=0.99, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.98, text_image_epoch_neg_acc=0.96, text_image_epoch_pos_acc=1]   \n",
      "05/05/2022 05:01:07 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 05:01:07 - INFO - root -   Epoch:90\n",
      "100%|██████████| 1091/1091 [06:15<00:00,  2.90it/s, Epoch=90, LR=1.45e-6, Train_acc=0.986, key_attr_epoch_acc=0.996, key_attr_epoch_neg_acc=0.987, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.977, text_image_epoch_neg_acc=0.958, text_image_epoch_pos_acc=0.994]\n",
      "05/05/2022 05:07:23 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:29<00:00,  3.64it/s, Epoch=90, LR=1.45e-6, Train_acc=0.989, key_attr_epoch_acc=0.998, key_attr_epoch_neg_acc=0.99, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.98, text_image_epoch_neg_acc=0.96, text_image_epoch_pos_acc=1]      \n",
      "05/05/2022 05:09:53 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 05:09:53 - INFO - root -   Weighted_acc improved: best_acc improved from 0.988958696688417 -----> 0.9890408806078925\n",
      "05/05/2022 05:09:53 - INFO - root -   \n",
      "\n",
      "05/05/2022 05:09:55 - INFO - root -   Epoch:91\n",
      "100%|██████████| 1091/1091 [06:13<00:00,  2.92it/s, Epoch=91, LR=5.19e-6, Train_acc=0.986, key_attr_epoch_acc=0.996, key_attr_epoch_neg_acc=0.987, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.977, text_image_epoch_neg_acc=0.959, text_image_epoch_pos_acc=0.994]\n",
      "05/05/2022 05:16:09 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:26<00:00,  3.73it/s, Epoch=91, LR=5.19e-6, Train_acc=0.989, key_attr_epoch_acc=0.998, key_attr_epoch_neg_acc=0.991, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.98, text_image_epoch_neg_acc=0.959, text_image_epoch_pos_acc=1]   \n",
      "05/05/2022 05:18:35 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 05:18:35 - INFO - root -   Epoch:92\n",
      "100%|██████████| 1091/1091 [06:10<00:00,  2.94it/s, Epoch=92, LR=1.02e-5, Train_acc=0.986, key_attr_epoch_acc=0.996, key_attr_epoch_neg_acc=0.986, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.976, text_image_epoch_neg_acc=0.959, text_image_epoch_pos_acc=0.993]\n",
      "05/05/2022 05:24:46 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:29<00:00,  3.66it/s, Epoch=92, LR=1.02e-5, Train_acc=0.988, key_attr_epoch_acc=0.998, key_attr_epoch_neg_acc=0.99, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.979, text_image_epoch_neg_acc=0.958, text_image_epoch_pos_acc=1]   \n",
      "05/05/2022 05:27:15 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 05:27:15 - INFO - root -   Epoch:93\n",
      "100%|██████████| 1091/1091 [06:16<00:00,  2.90it/s, Epoch=93, LR=1.52e-5, Train_acc=0.985, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.986, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.975, text_image_epoch_neg_acc=0.958, text_image_epoch_pos_acc=0.992]\n",
      "05/05/2022 05:33:31 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:25<00:00,  3.75it/s, Epoch=93, LR=1.52e-5, Train_acc=0.989, key_attr_epoch_acc=0.998, key_attr_epoch_neg_acc=0.99, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.979, text_image_epoch_neg_acc=0.959, text_image_epoch_pos_acc=1]\n",
      "05/05/2022 05:35:57 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 05:35:57 - INFO - root -   Epoch:94\n",
      "100%|██████████| 1091/1091 [06:13<00:00,  2.92it/s, Epoch=94, LR=1.88e-5, Train_acc=0.984, key_attr_epoch_acc=0.994, key_attr_epoch_neg_acc=0.983, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.974, text_image_epoch_neg_acc=0.956, text_image_epoch_pos_acc=0.991]\n",
      "05/05/2022 05:42:11 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:28<00:00,  3.68it/s, Epoch=94, LR=1.88e-5, Train_acc=0.988, key_attr_epoch_acc=0.998, key_attr_epoch_neg_acc=0.989, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.979, text_image_epoch_neg_acc=0.958, text_image_epoch_pos_acc=1]\n",
      "05/05/2022 05:44:39 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 05:44:39 - INFO - root -   Epoch:95\n",
      "100%|██████████| 1091/1091 [06:11<00:00,  2.94it/s, Epoch=95, LR=2e-5, Train_acc=0.983, key_attr_epoch_acc=0.994, key_attr_epoch_neg_acc=0.982, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.973, text_image_epoch_neg_acc=0.955, text_image_epoch_pos_acc=0.99]   \n",
      "05/05/2022 05:50:51 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:17<00:00,  3.97it/s, Epoch=95, LR=2e-5, Train_acc=0.989, key_attr_epoch_acc=0.998, key_attr_epoch_neg_acc=0.989, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.979, text_image_epoch_neg_acc=0.958, text_image_epoch_pos_acc=1]   \n",
      "05/05/2022 05:53:08 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 05:53:08 - INFO - root -   Epoch:96\n",
      "100%|██████████| 1091/1091 [06:07<00:00,  2.97it/s, Epoch=96, LR=1.85e-5, Train_acc=0.984, key_attr_epoch_acc=0.994, key_attr_epoch_neg_acc=0.982, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.974, text_image_epoch_neg_acc=0.957, text_image_epoch_pos_acc=0.99]\n",
      "05/05/2022 05:59:15 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:20<00:00,  3.90it/s, Epoch=96, LR=1.85e-5, Train_acc=0.989, key_attr_epoch_acc=0.998, key_attr_epoch_neg_acc=0.989, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.98, text_image_epoch_neg_acc=0.959, text_image_epoch_pos_acc=1] \n",
      "05/05/2022 06:01:35 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 06:01:35 - INFO - root -   Epoch:97\n",
      "100%|██████████| 1091/1091 [06:05<00:00,  2.98it/s, Epoch=97, LR=1.48e-5, Train_acc=0.984, key_attr_epoch_acc=0.994, key_attr_epoch_neg_acc=0.984, key_attr_epoch_pos_acc=0.997, text_image_epoch_acc=0.974, text_image_epoch_neg_acc=0.957, text_image_epoch_pos_acc=0.99]\n",
      "05/05/2022 06:07:41 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:18<00:00,  3.93it/s, Epoch=97, LR=1.48e-5, Train_acc=0.988, key_attr_epoch_acc=0.998, key_attr_epoch_neg_acc=0.989, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.979, text_image_epoch_neg_acc=0.958, text_image_epoch_pos_acc=1]  \n",
      "05/05/2022 06:10:00 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 06:10:00 - INFO - root -   Epoch:98\n",
      "100%|██████████| 1091/1091 [06:03<00:00,  3.00it/s, Epoch=98, LR=9.76e-6, Train_acc=0.985, key_attr_epoch_acc=0.995, key_attr_epoch_neg_acc=0.985, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.974, text_image_epoch_neg_acc=0.956, text_image_epoch_pos_acc=0.992]\n",
      "05/05/2022 06:16:03 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:19<00:00,  3.90it/s, Epoch=98, LR=9.76e-6, Train_acc=0.989, key_attr_epoch_acc=0.998, key_attr_epoch_neg_acc=0.991, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.98, text_image_epoch_neg_acc=0.96, text_image_epoch_pos_acc=1]  \n",
      "05/05/2022 06:18:23 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 06:18:23 - INFO - root -   Epoch:99\n",
      "100%|██████████| 1091/1091 [06:07<00:00,  2.97it/s, Epoch=99, LR=4.79e-6, Train_acc=0.986, key_attr_epoch_acc=0.996, key_attr_epoch_neg_acc=0.988, key_attr_epoch_pos_acc=0.998, text_image_epoch_acc=0.977, text_image_epoch_neg_acc=0.96, text_image_epoch_pos_acc=0.993]\n",
      "05/05/2022 06:24:31 - INFO - root -   ***** Train results %s *****\n",
      "100%|██████████| 546/546 [02:19<00:00,  3.91it/s, Epoch=99, LR=4.79e-6, Train_acc=0.989, key_attr_epoch_acc=0.998, key_attr_epoch_neg_acc=0.991, key_attr_epoch_pos_acc=1, text_image_epoch_acc=0.98, text_image_epoch_neg_acc=0.961, text_image_epoch_pos_acc=1] \n",
      "05/05/2022 06:26:50 - INFO - root -   ***** Eval results %s *****\n",
      "05/05/2022 06:26:50 - INFO - root -   Weighted_acc improved: best_acc improved from 0.9890408806078925 -----> 0.9892699156264261\n",
      "05/05/2022 06:26:50 - INFO - root -   \n",
      "\n",
      "05/05/2022 06:26:52 - INFO - root -   avg acc:0.9892699156264261\n",
      "05/05/2022 06:26:52 - INFO - root -   [0.9892699156264261]\n"
     ]
    }
   ],
   "source": [
    "device = CFG.device\n",
    "run(df, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0894346c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94866"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "94866"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c520ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9936d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3497ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e98781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "com_envs",
   "language": "python",
   "name": "com_envs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
